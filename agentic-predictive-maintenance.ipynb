{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902a7186-2e68-403e-9622-84053bfbafc8",
   "metadata": {},
   "source": [
    "# Agentic Predictive Maintenance for Insured Assets\n",
    "---\n",
    "**Objective:** Develop an agentic predictive maintenance solution using time-series sensor data.\n",
    "\n",
    "**Core Components:**\n",
    "* **Data:** Time-series sensor data, policy data, and maintenance logs/manuals.\n",
    "* **Model:** Time-aware model selection (forecasting/classification) and hyperparameter tuning.\n",
    "* **Agent:** An AI agent combining deterministic checks, RAG (retrieval from manuals), and LLM reasoning to provide explainable maintenance recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1ec4a0-3ffc-43b3-b998-f243d9d1b38e",
   "metadata": {},
   "source": [
    "## Batch Processing: Full Pipeline for All Datasets (FD001-FD004)\n",
    "\n",
    "This cell executes the complete **Data Engineering Pipeline** for all four CMAPSS subsets.\n",
    "It orchestrates the modules we created earlier (`data_ingest`, `time_cleaning`, `feature_tools`, `scaling`).\n",
    "\n",
    "**Pipeline Logic per Dataset:**\n",
    "1.  **Ingest:** Loads raw text files, computes RUL, saves intermediate CSVs.\n",
    "2.  **Clean:** Aligns cycles, fills missing values (imputation), and caps outliers.\n",
    "3.  **Feature Engineering:** Generates temporal features (rolling mean/std, lag, trends) and anomaly indicators on the *physical* (unscaled) values.\n",
    "4.  **Scaling:**\n",
    "    * **FD001 & FD003:** Uses `Global Standardization` (single scaler).\n",
    "    * **FD002 & FD004:** Uses `Conditional Standardization` (clusters data by operating conditions first, then scales per cluster) to handle complex regimes.\n",
    "5.  **Save:** exports the final, model-ready data to `data/processed/CMAPSS/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea67e712-d29a-4150-85b0-70a5f5b9acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¢ Starting Batch Processing for All Subsets...\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD001\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD001 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD001\\train_FD001_raw.csv, data\\intermediate\\CMAPSS\\FD001\\test_FD001_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Global Standardization\n",
      "[scaling] Saved global scaler: artifacts\\scalers\\FD001_global_scaler.pkl\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD001 in 796.00 seconds.\n",
      "   Saved shape: Train (20631, 428), Test (13096, 428)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD002\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD002 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD002\\train_FD002_raw.csv, data\\intermediate\\CMAPSS\\FD002\\test_FD002_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Conditional Standardization (Clustering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.02310017 -0.02310017 -0.02310017 ... -0.02310017 -0.02310017\n",
      " -0.02310017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0326773 -0.0326773 -0.0326773 ... -0.0326773 -0.0326773 -0.0326773]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.06121538 -0.06121538 -0.06121538 ... -0.06121538 -0.06121538\n",
      " -0.06121538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03906578 -0.03906578 -0.03906578 ... -0.03906578 -0.03906578\n",
      " -0.03906578]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00872905 -0.00872905 -0.00872905 ... -0.00872905 -0.00872905\n",
      " -0.00872905]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.02310017 -0.02310017 -0.02310017 ... -0.02310017 -0.02310017\n",
      " -0.02310017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0326773 -0.0326773 -0.0326773 ... -0.0326773 -0.0326773 -0.0326773]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.06121538 -0.06121538 -0.06121538 ... -0.06121538 -0.06121538\n",
      " -0.06121538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03906578 -0.03906578 -0.03906578 ... -0.03906578 -0.03906578\n",
      " -0.03906578]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00872905 -0.00872905 -0.00872905 ... -0.00872905 -0.00872905\n",
      " -0.00872905]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scaling] Saved 6 cluster scalers and unit->cluster map for FD002\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD002 in 2404.56 seconds.\n",
      "   Saved shape: Train (53759, 429), Test (33991, 429)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD003\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD003 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD003\\train_FD003_raw.csv, data\\intermediate\\CMAPSS\\FD003\\test_FD003_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Global Standardization\n",
      "[scaling] Saved global scaler: artifacts\\scalers\\FD003_global_scaler.pkl\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD003 in 1117.04 seconds.\n",
      "   Saved shape: Train (24720, 428), Test (16596, 428)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD004\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD004 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD004\\train_FD004_raw.csv, data\\intermediate\\CMAPSS\\FD004\\test_FD004_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Conditional Standardization (Clustering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01730062 -0.01730062 -0.01730062 ... -0.01730062 -0.01730062\n",
      " -0.01730062]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.09715425 -0.09715425 -0.09715425 ... -0.09715425 -0.09715425\n",
      " -0.09715425]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03119965 -0.03119965 -0.03119965 ... -0.03119965 -0.03119965\n",
      " -0.03119965]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0561403 -0.0561403 -0.0561403 ... -0.0561403 -0.0561403 -0.0561403]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03772701 -0.03772701 -0.03772701 ... -0.03772701 -0.03772701\n",
      " -0.03772701]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0967612 -0.0967612 -0.0967612 ... -0.0967612 -0.0967612 -0.0967612]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01730062 -0.01730062 -0.01730062 ... -0.01730062 -0.01730062\n",
      " -0.01730062]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.09715425 -0.09715425 -0.09715425 ... -0.09715425 -0.09715425\n",
      " -0.09715425]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03119965 -0.03119965 -0.03119965 ... -0.03119965 -0.03119965\n",
      " -0.03119965]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0561403 -0.0561403 -0.0561403 ... -0.0561403 -0.0561403 -0.0561403]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03772701 -0.03772701 -0.03772701 ... -0.03772701 -0.03772701\n",
      " -0.03772701]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0967612 -0.0967612 -0.0967612 ... -0.0967612 -0.0967612 -0.0967612]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01140124 -0.01140124 -0.01140124 ... -0.01140124 -0.01140124\n",
      " -0.01140124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01140124 -0.01140124 -0.01140124 ... -0.01140124 -0.01140124\n",
      " -0.01140124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scaling] Saved 6 cluster scalers and unit->cluster map for FD004\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD004 in 2634.24 seconds.\n",
      "   Saved shape: Train (61249, 429), Test (41214, 429)\n",
      "\n",
      "ðŸŽ‰ðŸŽ‰ ALL DATASETS PROCESSED SUCCESSFULLY! ðŸŽ‰ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# --- 1. Suppress Warnings ---\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# 1. Import Your Modules\n",
    "from agentic_pm import data_ingest, time_cleaning, feature_tools, scaling\n",
    "\n",
    "# --- CONFIG ---\n",
    "SUBSETS = [\"FD001\", \"FD002\", \"FD003\", \"FD004\"]\n",
    "\n",
    "RAW_DIR = Path(\"data/raw/CMAPSS\")\n",
    "INTERMEDIATE_DIR = Path(\"data/intermediate/CMAPSS\")\n",
    "PROCESSED_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SCALER_DIR = Path(\"artifacts/scalers\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SCALER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def run_full_pipeline(subset_name):\n",
    "    \"\"\"\n",
    "    Runs the End-to-End Pipeline for a single subset:\n",
    "    Ingest -> Clean -> Feature Eng -> Scale -> Save\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"ðŸš€ Processing Subset: {subset_name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 1: INGEST (Load Raw & Compute RUL)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"1ï¸âƒ£ Ingesting data...\")\n",
    "    data_ingest.process_subset(subset_name, raw_base=RAW_DIR, out_base=INTERMEDIATE_DIR)\n",
    "    \n",
    "    # Load intermediate raw data\n",
    "    train_df = pd.read_csv(INTERMEDIATE_DIR / subset_name / f\"train_{subset_name}_raw.csv\")\n",
    "    test_df  = pd.read_csv(INTERMEDIATE_DIR / subset_name / f\"test_{subset_name}_raw.csv\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 2: CLEANING\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\")\n",
    "    train_df = time_cleaning.align_cycles(train_df)\n",
    "    train_df = time_cleaning.impute_missing(train_df)\n",
    "    train_df = time_cleaning.cap_outliers(train_df)\n",
    "\n",
    "    test_df = time_cleaning.align_cycles(test_df)\n",
    "    test_df = time_cleaning.impute_missing(test_df)\n",
    "    test_df = time_cleaning.cap_outliers(test_df)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 3: FEATURE ENGINEERING (On Physical Values)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"3ï¸âƒ£ Engineering Features...\")\n",
    "    # Train\n",
    "    train_df = feature_tools.create_temporal_features(train_df)\n",
    "    train_df = feature_tools.create_anomaly_indicators(train_df)\n",
    "    train_df = feature_tools.compute_health_index(train_df)\n",
    "    \n",
    "    # Test\n",
    "    test_df = feature_tools.create_temporal_features(test_df)\n",
    "    test_df = feature_tools.create_anomaly_indicators(test_df)\n",
    "    test_df = feature_tools.compute_health_index(test_df)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 4: SCALING (Prepare for ML Model)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"4ï¸âƒ£ Scaling features...\")\n",
    "    \n",
    "    # Identify feature columns (exclude metadata)\n",
    "    # We exclude 'unit', 'cycle', 'RUL', 'gap_flag' and the raw 'op_settings' if we want\n",
    "    # Usually we KEEP op_settings as features, but we scale them.\n",
    "    cols_to_exclude = ['unit', 'cycle', 'RUL', 'gap_flag', 'anom_score'] \n",
    "    # Note: 'anom_score' is 0-1 flag based, usually doesn't need scaling, but can be scaled.\n",
    "    # Let's include everything else.\n",
    "    feature_cols = [c for c in train_df.columns if c not in cols_to_exclude]\n",
    "\n",
    "    # Logic: FD001/FD003 -> Global Scaling\n",
    "    #        FD002/FD004 -> Conditional Scaling (due to multiple operating conditions)\n",
    "    if subset_name in [\"FD001\", \"FD003\"]:\n",
    "        print(f\"   -> Using Global Standardization\")\n",
    "        train_scaled, test_scaled, _ = scaling.global_standardize(\n",
    "            train_df, test_df, feature_cols, subset_name=subset_name\n",
    "        )\n",
    "    else:\n",
    "        print(f\"   -> Using Conditional Standardization (Clustering)\")\n",
    "        op_cols = [\"op_setting_1\", \"op_setting_2\", \"op_setting_3\"]\n",
    "        train_scaled, test_scaled, _, _ = scaling.conditional_standardize(\n",
    "            train_df, test_df, feature_cols, op_cols, subset_name=subset_name\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 5: SAVE FINAL DATA\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"5ï¸âƒ£ Saving final processed data...\")\n",
    "    final_train_path = PROCESSED_DIR / f\"train_{subset_name}_final.csv\"\n",
    "    final_test_path = PROCESSED_DIR / f\"test_{subset_name}_final.csv\"\n",
    "    \n",
    "    train_scaled.to_csv(final_train_path, index=False)\n",
    "    test_scaled.to_csv(final_test_path, index=False)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"âœ… Done with {subset_name} in {elapsed:.2f} seconds.\")\n",
    "    print(f\"   Saved shape: Train {train_scaled.shape}, Test {test_scaled.shape}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION LOOP\n",
    "# ==========================================\n",
    "print(\"ðŸ“¢ Starting Batch Processing for All Subsets...\")\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    try:\n",
    "        run_full_pipeline(subset)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ FAILED on {subset}: {e}\")\n",
    "        # Uncomment 'raise' if you want to stop the whole notebook on error\n",
    "        # raise e \n",
    "\n",
    "print(\"\\nðŸŽ‰ðŸŽ‰ ALL DATASETS PROCESSED SUCCESSFULLY! ðŸŽ‰ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d633a83-bb02-4e11-b372-c328302bde24",
   "metadata": {},
   "source": [
    "### Labeling & Problem Framing\n",
    "\n",
    "#### 1. Task Definition\n",
    "For this project, we explicitly define the prediction task as:\n",
    "\n",
    "- **(B) Remaining Useful Life (RUL) Regression**  \n",
    "  The model predicts the number of cycles remaining before the asset reaches end-of-life (failure threshold).  \n",
    "  Alternative tasks (A: time-to-failure regression, C: binary/multi-class maintenance classification) were considered but not selected for this iteration.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Assumptions\n",
    "- Each *cycle* in the CMAPSS dataset represents a consistent time step (uniform sampling frequency).  \n",
    "- The degradation process is monotonic toward failure within each unitâ€™s operational trajectory.  \n",
    "- Units in the training set run until failure; units in the test set are truncated before failure.  \n",
    "- Sensor measurements are assumed to be correctly calibrated and synchronized.  \n",
    "- No maintenance occurs during each unitâ€™s recorded run unless explicitly annotated.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Sampling Frequency\n",
    "- **Sampling interval:** One record per engine per cycle (i.e., *per-cycle sampling*).  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Label Generation Rules\n",
    "\n",
    "##### **Training Data**\n",
    "- Each unit runs until failure; therefore:\n",
    "  \n",
    "  \\[\n",
    "  RUL_{train}(unit, t) = \\text{max\\_cycle(unit)} - t\n",
    "  \\]\n",
    "\n",
    "##### **Test Data**\n",
    "- Test trajectories end before failure. Ground-truth final RUL values are provided separately.\n",
    "  \n",
    "  \\[\n",
    "  RUL_{test}(unit, t) = RUL_{given}(unit) + (\\text{final\\_cycle(unit)} - t)\n",
    "  \\]\n",
    "\n",
    "##### **Optional Enhancements**\n",
    "- Clip large RUL values (e.g., max 130 cycles) to stabilize model training.  \n",
    "- Apply transformations (e.g., `log1p(RUL)`) when using models sensitive to scale.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Example Asset Timelines (Annotated)\n",
    "\n",
    "Below we illustrate two example trajectories:\n",
    "\n",
    "1. **Training unit (full run):**\n",
    "   - Starts healthy, degrades over time, ends in a failure event.  \n",
    "   - RUL decreases linearly with respect to cycle index until reaching zero at the final cycle.\n",
    "\n",
    "2. **Test unit (truncated run):**\n",
    "   - Sequence ends before failure.  \n",
    "   - Final RUL label is assigned by combining the provided RUL file with the time remaining from the last observed cycle.\n",
    "\n",
    "These annotated timelines help verify label correctness, confirm continuity, and validate assumptions about degradation behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4811fd-658d-4687-9e9c-0cf1f84bd25a",
   "metadata": {},
   "source": [
    "# ðŸ“ Project Status Checkpoint: Data Pipeline & Feature Engineering\n",
    "\n",
    "At this stage, we have successfully implemented the **Data Engineering** and **Tool Definition** layers of our Agentic Predictive Maintenance system. Instead of raw processing within the notebook, we have modularized our code into the `agentic_pm` package for reproducibility and scalability.\n",
    "\n",
    "### Summary of Accomplishments:\n",
    "\n",
    "#### 1. Data Ingestion & Cleaning (Layer 1)\n",
    "We processed the raw CMAPSS datasets (FD001-FD004) through a rigorous cleaning pipeline:\n",
    "* **Ingestion:** Loaded raw text files and computed the **Remaining Useful Life (RUL)** target.\n",
    "* **Alignment:** Used `align_cycles` to create a continuous time index for each asset, handling missing timestamps.\n",
    "* **Imputation:** Filled sensor gaps using linear interpolation (`impute_missing`).\n",
    "* **Noise Reduction:** Applied a rolling Z-score filter (`cap_outliers`) to smooth extreme sensor spikes while retaining the signal.\n",
    "\n",
    "#### 2. Feature Engineering (Layer 2)\n",
    "We generated advanced features on the *cleaned physical values* (before normalization) to capture temporal dynamics:\n",
    "* **Temporal Features:** Rolling Means & Standard Deviations (window sizes 5, 15, 60), Exponential Moving Averages (EMA), and Lag features.\n",
    "* **Anomaly Indicators:** Computed Z-scores and change-point detection flags to highlight abnormal sensor behavior.\n",
    "* **Health Index:** Created a composite score combining weighted sensor values to represent overall asset health.\n",
    "\n",
    "#### 3. Agent Tools (Layer 3)\n",
    "We implemented deterministic tools that our AI Agent will call later:\n",
    "* **`diagnostic_checker`:** A rule-based tool that checks specific physical thresholds (e.g., *Temperature > 800Â°C*) to flag immediate risks.\n",
    "* **`maintenance_simulator`:** A \"what-if\" tool to simulate the impact of preventive maintenance on failure probability.\n",
    "\n",
    "#### 4. Scaling & Normalization (Layer 4)\n",
    "To prepare the data for Machine Learning models, we applied dataset-specific scaling:\n",
    "* **Global Standardization:** Applied to **FD001 & FD003** (single operating condition).\n",
    "* **Conditional Standardization:** Applied to **FD002 & FD004** (multiple operating conditions), using KMeans clustering to normalize data within specific operating regimes.\n",
    "\n",
    "---\n",
    "**âœ… Current State:** Cleaned, feature-engineered, and normalized datasets are saved in `data/processed/CMAPSS/`.\n",
    "**ðŸ‘‰ Next Step:** We will now proceed to **Step 3: Model Selection**, where we will train and evaluate models (XGBoost, etc.) using time-aware validation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111447f4-09ec-4058-b602-b7ca1d494e08",
   "metadata": {},
   "source": [
    "## 3. Model Selection, Hyperparameter Tuning & Evaluation\n",
    "\n",
    "CMAPSS Predictive Maintenance â€” Full Modeling Pipeline\n",
    "\n",
    "Tabular + Sequence Models + Anomaly Detection + Comparison\n",
    "\n",
    "This notebook uses the final processed datasets created by the preprocessing pipeline:\n",
    "   data/processed/CMAPSS/train_FD00X_final.csv\n",
    "   data/processed/CMAPSS/test_FD00X_final.csv\n",
    "\n",
    "It evaluates:\n",
    "- Classical tabular models (RandomForest, ElasticNet, LightGBM)\n",
    "- Sequence models (LSTM, GRU, Mini-TCN)\n",
    "- Anomaly model (IsolationForest) and using its score as a feature\n",
    "- Comparison table summarizing metrics\n",
    "\n",
    "### 3.1 Import & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12648b07-24ad-4a12-a0b5-c34f5504d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready. Torch: True LightGBM: True Optuna: True\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# modeling utilities we created\n",
    "from agentic_pm.modeling import model_selection as ms\n",
    "\n",
    "# optional libs - we'll check availability\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "except Exception:\n",
    "    optuna = None\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "except Exception:\n",
    "    torch = None\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import joblib\n",
    "\n",
    "print(\"Environment ready. Torch:\", bool(torch), \"LightGBM:\", bool(lgb), \"Optuna:\", bool(optuna))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40bc9c0-667c-4458-b995-47d914200573",
   "metadata": {},
   "source": [
    "### 3.2 Load Final Datasets\n",
    "Choose subset (FD001..FD004) and load the final train/test CSVs produced by your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d14d73-e549-4276-9309-b3821c56a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files:\n",
      " - data\\processed\\CMAPSS\\train_FD001_final.csv (20631, 428)\n",
      " - data\\processed\\CMAPSS\\test_FD001_final.csv (13096, 428)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>unit</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_13_norm_unit</th>\n",
       "      <th>sensor_14_norm_unit</th>\n",
       "      <th>sensor_15_norm_unit</th>\n",
       "      <th>sensor_16_norm_unit</th>\n",
       "      <th>sensor_17_norm_unit</th>\n",
       "      <th>sensor_18_norm_unit</th>\n",
       "      <th>sensor_19_norm_unit</th>\n",
       "      <th>sensor_20_norm_unit</th>\n",
       "      <th>sensor_21_norm_unit</th>\n",
       "      <th>health_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.315980</td>\n",
       "      <td>-1.372953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.721725</td>\n",
       "      <td>-0.134255</td>\n",
       "      <td>-0.925936</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278164</td>\n",
       "      <td>1.997798</td>\n",
       "      <td>-0.380157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.354811</td>\n",
       "      <td>1.317629</td>\n",
       "      <td>-0.534520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872722</td>\n",
       "      <td>-1.031720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.061780</td>\n",
       "      <td>0.211528</td>\n",
       "      <td>-0.643726</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636957</td>\n",
       "      <td>1.072544</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991643</td>\n",
       "      <td>1.360548</td>\n",
       "      <td>-0.438211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.961874</td>\n",
       "      <td>1.015677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-0.413166</td>\n",
       "      <td>-0.525953</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.149922</td>\n",
       "      <td>1.298342</td>\n",
       "      <td>-0.435259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.053313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689003</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>-0.618248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324090</td>\n",
       "      <td>-0.008022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-1.261314</td>\n",
       "      <td>-0.784831</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508715</td>\n",
       "      <td>1.376204</td>\n",
       "      <td>-2.042955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265307</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>-0.765705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.864611</td>\n",
       "      <td>-0.690488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621816</td>\n",
       "      <td>-1.251528</td>\n",
       "      <td>-0.301518</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021681</td>\n",
       "      <td>1.372310</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.223972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386363</td>\n",
       "      <td>1.181405</td>\n",
       "      <td>-0.317219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cycle  unit  op_setting_1  op_setting_2  op_setting_3  sensor_1  sensor_2  \\\n",
       "0      1     1     -0.315980     -1.372953           0.0       0.0 -1.721725   \n",
       "1      2     1      0.872722     -1.031720           0.0       0.0 -1.061780   \n",
       "2      3     1     -1.961874      1.015677           0.0       0.0 -0.661813   \n",
       "3      4     1      0.324090     -0.008022           0.0       0.0 -0.661813   \n",
       "4      5     1     -0.864611     -0.690488           0.0       0.0 -0.621816   \n",
       "\n",
       "   sensor_3  sensor_4      sensor_5  ...  sensor_13_norm_unit  \\\n",
       "0 -0.134255 -0.925936 -5.329071e-15  ...            -1.278164   \n",
       "1  0.211528 -0.643726 -5.329071e-15  ...            -0.636957   \n",
       "2 -0.413166 -0.525953 -5.329071e-15  ...            -1.149922   \n",
       "3 -1.261314 -0.784831 -5.329071e-15  ...            -0.508715   \n",
       "4 -1.251528 -0.301518 -5.329071e-15  ...            -1.021681   \n",
       "\n",
       "   sensor_14_norm_unit  sensor_15_norm_unit  sensor_16_norm_unit  \\\n",
       "0             1.997798            -0.380157                  0.0   \n",
       "1             1.072544             0.018526                  0.0   \n",
       "2             1.298342            -0.435259                  0.0   \n",
       "3             1.376204            -2.042955                  0.0   \n",
       "4             1.372310            -0.059266                  0.0   \n",
       "\n",
       "   sensor_17_norm_unit  sensor_18_norm_unit  sensor_19_norm_unit  \\\n",
       "0            -0.833752                  0.0                  0.0   \n",
       "1            -0.833752                  0.0                  0.0   \n",
       "2            -2.053313                  0.0                  0.0   \n",
       "3            -0.833752                  0.0                  0.0   \n",
       "4            -0.223972                  0.0                  0.0   \n",
       "\n",
       "   sensor_20_norm_unit  sensor_21_norm_unit  health_index  \n",
       "0             1.354811             1.317629     -0.534520  \n",
       "1             0.991643             1.360548     -0.438211  \n",
       "2             0.689003             0.619718     -0.618248  \n",
       "3             0.265307             0.896829     -0.765705  \n",
       "4             0.386363             1.181405     -0.317219  \n",
       "\n",
       "[5 rows x 428 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SUBSET = \"FD001\"   # change if you want FD002/FD003/FD004\n",
    "\n",
    "train_path = DATA_DIR / f\"train_{SUBSET}_final.csv\"\n",
    "test_path  = DATA_DIR / f\"test_{SUBSET}_final.csv\"\n",
    "\n",
    "assert train_path.exists(), f\"Train file missing: {train_path}\"\n",
    "assert test_path.exists(),  f\"Test file missing: {test_path}\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Loaded files:\")\n",
    "print(\" -\", train_path, train_df.shape)\n",
    "print(\" -\", test_path, test_df.shape)\n",
    "display(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532787d-1ab6-4966-aad0-8292de4df389",
   "metadata": {},
   "source": [
    "### 3.3 Basic sanity checks\n",
    "Check RUL, missing values, and columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c783d5d-68cc-4622-b47c-65145f2e5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUL range (train): 0 361\n",
      "Nulls per column (train):\n",
      "sensor_21_lag_6    600\n",
      "sensor_20_lag_6    600\n",
      "sensor_19_lag_6    600\n",
      "sensor_18_lag_6    600\n",
      "sensor_17_lag_6    600\n",
      "sensor_16_lag_6    600\n",
      "sensor_15_lag_6    600\n",
      "sensor_14_lag_6    600\n",
      "sensor_13_lag_6    600\n",
      "sensor_12_lag_6    600\n",
      "dtype: int64\n",
      "Total columns: 428\n",
      "Sample columns: ['cycle', 'unit', 'op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15', 'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19', 'sensor_20', 'sensor_21', 'RUL', 'sensor_1_rm_5', 'sensor_1_rstd_5', 'sensor_1_slope_5']\n"
     ]
    }
   ],
   "source": [
    "# sanity\n",
    "print(\"RUL range (train):\", train_df[\"RUL\"].min(), train_df[\"RUL\"].max())\n",
    "print(\"Nulls per column (train):\")\n",
    "print(train_df.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# list of columns\n",
    "cols = train_df.columns.tolist()\n",
    "print(\"Total columns:\", len(cols))\n",
    "print(\"Sample columns:\", cols[:30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30c882-a0f5-44c3-8dbe-45ed6238ece7",
   "metadata": {},
   "source": [
    "### 3.4 Feature Selection\n",
    "We have too many features. We need feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fddf6210-5ef1-42d9-bdbc-d1196b70cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning feature space...\n",
      "Removing lag columns: 63 columns removed\n",
      "NaN fix complete:\n",
      "cycle           0\n",
      "unit            0\n",
      "op_setting_1    0\n",
      "op_setting_2    0\n",
      "op_setting_3    0\n",
      "dtype: int64\n",
      " Tabular features selected: 125\n",
      "Sequence features selected: 29\n",
      "Examples (tabular): ['anom_score', 'health_index', 'op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_10_slope_15', 'sensor_11_rm_15', 'sensor_11_rm_60', 'sensor_11_slope_15', 'sensor_11_slope_5']\n",
      "Examples (sequence): ['anom_score', 'health_index', 'sensor_11_rm_15', 'sensor_11_rm_60', 'sensor_13', 'sensor_13_rm_5', 'sensor_13_rstd_5', 'sensor_14_rm_15', 'sensor_14_rm_5', 'sensor_15_rm_5']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5) Feature Cleanup & Selection (Tabular + Sequence)\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Cleaning feature space...\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Drop all lag columns (lag features cause NaN at sequence start)\n",
    "# ------------------------------------------------------------\n",
    "lag_cols = [c for c in train_df.columns if \"_lag_\" in c]\n",
    "print(f\"Removing lag columns: {len(lag_cols)} columns removed\")\n",
    "train_df = train_df.drop(columns=lag_cols)\n",
    "test_df  = test_df.drop(columns=lag_cols)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Fix NaN values (per-unit backfill â†’ forward fill)\n",
    "# ------------------------------------------------------------\n",
    "def fix_nans(df):\n",
    "    return (df.groupby(\"unit\")\n",
    "              .apply(lambda g: g.bfill().ffill())\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "train_df = fix_nans(train_df)\n",
    "test_df  = fix_nans(test_df)\n",
    "\n",
    "print(\"NaN fix complete:\")\n",
    "print(train_df.isna().sum().sort_values(ascending=False).head(5))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Construct tabular feature list\n",
    "# ------------------------------------------------------------\n",
    "META_EXCLUDE = {\"unit\", \"cycle\", \"RUL\", \"gap_flag\"}\n",
    "\n",
    "all_features = [c for c in train_df.columns if c not in META_EXCLUDE]\n",
    "\n",
    "# Variance filtering: keep top-k highest variance features\n",
    "k = 120\n",
    "variances = train_df[all_features].var().sort_values(ascending=False)\n",
    "topk = list(variances.index[:k])\n",
    "\n",
    "# Always keep key domain indicators\n",
    "domain_keep = [\n",
    "    \"health_index\",\n",
    "    \"anom_score\",\n",
    "    \"op_setting_1\",\n",
    "    \"op_setting_2\",\n",
    "    \"op_setting_3\"\n",
    "]\n",
    "domain_keep = [c for c in domain_keep if c in train_df.columns]\n",
    "\n",
    "tabular_features = sorted(set(topk + domain_keep))\n",
    "\n",
    "print(f\" Tabular features selected: {len(tabular_features)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Build sequence features (reduced set for LSTM/TCN efficiency)\n",
    "# ------------------------------------------------------------\n",
    "keep_patterns = [\n",
    "    r'^sensor_\\d+$',        # raw sensor values\n",
    "    r'^sensor_\\d+_rm_5$',   # short rolling means\n",
    "    r'^sensor_\\d+_rm_15$',\n",
    "    r'^sensor_\\d+_rm_60$',\n",
    "    r'^sensor_\\d+_rstd_5$', # short rolling std\n",
    "    r'^health_index$',      # degradation signal\n",
    "    r'^anom_score$'         # anomaly indicator\n",
    "]\n",
    "\n",
    "def match_any(col):\n",
    "    return any(re.match(p, col) for p in keep_patterns)\n",
    "\n",
    "sequence_features = [c for c in tabular_features if match_any(c)]\n",
    "\n",
    "# fallback if pattern too restrictive\n",
    "if len(sequence_features) < 12:\n",
    "    sequence_features = tabular_features[:40]\n",
    "\n",
    "print(f\"Sequence features selected: {len(sequence_features)}\")\n",
    "\n",
    "# Show samples\n",
    "print(\"Examples (tabular):\", tabular_features[:10])\n",
    "print(\"Examples (sequence):\", sequence_features[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91582f00-25ad-4ce3-8dd7-1a3a6e04bb27",
   "metadata": {},
   "source": [
    "### 3.5 Train/Validation Split (per-unit holdout)\n",
    "Use per-unit holdout (last portion of cycles per unit) to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3213aca3-57af-41a9-b62a-db7f4af78614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 14398 Val rows: 6233\n"
     ]
    }
   ],
   "source": [
    "# Get row indices for per-unit holdout\n",
    "train_idx, val_idx = ms.per_unit_holdout(train_df, holdout_frac=0.3)\n",
    "print(\"Train rows:\", len(train_idx), \"Val rows:\", len(val_idx))\n",
    "\n",
    "# Prepare arrays for tabular models\n",
    "X = train_df[tabular_features].values\n",
    "y = train_df[\"RUL\"].values\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_val   = X[val_idx]\n",
    "y_train = y[train_idx]\n",
    "y_val   = y[val_idx]\n",
    "\n",
    "# Standardize features for sklearn models (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25499f5-13bf-491e-ad61-c8678c7f305c",
   "metadata": {},
   "source": [
    "### 3.6 Baselines (Persistence & Moving-average linear map)\n",
    "Evaluate leakage-free baselines to anchor model expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d17d5b-de55-442f-ab7c-e4c298faa763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence baseline (shifted) metrics: {'MAE': 0.9839563613027434, 'RMSE': 0.9919457451407024, 'R2': 0.9977172069450396}\n",
      "Moving-average baseline metrics: {'MAE': 108.3474749721799, 'RMSE': 110.31866168564305, 'R2': -27.23505734065863}\n"
     ]
    }
   ],
   "source": [
    "# Baseline: persistence (shifted)\n",
    "y_val_persist = ms.baseline_persistence_shift(train_df.iloc[val_idx])  # make sure method accepts dataframe slice\n",
    "# The baseline impl may expect full df aligned; use ms.baseline_persistence_shift on the val slice\n",
    "# We need y_true for validation rows:\n",
    "y_true = y[val_idx]\n",
    "\n",
    "# For moving-average baseline: fit on train_df and predict on validation portion of train_df (or test later)\n",
    "# Here demonstrate using same split: compute on rows corresponding to val_idx (they are rows in train_df)\n",
    "ma_preds = ms.baseline_ma_linear_map(train_df.iloc[train_idx], train_df.iloc[val_idx], sensor_col=\"sensor_1\", window=10)\n",
    "\n",
    "# Evaluate\n",
    "try:\n",
    "    metrics_persist = ms.regression_metrics(y_true, y_val_persist)\n",
    "except Exception:\n",
    "    # fallback compute on simple approach (if shapes mismatch)\n",
    "    metrics_persist = {\"MAE\": float(\"nan\"), \"RMSE\": float(\"nan\"), \"R2\": float(\"nan\")}\n",
    "\n",
    "metrics_ma = ms.regression_metrics(y_true, ma_preds)\n",
    "\n",
    "print(\"Persistence baseline (shifted) metrics:\", metrics_persist)\n",
    "print(\"Moving-average baseline metrics:\", metrics_ma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7d964b-7d29-470e-a98d-adbec1b8b66f",
   "metadata": {},
   "source": [
    "### 3.7 Tabular Model\n",
    "#### 3.7.1 Random Forest\n",
    "Train a RandomForest on the standardized tabular features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6250ca-0efa-410e-b5d6-a1236c4e23d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF metrics: {'MAE': 27.662710956963686, 'RMSE': 31.64981748161584, 'R2': -1.323983950866963}\n",
      "Precision@100 (rf): 0.02\n",
      "Early-warning@7 (rf): 0.0\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\"n_estimators\":200, \"max_depth\":12, \"min_samples_leaf\":2}\n",
    "rf = ms.fit_random_forest(X_train_s, y_train, params=rf_params)\n",
    "y_val_pred_rf = rf.predict(X_val_s)\n",
    "metrics_rf = ms.regression_metrics(y_val, y_val_pred_rf)\n",
    "print(\"RF metrics:\", metrics_rf)\n",
    "print(\"Precision@100 (rf):\", ms.precision_at_k_rul(y_val, y_val_pred_rf, k=100))\n",
    "print(\"Early-warning@7 (rf):\", ms.early_warning_rate(train_df.iloc[val_idx], y_val, y_val_pred_rf, lead=7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca54c92-bc09-4452-842a-0d580f291ddb",
   "metadata": {},
   "source": [
    "#### 3.7.2 ElasticNet\n",
    "Train a regularized linear model (ElasticNet) for benchmarking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d80abf9-3e7f-4e02-ae2e-38607af6e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet metrics: {'MAE': 75.38697489734093, 'RMSE': 101.54092259576085, 'R2': -22.920646601780117}\n",
      "Precision@100 (en): 0.22\n"
     ]
    }
   ],
   "source": [
    "en_params = {\"alpha\": 0.01, \"l1_ratio\": 0.2}\n",
    "en = ms.fit_elasticnet(X_train_s, y_train, params=en_params)\n",
    "y_val_pred_en = en.predict(X_val_s)\n",
    "metrics_en = ms.regression_metrics(y_val, y_val_pred_en)\n",
    "print(\"ElasticNet metrics:\", metrics_en)\n",
    "print(\"Precision@100 (en):\", ms.precision_at_k_rul(y_val, y_val_pred_en, k=100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50518fe6-df5c-480e-8fdf-9e6829086f37",
   "metadata": {},
   "source": [
    "#### 3.7.3 LightGBM (version-safe)\n",
    "Train LightGBM using ms.fit_lightgbm. If LightGBM not installed, skip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ae24fe-8142-4a46-8b9a-b68142fcdf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's l1: 22.7097\n",
      "LightGBM metrics: {'MAE': 22.709666182561556, 'RMSE': 27.10636182058728, 'R2': -0.7046419305422893}\n",
      "Precision@100 (lgb): 0.0\n",
      "Early-warning@7 (lgb): 0.0\n"
     ]
    }
   ],
   "source": [
    "if lgb is None:\n",
    "    print(\"LightGBM not installed â€” skipping LGBM.\")\n",
    "else:\n",
    "    lgb_params = {\"objective\":\"regression\", \"metric\":\"mae\", \"learning_rate\":0.05, \"num_leaves\":48, \"verbosity\":-1}\n",
    "    try:\n",
    "        lgb_model, lgb_info = ms.fit_lightgbm(X_train_s, y_train, X_val_s, y_val, params=lgb_params, rounds=1000, early=50)\n",
    "        y_val_pred_lgb = lgb_model.predict(X_val_s)\n",
    "        metrics_lgb = ms.regression_metrics(y_val, y_val_pred_lgb)\n",
    "        print(\"LightGBM metrics:\", metrics_lgb)\n",
    "        print(\"Precision@100 (lgb):\", ms.precision_at_k_rul(y_val, y_val_pred_lgb, k=100))\n",
    "        print(\"Early-warning@7 (lgb):\", ms.early_warning_rate(train_df.iloc[val_idx], y_val, y_val_pred_lgb, lead=7))\n",
    "    except Exception as e:\n",
    "        print(\"LightGBM training error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354ecdf-92df-4332-a83b-28ca332c1817",
   "metadata": {},
   "source": [
    "### 3.8 Anomaly Model: IsolationForest\n",
    "Fit IsolationForest on training features, compute anomaly score for train/val and optionally add as a feature for model retraining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793b057a-0150-4201-ab7d-fb8ee87746a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly score (train) stats: 0.3509437643130367 0.6964313243918464 0.4067106093380277\n",
      "Anomaly score (val)   stats: 0.3635086542925437 0.6586642447075471 0.49786727881221426\n",
      "RF enriched (with anomaly) metrics: {'MAE': 27.67307100422802, 'RMSE': 31.669657734252304, 'R2': -1.326898525693852}\n"
     ]
    }
   ],
   "source": [
    "iso = IsolationForest(contamination=0.02, random_state=42)\n",
    "iso.fit(X_train_s)\n",
    "train_anom = iso.score_samples(X_train_s)   # higher = less anomalous; we can invert\n",
    "val_anom   = iso.score_samples(X_val_s)\n",
    "\n",
    "# Invert to get anomaly magnitude (higher means more anomalous)\n",
    "train_anom_score = -train_anom\n",
    "val_anom_score = -val_anom\n",
    "\n",
    "print(\"Anomaly score (train) stats:\", np.nanmin(train_anom_score), np.nanmax(train_anom_score), np.nanmean(train_anom_score))\n",
    "print(\"Anomaly score (val)   stats:\", np.nanmin(val_anom_score), np.nanmax(val_anom_score), np.nanmean(val_anom_score))\n",
    "\n",
    "# Optionally attach to features and retrain RF quickly to see impact\n",
    "X_train_enriched = np.hstack([X_train_s, train_anom_score.reshape(-1,1)])\n",
    "X_val_enriched   = np.hstack([X_val_s, val_anom_score.reshape(-1,1)])\n",
    "\n",
    "rf_enriched = ms.fit_random_forest(X_train_enriched, y_train, params=rf_params)\n",
    "y_val_pred_rf_enriched = rf_enriched.predict(X_val_enriched)\n",
    "metrics_rf_enriched = ms.regression_metrics(y_val, y_val_pred_rf_enriched)\n",
    "print(\"RF enriched (with anomaly) metrics:\", metrics_rf_enriched)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc71801-5fdd-4ecd-90a3-d10f2f01c375",
   "metadata": {},
   "source": [
    "### 3.9 Sequence Model\n",
    "#### 3.9.1 Prepare Sliding Windows for Sequence Models\n",
    "Convert train/val row-splits into sliding windows (single-step RUL prediction).\n",
    "- Uses ms.make_windows() and sequence_features defined earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df86ce4-cf77-4a4a-a624-d5f4077362fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence windows shapes -> Train: (9498, 50, 29) Val: (1393, 50, 29)\n"
     ]
    }
   ],
   "source": [
    "if torch is None:\n",
    "    print(\"PyTorch not available â€” sequence models will be skipped.\")\n",
    "else:\n",
    "    seq_len = 50   # starting point; tune later\n",
    "    stride = 1\n",
    "\n",
    "    # Prepare windows using rows from train_idx and val_idx (these index into train_df)\n",
    "    train_df_tr = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    train_df_va = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    Xtr_seq, ytr_seq, units_tr = ms.make_windows(train_df_tr, sequence_features, seq_len=seq_len, )\n",
    "    Xva_seq, yva_seq, units_va = ms.make_windows(train_df_va, sequence_features, seq_len=seq_len, )\n",
    "\n",
    "    print(\"Sequence windows shapes -> Train:\", Xtr_seq.shape, \"Val:\", Xva_seq.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb0963-a729-4d1f-bb32-597fd65d02ee",
   "metadata": {},
   "source": [
    "#### 3.9.2 Sequence DataLoaders\n",
    "Build DataLoader wrappers for training sequence models (if torch available).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "112ded19-f119-4497-bee4-830e9c7c7b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for sequence training: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch is not None:\n",
    "    batch_size = 32\n",
    "    train_loader_seq = DataLoader(ms.SequenceDataset(Xtr_seq, ytr_seq), batch_size=batch_size, shuffle=True)\n",
    "    val_loader_seq   = DataLoader(ms.SequenceDataset(Xva_seq, yva_seq), batch_size=batch_size, shuffle=False)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Device for sequence training:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394cb38-91c3-40d2-bcde-fa41307715b2",
   "metadata": {},
   "source": [
    "#### 3.9.3 Sequence Model: LSTM\n",
    "Train LSTM (if torch available). This is a small model to be laptop-friendly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ad026c-ee2a-4df7-94cf-d414e546ad45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 21:33:39,816 INFO [SEQ] Epoch 00  val_MAE=11.6552\n",
      "2025-11-22 21:33:40,560 INFO [SEQ] Epoch 01  val_MAE=10.7492\n",
      "2025-11-22 21:33:41,522 INFO [SEQ] Epoch 02  val_MAE=10.3695\n",
      "2025-11-22 21:33:42,492 INFO [SEQ] Epoch 03  val_MAE=10.2608\n",
      "2025-11-22 21:33:43,373 INFO [SEQ] Epoch 04  val_MAE=10.3200\n",
      "2025-11-22 21:33:44,325 INFO [SEQ] Epoch 05  val_MAE=10.4923\n",
      "2025-11-22 21:33:45,251 INFO [SEQ] Epoch 06  val_MAE=10.7466\n",
      "2025-11-22 21:33:46,169 INFO [SEQ] Epoch 07  val_MAE=11.0896\n",
      "2025-11-22 21:33:47,159 INFO [SEQ] Epoch 08  val_MAE=11.5169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM best val MAE: 10.260827097025784\n"
     ]
    }
   ],
   "source": [
    "lstm_val_mae = None\n",
    "if torch is None:\n",
    "    print(\"PyTorch not installed â€” skipping LSTM.\")\n",
    "else:\n",
    "    model_lstm = ms.LSTMRegressor(n_features=len(sequence_features), hidden_size=64, num_layers=1)\n",
    "    model_lstm, lstm_val_mae = ms.train_sequence_model(model_lstm, train_loader_seq, val_loader_seq, lr=1e-4, epochs=25, patience=5, device=device)\n",
    "    print(\"LSTM best val MAE:\", lstm_val_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f45c4-7384-4d0e-a556-5453263357de",
   "metadata": {},
   "source": [
    "#### 3.9.4 Sequence Model: GRU\n",
    "Train a GRU (if torch available).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2614ab6d-97cc-4bea-86f1-a70aeeb01b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 21:33:48,088 INFO [SEQ] Epoch 00  val_MAE=22.6069\n",
      "2025-11-22 21:33:48,971 INFO [SEQ] Epoch 01  val_MAE=36.3908\n",
      "2025-11-22 21:33:49,855 INFO [SEQ] Epoch 02  val_MAE=51.1391\n",
      "2025-11-22 21:33:50,713 INFO [SEQ] Epoch 03  val_MAE=59.5705\n",
      "2025-11-22 21:33:51,482 INFO [SEQ] Epoch 04  val_MAE=68.3851\n",
      "2025-11-22 21:33:52,278 INFO [SEQ] Epoch 05  val_MAE=68.6047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU best val MAE: 22.606884197755292\n"
     ]
    }
   ],
   "source": [
    "gru_val_mae = None\n",
    "if torch is None:\n",
    "    print(\"PyTorch not installed â€” skipping GRU.\")\n",
    "else:\n",
    "    # GRURegressor may be available in ms; if not, we can reuse LSTMRegressor signature as GRU.\n",
    "    try:\n",
    "        model_gru = ms.GRURegressor(n_features=len(sequence_features), hidden_size=64, num_layers=1)\n",
    "    except Exception:\n",
    "        # fallback: try to construct GRU analog by building a simple wrapper in-line\n",
    "        class GRURegressorFallback(torch.nn.Module):\n",
    "            def __init__(self, n_features, hidden_size=64, num_layers=1, dropout=0.0):\n",
    "                super().__init__()\n",
    "                self.gru = torch.nn.GRU(input_size=n_features, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout if num_layers>1 else 0.0)\n",
    "                self.fc = torch.nn.Linear(hidden_size, 1)\n",
    "            def forward(self, x):\n",
    "                _, h = self.gru(x)\n",
    "                last = h[-1]\n",
    "                return self.fc(last).squeeze(1)\n",
    "        model_gru = GRURegressorFallback(n_features=len(sequence_features), hidden_size=64, num_layers=1)\n",
    "\n",
    "    model_gru, gru_val_mae = ms.train_sequence_model(model_gru, train_loader_seq, val_loader_seq, lr=1e-3, epochs=25, patience=5, device=device)\n",
    "    print(\"GRU best val MAE:\", gru_val_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71dc5b-2fc4-4a46-8149-03533003d6c8",
   "metadata": {},
   "source": [
    "#### 3.9.5 Sequence Model: Mini-TCN\n",
    "Train a tiny Temporal Convolutional Network (if torch available).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd4134e3-b46d-4ccd-a54c-44e11317773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 21:33:53,208 INFO [SEQ] Epoch 00  val_MAE=32.8764\n",
      "2025-11-22 21:33:54,007 INFO [SEQ] Epoch 01  val_MAE=29.8522\n",
      "2025-11-22 21:33:54,831 INFO [SEQ] Epoch 02  val_MAE=22.3941\n",
      "2025-11-22 21:33:55,629 INFO [SEQ] Epoch 03  val_MAE=22.2304\n",
      "2025-11-22 21:33:56,441 INFO [SEQ] Epoch 04  val_MAE=22.4182\n",
      "2025-11-22 21:33:57,271 INFO [SEQ] Epoch 05  val_MAE=23.8514\n",
      "2025-11-22 21:33:58,099 INFO [SEQ] Epoch 06  val_MAE=21.1476\n",
      "2025-11-22 21:33:58,787 INFO [SEQ] Epoch 07  val_MAE=22.9198\n",
      "2025-11-22 21:33:59,535 INFO [SEQ] Epoch 08  val_MAE=23.7594\n",
      "2025-11-22 21:34:00,353 INFO [SEQ] Epoch 09  val_MAE=24.0141\n",
      "2025-11-22 21:34:01,283 INFO [SEQ] Epoch 10  val_MAE=22.7364\n",
      "2025-11-22 21:34:02,193 INFO [SEQ] Epoch 11  val_MAE=18.1499\n",
      "2025-11-22 21:34:03,128 INFO [SEQ] Epoch 12  val_MAE=17.8936\n",
      "2025-11-22 21:34:04,044 INFO [SEQ] Epoch 13  val_MAE=16.9914\n",
      "2025-11-22 21:34:04,943 INFO [SEQ] Epoch 14  val_MAE=17.2406\n",
      "2025-11-22 21:34:05,861 INFO [SEQ] Epoch 15  val_MAE=18.9973\n",
      "2025-11-22 21:34:06,772 INFO [SEQ] Epoch 16  val_MAE=22.3488\n",
      "2025-11-22 21:34:07,670 INFO [SEQ] Epoch 17  val_MAE=21.2573\n",
      "2025-11-22 21:34:08,569 INFO [SEQ] Epoch 18  val_MAE=22.5505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCN best val MAE: 16.99135171283375\n"
     ]
    }
   ],
   "source": [
    "tcn_val_mae = None\n",
    "if torch is None:\n",
    "    print(\"PyTorch not installed â€” skipping TCN.\")\n",
    "else:\n",
    "    try:\n",
    "        model_tcn = ms.MiniTCN(n_features=len(sequence_features), hidden=32)\n",
    "        model_tcn, tcn_val_mae = ms.train_sequence_model(model_tcn, train_loader_seq, val_loader_seq, lr=1e-3, epochs=25, patience=5, device=device)\n",
    "        print(\"TCN best val MAE:\", tcn_val_mae)\n",
    "    except Exception as e:\n",
    "        print(\"TCN training failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649f21b-c6cd-42a7-830b-7592957b8244",
   "metadata": {},
   "source": [
    "### 3.10 Evaluate sequence models on validation windows\n",
    "Convert val_loader outputs to predictions and compute metrics for sequence models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b9f63b-8d6e-42ce-a002-150a530eae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence results (val):\n",
      "            MAE       RMSE        R2\n",
      "LSTM  10.301333  14.395913 -0.564732\n",
      "GRU   22.636562  25.065982 -3.743852\n",
      "TCN   17.073636  20.586895 -2.199951\n"
     ]
    }
   ],
   "source": [
    "def eval_sequence_model(model, data_loader, device=\"cuda\"):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in data_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            preds.extend(out.cpu().numpy().tolist())\n",
    "            trues.extend(yb.cpu().numpy().tolist())\n",
    "    return np.array(trues), np.array(preds)\n",
    "\n",
    "seq_results = {}\n",
    "if torch is not None:\n",
    "    if lstm_val_mae is not None:\n",
    "        y_true_l, y_pred_l = eval_sequence_model(model_lstm, val_loader_seq, device=device)\n",
    "        seq_results['LSTM'] = ms.regression_metrics(y_true_l, y_pred_l)\n",
    "    if gru_val_mae is not None:\n",
    "        y_true_g, y_pred_g = eval_sequence_model(model_gru, val_loader_seq, device=device)\n",
    "        seq_results['GRU'] = ms.regression_metrics(y_true_g, y_pred_g)\n",
    "    if tcn_val_mae is not None:\n",
    "        y_true_t, y_pred_t = eval_sequence_model(model_tcn, val_loader_seq, device=device)\n",
    "        seq_results['TCN'] = ms.regression_metrics(y_true_t, y_pred_t)\n",
    "\n",
    "print(\"Sequence results (val):\")\n",
    "print(pd.DataFrame(seq_results).transpose() if seq_results else \"No sequence results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada6807-328a-4eb0-aa7c-5542ae2ec5a5",
   "metadata": {},
   "source": [
    "### 3.11 Final Comparison Table (collect all results)\n",
    "Build a table summarizing MAE / RMSE / R2 for baselines, tabular, enriched, LGBM (if any), and sequence models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f402c4bc-55cf-45fa-b2fa-84e965bcc765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Persistence</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.991946</td>\n",
       "      <td>0.997717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>10.301333</td>\n",
       "      <td>14.395913</td>\n",
       "      <td>-0.564732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCN</td>\n",
       "      <td>17.073636</td>\n",
       "      <td>20.586895</td>\n",
       "      <td>-2.199951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>22.636562</td>\n",
       "      <td>25.065982</td>\n",
       "      <td>-3.743852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>22.709666</td>\n",
       "      <td>27.106362</td>\n",
       "      <td>-0.704642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>27.662711</td>\n",
       "      <td>31.649817</td>\n",
       "      <td>-1.323984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF+Iso</td>\n",
       "      <td>27.673071</td>\n",
       "      <td>31.669658</td>\n",
       "      <td>-1.326899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>75.386975</td>\n",
       "      <td>101.540923</td>\n",
       "      <td>-22.920647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MovingAvg</td>\n",
       "      <td>108.347475</td>\n",
       "      <td>110.318662</td>\n",
       "      <td>-27.235057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model         MAE        RMSE         R2\n",
       "0  Persistence    0.983956    0.991946   0.997717\n",
       "1         LSTM   10.301333   14.395913  -0.564732\n",
       "2          TCN   17.073636   20.586895  -2.199951\n",
       "3          GRU   22.636562   25.065982  -3.743852\n",
       "4     LightGBM   22.709666   27.106362  -0.704642\n",
       "5           RF   27.662711   31.649817  -1.323984\n",
       "6       RF+Iso   27.673071   31.669658  -1.326899\n",
       "7   ElasticNet   75.386975  101.540923 -22.920647\n",
       "8    MovingAvg  108.347475  110.318662 -27.235057"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "# persistence & moving avg (we computed earlier)\n",
    "if isinstance(metrics_persist.get(\"MAE\"), float) or not math.isnan(metrics_persist.get(\"MAE\", float('nan'))):\n",
    "    rows.append({\"Model\":\"Persistence\",\"MAE\":metrics_persist.get(\"MAE\"), \"RMSE\":metrics_persist.get(\"RMSE\"), \"R2\":metrics_persist.get(\"R2\")})\n",
    "rows.append({\"Model\":\"MovingAvg\",\"MAE\":metrics_ma[\"MAE\"], \"RMSE\":metrics_ma[\"RMSE\"], \"R2\":metrics_ma.get(\"R2\")})\n",
    "\n",
    "rows.append({\"Model\":\"ElasticNet\",\"MAE\":metrics_en[\"MAE\"], \"RMSE\":metrics_en[\"RMSE\"], \"R2\":metrics_en[\"R2\"]})\n",
    "rows.append({\"Model\":\"RF\",\"MAE\":metrics_rf[\"MAE\"], \"RMSE\":metrics_rf[\"RMSE\"], \"R2\":metrics_rf[\"R2\"]})\n",
    "rows.append({\"Model\":\"RF+Iso\",\"MAE\":metrics_rf_enriched[\"MAE\"], \"RMSE\":metrics_rf_enriched[\"RMSE\"], \"R2\":metrics_rf_enriched[\"R2\"]})\n",
    "\n",
    "if 'metrics_lgb' in globals():\n",
    "    rows.append({\"Model\":\"LightGBM\",\"MAE\":metrics_lgb[\"MAE\"], \"RMSE\":metrics_lgb[\"RMSE\"], \"R2\":metrics_lgb[\"R2\"]})\n",
    "\n",
    "# add sequence model metrics if available (we computed seq_results)\n",
    "if seq_results:\n",
    "    for m, met in seq_results.items():\n",
    "        rows.append({\"Model\": m, \"MAE\": met[\"MAE\"], \"RMSE\": met[\"RMSE\"], \"R2\": met[\"R2\"]})\n",
    "\n",
    "comp_df = pd.DataFrame(rows).sort_values(\"MAE\").reset_index(drop=True)\n",
    "display(comp_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d47c913-4142-4689-8f09-a3333541ee52",
   "metadata": {},
   "source": [
    "### Expand sequence features (richer temporal representation)\n",
    "We will:\n",
    "- Add short-window diffs (delta) and slope features (already present for some windows).\n",
    "- Add medium-window rstd (std) and short-window rstd if missing.\n",
    "- Add short-window exponential moving averages (EMA).\n",
    "- Ensure features are forward/backfilled per-unit (no NA).\n",
    "This expanded set usually helps sequence models (LSTM/GRU/TCN) learn finer temporal patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a805fe8-2ff7-437d-83d4-6719af78b701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before expansion, columns: 386\n",
      "After expansion, columns: 386\n",
      "New sequence features count: 170\n",
      "Sample sequence features: ['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10']\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Feature expansion: create additional sequence features (FIXED)\n",
    "# ===============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure train_df and test_df exist\n",
    "DATA_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SUBSET = globals().get(\"SUBSET\", \"FD001\")\n",
    "train_path = DATA_DIR / f\"train_{SUBSET}_final.csv\"\n",
    "test_path  = DATA_DIR / f\"test_{SUBSET}_final.csv\"\n",
    "\n",
    "if 'train_df' not in globals() or 'test_df' not in globals():\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Before expansion, columns:\", len(train_df.columns))\n",
    "\n",
    "# --- Helper: Correctly identify sensor columns ---\n",
    "# We explicitly list them or check against known format\n",
    "SENSOR_COLS_RAW = [f\"sensor_{i}\" for i in range(1, 22)]\n",
    "# Filter to keep only those present in df\n",
    "valid_sensors = [c for c in SENSOR_COLS_RAW if c in train_df.columns]\n",
    "\n",
    "def add_seq_features(df, sensors):\n",
    "    df = df.copy()\n",
    "    \n",
    "    for s in sensors:\n",
    "        # 1. Diff features (Velocity)\n",
    "        col_diff = f\"{s}_diff1\"\n",
    "        if col_diff not in df.columns:\n",
    "            # Calculate diff per unit\n",
    "            df[col_diff] = df.groupby(\"unit\")[s].diff().fillna(0)\n",
    "            \n",
    "        # 2. EMA short span (Fast Trend)\n",
    "        col_ema5 = f\"{s}_ema_5\"\n",
    "        if col_ema5 not in df.columns:\n",
    "            df[col_ema5] = df.groupby(\"unit\")[s].transform(lambda x: x.ewm(span=5, adjust=False).mean())\n",
    "            \n",
    "        # 3. Rolling Std (Volatility)\n",
    "        col_rstd15 = f\"{s}_rstd_15\"\n",
    "        if col_rstd15 not in df.columns:\n",
    "            df[col_rstd15] = df.groupby(\"unit\")[s].rolling(15, min_periods=1).std().reset_index(level=0, drop=True).fillna(0)\n",
    "            \n",
    "    # Ensure health_index exists\n",
    "    if 'health_index' not in df.columns:\n",
    "        df['health_index'] = df[sensors].mean(axis=1)\n",
    "        \n",
    "    # Global fillna just in case\n",
    "    df = df.groupby(\"unit\").apply(lambda g: g.bfill().ffill()).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Apply expansion\n",
    "train_df = add_seq_features(train_df, valid_sensors)\n",
    "test_df  = add_seq_features(test_df, valid_sensors)\n",
    "\n",
    "print(\"After expansion, columns:\", len(train_df.columns))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Update sequence_features list\n",
    "# ------------------------------------------------------------\n",
    "keep_patterns = [\n",
    "    r'^sensor_\\d+$',             # Raw sensors\n",
    "    r'^sensor_\\d+_rm_5$',        # Short rolling mean\n",
    "    r'^sensor_\\d+_rm_15$',       # Medium rolling mean\n",
    "    r'^sensor_\\d+_rm_60$',       # Long rolling mean\n",
    "    r'^sensor_\\d+_rstd_5$',      # Short volatility\n",
    "    r'^sensor_\\d+_rstd_15$',     # Medium volatility (NEW)\n",
    "    r'^sensor_\\d+_ema_5$',       # Fast trend (NEW)\n",
    "    r'^sensor_\\d+_diff1$',       # Velocity (NEW)\n",
    "    r'^health_index$',\n",
    "    r'^anom_score$'\n",
    "]\n",
    "\n",
    "def match_any(col):\n",
    "    return any(re.match(p, col) for p in keep_patterns)\n",
    "\n",
    "# Filter all columns to find sequence candidates\n",
    "all_cols = train_df.columns.tolist()\n",
    "sequence_features = [c for c in all_cols if match_any(c)]\n",
    "\n",
    "print(f\"New sequence features count: {len(sequence_features)}\")\n",
    "print(\"Sample sequence features:\", sequence_features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec0c62-889c-4e24-ab8f-a2c19be26a24",
   "metadata": {},
   "source": [
    "### LSTM Hyperparameter Tuning (Optuna)\n",
    "We will run an Optuna study to tune:\n",
    "- seq_len: [30, 120]\n",
    "- hidden_size: [32, 128]\n",
    "- num_layers: [1, 2]\n",
    "- dropout: [0.0, 0.3]\n",
    "- lr: [1e-4, 1e-2] (log)\n",
    "- batch_size: [16, 64]\n",
    "We will use a small number of trials initially (e.g. 12) to find a good region, then increase if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ab873ba-8c81-4e9d-9e47-3c36a1cc1dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:22:16,903] A new study created in memory with name: no-name-fbdf855d-3d71-439d-bce6-bdbad80589d7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ca7f8f15144a8ab04d6700d88035a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:22:17,291] Trial 0 finished with value: inf and parameters: {'seq_len': 114, 'hidden': 105, 'num_layers': 2, 'dropout': 0.014760606515730145, 'lr': 0.005573656703591355, 'batch_size': 16}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 22:22:18,661 INFO [SEQ] Epoch 00  val_MAE=14.0834\n",
      "2025-11-22 22:22:19,397 INFO [SEQ] Epoch 01  val_MAE=13.3949\n",
      "2025-11-22 22:22:20,197 INFO [SEQ] Epoch 02  val_MAE=13.5709\n",
      "2025-11-22 22:22:21,098 INFO [SEQ] Epoch 03  val_MAE=14.4802\n",
      "2025-11-22 22:22:21,961 INFO [SEQ] Epoch 04  val_MAE=15.9960\n",
      "2025-11-22 22:22:22,855 INFO [SEQ] Epoch 05  val_MAE=18.0422\n",
      "2025-11-22 22:22:23,822 INFO [SEQ] Epoch 06  val_MAE=20.4645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:22:23,852] Trial 1 finished with value: 13.394905261273655 and parameters: {'seq_len': 30, 'hidden': 79, 'num_layers': 2, 'dropout': 0.2721964755110721, 'lr': 0.0003069200633759078, 'batch_size': 64}. Best is trial 1 with value: 13.394905261273655.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 22:22:24,605 INFO [SEQ] Epoch 00  val_MAE=23.4040\n",
      "2025-11-22 22:22:24,963 INFO [SEQ] Epoch 01  val_MAE=49.2441\n",
      "2025-11-22 22:22:25,308 INFO [SEQ] Epoch 02  val_MAE=67.6755\n",
      "2025-11-22 22:22:25,709 INFO [SEQ] Epoch 03  val_MAE=32.5901\n",
      "2025-11-22 22:22:26,092 INFO [SEQ] Epoch 04  val_MAE=10.8717\n",
      "2025-11-22 22:22:26,500 INFO [SEQ] Epoch 05  val_MAE=8.9231\n",
      "2025-11-22 22:22:26,902 INFO [SEQ] Epoch 06  val_MAE=3.7434\n",
      "2025-11-22 22:22:27,299 INFO [SEQ] Epoch 07  val_MAE=4.3727\n",
      "2025-11-22 22:22:27,709 INFO [SEQ] Epoch 08  val_MAE=5.1001\n",
      "2025-11-22 22:22:28,112 INFO [SEQ] Epoch 09  val_MAE=10.8792\n",
      "2025-11-22 22:22:28,535 INFO [SEQ] Epoch 10  val_MAE=5.9844\n",
      "2025-11-22 22:22:28,941 INFO [SEQ] Epoch 11  val_MAE=11.5568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:22:28,972] Trial 2 finished with value: 3.7433974742889404 and parameters: {'seq_len': 99, 'hidden': 96, 'num_layers': 1, 'dropout': 0.20727359256103486, 'lr': 0.0036572787177240255, 'batch_size': 64}. Best is trial 2 with value: 3.7433974742889404.\n",
      "[I 2025-11-22 22:22:29,350] Trial 3 finished with value: inf and parameters: {'seq_len': 117, 'hidden': 94, 'num_layers': 1, 'dropout': 0.035359618736952404, 'lr': 0.00015618738936610177, 'batch_size': 64}. Best is trial 2 with value: 3.7433974742889404.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 22:22:30,536 INFO [SEQ] Epoch 00  val_MAE=17.8552\n",
      "2025-11-22 22:22:31,173 INFO [SEQ] Epoch 01  val_MAE=39.5056\n",
      "2025-11-22 22:22:31,854 INFO [SEQ] Epoch 02  val_MAE=60.1105\n",
      "2025-11-22 22:22:32,639 INFO [SEQ] Epoch 03  val_MAE=74.9442\n",
      "2025-11-22 22:22:33,275 INFO [SEQ] Epoch 04  val_MAE=84.5686\n",
      "2025-11-22 22:22:33,886 INFO [SEQ] Epoch 05  val_MAE=90.4824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:22:33,915] Trial 4 finished with value: 17.855185781206405 and parameters: {'seq_len': 57, 'hidden': 65, 'num_layers': 2, 'dropout': 0.23767933284609893, 'lr': 0.002474261230999069, 'batch_size': 64}. Best is trial 2 with value: 3.7433974742889404.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 22:22:34,858 INFO [SEQ] Epoch 00  val_MAE=20.4112\n",
      "2025-11-22 22:22:35,414 INFO [SEQ] Epoch 01  val_MAE=45.4354\n",
      "2025-11-22 22:22:35,918 INFO [SEQ] Epoch 02  val_MAE=66.0640\n",
      "2025-11-22 22:22:36,462 INFO [SEQ] Epoch 03  val_MAE=78.6278\n",
      "2025-11-22 22:22:36,981 INFO [SEQ] Epoch 04  val_MAE=85.7876\n",
      "2025-11-22 22:22:37,524 INFO [SEQ] Epoch 05  val_MAE=89.4488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:22:37,551] Trial 5 finished with value: 20.411226272583008 and parameters: {'seq_len': 75, 'hidden': 109, 'num_layers': 2, 'dropout': 0.20884883161942783, 'lr': 0.0020177912867089965, 'batch_size': 64}. Best is trial 2 with value: 3.7433974742889404.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 22:22:38,653 INFO [SEQ] Epoch 00  val_MAE=7.5861\n",
      "2025-11-22 22:22:39,455 INFO [SEQ] Epoch 01  val_MAE=7.5543\n",
      "2025-11-22 22:22:40,252 INFO [SEQ] Epoch 02  val_MAE=7.6812\n",
      "2025-11-22 22:22:41,033 INFO [SEQ] Epoch 03  val_MAE=7.7385\n",
      "2025-11-22 22:22:41,818 INFO [SEQ] Epoch 04  val_MAE=7.7754\n",
      "2025-11-22 22:22:42,565 INFO [SEQ] Epoch 05  val_MAE=7.8059\n",
      "2025-11-22 22:22:43,354 INFO [SEQ] Epoch 06  val_MAE=7.9676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:22:43,393] Trial 6 finished with value: 7.554283475875854 and parameters: {'seq_len': 80, 'hidden': 92, 'num_layers': 1, 'dropout': 0.08475972408638317, 'lr': 0.00013879352348867562, 'batch_size': 32}. Best is trial 2 with value: 3.7433974742889404.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 22:22:44,650 INFO [SEQ] Epoch 00  val_MAE=24.9910\n",
      "2025-11-22 22:22:45,487 INFO [SEQ] Epoch 01  val_MAE=52.9005\n",
      "2025-11-22 22:22:46,315 INFO [SEQ] Epoch 02  val_MAE=72.3662\n",
      "2025-11-22 22:22:47,148 INFO [SEQ] Epoch 03  val_MAE=82.5573\n",
      "2025-11-22 22:22:48,074 INFO [SEQ] Epoch 04  val_MAE=81.1315\n",
      "2025-11-22 22:22:48,989 INFO [SEQ] Epoch 05  val_MAE=57.4695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:22:49,044] Trial 7 finished with value: 24.9910306930542 and parameters: {'seq_len': 88, 'hidden': 40, 'num_layers': 2, 'dropout': 0.1876444975447715, 'lr': 0.0037819177427325344, 'batch_size': 32}. Best is trial 2 with value: 3.7433974742889404.\n",
      "[I 2025-11-22 22:22:49,356] Trial 8 finished with value: inf and parameters: {'seq_len': 113, 'hidden': 51, 'num_layers': 1, 'dropout': 0.06737296465174687, 'lr': 0.0018188899987237478, 'batch_size': 32}. Best is trial 2 with value: 3.7433974742889404.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 22:22:51,077 INFO [SEQ] Epoch 00  val_MAE=85.8168\n",
      "2025-11-22 22:22:52,469 INFO [SEQ] Epoch 01  val_MAE=91.4965\n",
      "2025-11-22 22:22:53,818 INFO [SEQ] Epoch 02  val_MAE=73.5231\n",
      "2025-11-22 22:22:55,172 INFO [SEQ] Epoch 03  val_MAE=79.9003\n",
      "2025-11-22 22:22:56,546 INFO [SEQ] Epoch 04  val_MAE=60.1335\n",
      "2025-11-22 22:22:57,831 INFO [SEQ] Epoch 05  val_MAE=66.0927\n",
      "2025-11-22 22:22:59,131 INFO [SEQ] Epoch 06  val_MAE=67.3663\n",
      "2025-11-22 22:23:00,536 INFO [SEQ] Epoch 07  val_MAE=56.9059\n",
      "2025-11-22 22:23:02,006 INFO [SEQ] Epoch 08  val_MAE=66.7704\n",
      "2025-11-22 22:23:03,449 INFO [SEQ] Epoch 09  val_MAE=62.1299\n",
      "2025-11-22 22:23:04,935 INFO [SEQ] Epoch 10  val_MAE=60.0003\n",
      "2025-11-22 22:23:06,373 INFO [SEQ] Epoch 11  val_MAE=62.5584\n",
      "2025-11-22 22:23:07,801 INFO [SEQ] Epoch 12  val_MAE=64.2515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:23:07,855] Trial 9 finished with value: 56.905921936035156 and parameters: {'seq_len': 91, 'hidden': 98, 'num_layers': 2, 'dropout': 0.29044392087707865, 'lr': 0.003493147910701567, 'batch_size': 16}. Best is trial 2 with value: 3.7433974742889404.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 22:23:08,979 INFO [SEQ] Epoch 00  val_MAE=45.9567\n",
      "2025-11-22 22:23:09,651 INFO [SEQ] Epoch 01  val_MAE=45.7902\n",
      "2025-11-22 22:23:10,255 INFO [SEQ] Epoch 02  val_MAE=42.7982\n",
      "2025-11-22 22:23:10,964 INFO [SEQ] Epoch 03  val_MAE=23.4949\n",
      "2025-11-22 22:23:11,679 INFO [SEQ] Epoch 04  val_MAE=9.2104\n",
      "2025-11-22 22:23:12,301 INFO [SEQ] Epoch 05  val_MAE=7.9422\n",
      "2025-11-22 22:23:12,883 INFO [SEQ] Epoch 06  val_MAE=7.9479\n",
      "2025-11-22 22:23:13,532 INFO [SEQ] Epoch 07  val_MAE=9.5855\n",
      "2025-11-22 22:23:14,136 INFO [SEQ] Epoch 08  val_MAE=9.0659\n",
      "2025-11-22 22:23:14,777 INFO [SEQ] Epoch 09  val_MAE=13.8015\n",
      "2025-11-22 22:23:15,368 INFO [SEQ] Epoch 10  val_MAE=12.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:23:15,398] Trial 10 finished with value: 7.942212200164795 and parameters: {'seq_len': 61, 'hidden': 128, 'num_layers': 1, 'dropout': 0.13830106043647858, 'lr': 0.009041610765135523, 'batch_size': 64}. Best is trial 2 with value: 3.7433974742889404.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 22:23:16,439 INFO [SEQ] Epoch 00  val_MAE=2.5313\n",
      "2025-11-22 22:23:17,047 INFO [SEQ] Epoch 01  val_MAE=7.5371\n",
      "2025-11-22 22:23:17,697 INFO [SEQ] Epoch 02  val_MAE=13.5499\n",
      "2025-11-22 22:23:18,357 INFO [SEQ] Epoch 03  val_MAE=18.5966\n",
      "2025-11-22 22:23:19,093 INFO [SEQ] Epoch 04  val_MAE=23.3525\n",
      "2025-11-22 22:23:19,731 INFO [SEQ] Epoch 05  val_MAE=27.9875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 22:23:19,756] Trial 11 finished with value: 2.531334400177002 and parameters: {'seq_len': 94, 'hidden': 79, 'num_layers': 1, 'dropout': 0.11373870488259177, 'lr': 0.00044219038201287177, 'batch_size': 32}. Best is trial 11 with value: 2.531334400177002.\n",
      "Optuna done. Best value: 2.531334400177002\n",
      "Best params: {'seq_len': 94, 'hidden': 79, 'num_layers': 1, 'dropout': 0.11373870488259177, 'lr': 0.00044219038201287177, 'batch_size': 32}\n",
      "Optuna tuning finished in 1.05 minutes\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Optuna tuning for LSTM (single-step RUL)\n",
    "# ===============================\n",
    "import numpy as np\n",
    "import optuna\n",
    "import time\n",
    "\n",
    "if torch is None:\n",
    "    raise RuntimeError(\"PyTorch not available in the environment â€” cannot tune LSTM.\")\n",
    "\n",
    "# Prepare function to build windows for given seq_len using ms.make_windows (which we have)\n",
    "def prepare_windows_for_indices(df_full, idx_train_rows, idx_val_rows, feature_cols, seq_len):\n",
    "    # idx_train_rows and idx_val_rows are row indices relative to full df (train_df)\n",
    "    train_df_local = df_full.iloc[idx_train_rows].reset_index(drop=True)\n",
    "    val_df_local   = df_full.iloc[idx_val_rows].reset_index(drop=True)\n",
    "    Xtr, ytr, _ = ms.make_windows(train_df_local, feature_cols, seq_len=seq_len)\n",
    "    Xva, yva, _ = ms.make_windows(val_df_local, feature_cols, seq_len=seq_len)\n",
    "    return Xtr, ytr, Xva, yva\n",
    "\n",
    "# Use earlier per-unit holdout (train_idx, val_idx) computed previously\n",
    "if 'train_idx' not in globals() or 'val_idx' not in globals():\n",
    "    train_idx, val_idx = ms.per_unit_holdout(train_df, holdout_frac=0.3)\n",
    "\n",
    "# Optuna objective using ms.train_sequence_model (generic trainer)\n",
    "def optuna_lstm_obj(trial):\n",
    "    seq_len = trial.suggest_int(\"seq_len\", 30, 120)\n",
    "    hidden = trial.suggest_int(\"hidden\", 32, 128)\n",
    "    layers = trial.suggest_int(\"num_layers\", 1, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    batch = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "\n",
    "    # prepare windows\n",
    "    Xtr, ytr, Xva, yva = None, None, None, None\n",
    "    try:\n",
    "        Xtr, ytr, Xva, yva = prepare_windows_for_indices(train_df, train_idx, val_idx, sequence_features, seq_len)\n",
    "    except Exception as e:\n",
    "        # if windows empty, return large value\n",
    "        return float(\"inf\")\n",
    "\n",
    "    if Xtr.shape[0] == 0 or Xva.shape[0] == 0:\n",
    "        return float(\"inf\")\n",
    "\n",
    "    train_loader = DataLoader(ms.SequenceDataset(Xtr, ytr), batch_size=batch, shuffle=True)\n",
    "    val_loader   = DataLoader(ms.SequenceDataset(Xva, yva), batch_size=batch, shuffle=False)\n",
    "\n",
    "    # model\n",
    "    model = ms.LSTMRegressor(n_features=len(sequence_features), hidden_size=hidden, num_layers=layers, dropout=dropout)\n",
    "\n",
    "    # train briefly\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    _, best_val = ms.train_sequence_model(model, train_loader, val_loader, lr=lr, epochs=20, patience=5, device=device)\n",
    "    return float(best_val)\n",
    "\n",
    "# Run study\n",
    "n_trials = 12   # start small â€” increase to 30-50 if time permits\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "start = time.time()\n",
    "study.optimize(optuna_lstm_obj, n_trials=n_trials, show_progress_bar=True)\n",
    "print(\"Optuna done. Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "elapsed = time.time() - start\n",
    "print(f\"Optuna tuning finished in {elapsed/60:.2f} minutes\")\n",
    "best_lstm_params = study.best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba98b404-aae1-4e76-950e-0a7bc708da48",
   "metadata": {},
   "source": [
    "### Retrain LSTM with the best hyperparameters found by Optuna\n",
    "We retrain on the outer training portion and evaluate on the validation set to get final metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff467eed-8bc0-444c-a8dd-ab439ba18927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 22:23:44,942 INFO [SEQ] Epoch 00  val_MAE=2.8965\n",
      "2025-11-22 22:23:45,415 INFO [SEQ] Epoch 01  val_MAE=1.4130\n",
      "2025-11-22 22:23:45,951 INFO [SEQ] Epoch 02  val_MAE=3.1464\n",
      "2025-11-22 22:23:46,482 INFO [SEQ] Epoch 03  val_MAE=6.0585\n",
      "2025-11-22 22:23:46,996 INFO [SEQ] Epoch 04  val_MAE=9.2946\n",
      "2025-11-22 22:23:47,648 INFO [SEQ] Epoch 05  val_MAE=12.7459\n",
      "2025-11-22 22:23:48,343 INFO [SEQ] Epoch 06  val_MAE=16.2824\n",
      "2025-11-22 22:23:48,989 INFO [SEQ] Epoch 07  val_MAE=19.7615\n",
      "2025-11-22 22:23:49,679 INFO [SEQ] Epoch 08  val_MAE=23.0432\n",
      "2025-11-22 22:23:50,330 INFO [SEQ] Epoch 09  val_MAE=25.9154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrained LSTM val metrics: {'MAE': 1.9654331833124161, 'RMSE': 2.9364395433019648, 'R2': 0.49763247600363236}\n",
      "Saved best LSTM state.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Retrain LSTM with best params and evaluate\n",
    "# ===============================\n",
    "import torch\n",
    "\n",
    "if torch is None:\n",
    "    print(\"PyTorch not available â€” skipping LSTM retrain.\")\n",
    "else:\n",
    "    bp = best_lstm_params\n",
    "    seq_len = int(bp.get(\"seq_len\", 50))\n",
    "    hidden = int(bp.get(\"hidden\", 64))\n",
    "    layers = int(bp.get(\"num_layers\", 1))\n",
    "    dropout = float(bp.get(\"dropout\", 0.0))\n",
    "    lr = float(bp.get(\"lr\", 1e-3))\n",
    "    batch = int(bp.get(\"batch_size\", 32))\n",
    "\n",
    "    # prepare windows\n",
    "    Xtr, ytr, Xva, yva = prepare_windows_for_indices(train_df, train_idx, val_idx, sequence_features, seq_len)\n",
    "\n",
    "    train_loader = DataLoader(ms.SequenceDataset(Xtr, ytr), batch_size=batch, shuffle=True)\n",
    "    val_loader   = DataLoader(ms.SequenceDataset(Xva, yva), batch_size=batch, shuffle=False)\n",
    "\n",
    "    model_best = ms.LSTMRegressor(n_features=len(sequence_features), hidden_size=hidden, num_layers=layers, dropout=dropout)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_best, best_val_mae = ms.train_sequence_model(model_best, train_loader, val_loader, lr=lr, epochs=50, patience=8, device=device)\n",
    "\n",
    "    # evaluate predictions on val windows\n",
    "    def eval_seq_model(model, loader):\n",
    "        preds, trues = [], []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in loader:\n",
    "                xb = xb.to(device)\n",
    "                out = model(xb)\n",
    "                preds.extend(out.cpu().numpy().tolist())\n",
    "                trues.extend(yb.numpy().tolist())\n",
    "        return np.array(trues), np.array(preds)\n",
    "\n",
    "    y_true_seq, y_pred_seq = eval_seq_model(model_best, val_loader)\n",
    "    seq_metrics = ms.regression_metrics(y_true_seq, y_pred_seq)\n",
    "    print(\"Retrained LSTM val metrics:\", seq_metrics)\n",
    "\n",
    "    # Save model for later ensemble\n",
    "    import torch\n",
    "    torch.save(model_best.state_dict(), f\"artifacts/models/lstm_best_{SUBSET}.pth\")\n",
    "    print(\"Saved best LSTM state.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610bdbbe-85aa-4e2f-af5e-c9ebe16b869b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
