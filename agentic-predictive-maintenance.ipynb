{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902a7186-2e68-403e-9622-84053bfbafc8",
   "metadata": {},
   "source": [
    "# Agentic Predictive Maintenance for Insured Assets\n",
    "---\n",
    "**Objective:** Develop an agentic predictive maintenance solution using time-series sensor data.\n",
    "\n",
    "**Core Components:**\n",
    "* **Data:** Time-series sensor data, policy data, and maintenance logs/manuals.\n",
    "* **Model:** Time-aware model selection (forecasting/classification) and hyperparameter tuning.\n",
    "* **Agent:** An AI agent combining deterministic checks, RAG (retrieval from manuals), and LLM reasoning to provide explainable maintenance recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1ec4a0-3ffc-43b3-b998-f243d9d1b38e",
   "metadata": {},
   "source": [
    "## Batch Processing: Full Pipeline for All Datasets (FD001-FD004)\n",
    "\n",
    "This cell executes the complete **Data Engineering Pipeline** for all four CMAPSS subsets.\n",
    "It orchestrates the modules we created earlier (`data_ingest`, `time_cleaning`, `feature_tools`, `scaling`).\n",
    "\n",
    "**Pipeline Logic per Dataset:**\n",
    "1.  **Ingest:** Loads raw text files, computes RUL, saves intermediate CSVs.\n",
    "2.  **Clean:** Aligns cycles, fills missing values (imputation), and caps outliers.\n",
    "3.  **Feature Engineering:** Generates temporal features (rolling mean/std, lag, trends) and anomaly indicators on the *physical* (unscaled) values.\n",
    "4.  **Scaling:**\n",
    "    * **FD001 & FD003:** Uses `Global Standardization` (single scaler).\n",
    "    * **FD002 & FD004:** Uses `Conditional Standardization` (clusters data by operating conditions first, then scales per cluster) to handle complex regimes.\n",
    "5.  **Save:** exports the final, model-ready data to `data/processed/CMAPSS/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea67e712-d29a-4150-85b0-70a5f5b9acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¢ Starting Batch Processing for All Subsets...\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD001\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD001 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD001\\train_FD001_raw.csv, data\\intermediate\\CMAPSS\\FD001\\test_FD001_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Global Standardization\n",
      "[scaling] Saved global scaler: artifacts\\scalers\\FD001_global_scaler.pkl\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD001 in 796.00 seconds.\n",
      "   Saved shape: Train (20631, 428), Test (13096, 428)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD002\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD002 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD002\\train_FD002_raw.csv, data\\intermediate\\CMAPSS\\FD002\\test_FD002_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Conditional Standardization (Clustering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.02310017 -0.02310017 -0.02310017 ... -0.02310017 -0.02310017\n",
      " -0.02310017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0326773 -0.0326773 -0.0326773 ... -0.0326773 -0.0326773 -0.0326773]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.06121538 -0.06121538 -0.06121538 ... -0.06121538 -0.06121538\n",
      " -0.06121538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03906578 -0.03906578 -0.03906578 ... -0.03906578 -0.03906578\n",
      " -0.03906578]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00872905 -0.00872905 -0.00872905 ... -0.00872905 -0.00872905\n",
      " -0.00872905]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.02310017 -0.02310017 -0.02310017 ... -0.02310017 -0.02310017\n",
      " -0.02310017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0326773 -0.0326773 -0.0326773 ... -0.0326773 -0.0326773 -0.0326773]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.06121538 -0.06121538 -0.06121538 ... -0.06121538 -0.06121538\n",
      " -0.06121538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03906578 -0.03906578 -0.03906578 ... -0.03906578 -0.03906578\n",
      " -0.03906578]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00872905 -0.00872905 -0.00872905 ... -0.00872905 -0.00872905\n",
      " -0.00872905]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scaling] Saved 6 cluster scalers and unit->cluster map for FD002\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD002 in 2404.56 seconds.\n",
      "   Saved shape: Train (53759, 429), Test (33991, 429)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD003\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD003 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD003\\train_FD003_raw.csv, data\\intermediate\\CMAPSS\\FD003\\test_FD003_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Global Standardization\n",
      "[scaling] Saved global scaler: artifacts\\scalers\\FD003_global_scaler.pkl\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD003 in 1117.04 seconds.\n",
      "   Saved shape: Train (24720, 428), Test (16596, 428)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD004\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD004 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD004\\train_FD004_raw.csv, data\\intermediate\\CMAPSS\\FD004\\test_FD004_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Conditional Standardization (Clustering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01730062 -0.01730062 -0.01730062 ... -0.01730062 -0.01730062\n",
      " -0.01730062]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.09715425 -0.09715425 -0.09715425 ... -0.09715425 -0.09715425\n",
      " -0.09715425]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03119965 -0.03119965 -0.03119965 ... -0.03119965 -0.03119965\n",
      " -0.03119965]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0561403 -0.0561403 -0.0561403 ... -0.0561403 -0.0561403 -0.0561403]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03772701 -0.03772701 -0.03772701 ... -0.03772701 -0.03772701\n",
      " -0.03772701]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0967612 -0.0967612 -0.0967612 ... -0.0967612 -0.0967612 -0.0967612]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01730062 -0.01730062 -0.01730062 ... -0.01730062 -0.01730062\n",
      " -0.01730062]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.09715425 -0.09715425 -0.09715425 ... -0.09715425 -0.09715425\n",
      " -0.09715425]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03119965 -0.03119965 -0.03119965 ... -0.03119965 -0.03119965\n",
      " -0.03119965]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0561403 -0.0561403 -0.0561403 ... -0.0561403 -0.0561403 -0.0561403]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03772701 -0.03772701 -0.03772701 ... -0.03772701 -0.03772701\n",
      " -0.03772701]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0967612 -0.0967612 -0.0967612 ... -0.0967612 -0.0967612 -0.0967612]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01140124 -0.01140124 -0.01140124 ... -0.01140124 -0.01140124\n",
      " -0.01140124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01140124 -0.01140124 -0.01140124 ... -0.01140124 -0.01140124\n",
      " -0.01140124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scaling] Saved 6 cluster scalers and unit->cluster map for FD004\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD004 in 2634.24 seconds.\n",
      "   Saved shape: Train (61249, 429), Test (41214, 429)\n",
      "\n",
      "ðŸŽ‰ðŸŽ‰ ALL DATASETS PROCESSED SUCCESSFULLY! ðŸŽ‰ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# --- 1. Suppress Warnings ---\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# 1. Import Your Modules\n",
    "from agentic_pm import data_ingest, time_cleaning, feature_tools, scaling\n",
    "\n",
    "# --- CONFIG ---\n",
    "SUBSETS = [\"FD001\", \"FD002\", \"FD003\", \"FD004\"]\n",
    "\n",
    "RAW_DIR = Path(\"data/raw/CMAPSS\")\n",
    "INTERMEDIATE_DIR = Path(\"data/intermediate/CMAPSS\")\n",
    "PROCESSED_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SCALER_DIR = Path(\"artifacts/scalers\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SCALER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def run_full_pipeline(subset_name):\n",
    "    \"\"\"\n",
    "    Runs the End-to-End Pipeline for a single subset:\n",
    "    Ingest -> Clean -> Feature Eng -> Scale -> Save\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"ðŸš€ Processing Subset: {subset_name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 1: INGEST (Load Raw & Compute RUL)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"1ï¸âƒ£ Ingesting data...\")\n",
    "    data_ingest.process_subset(subset_name, raw_base=RAW_DIR, out_base=INTERMEDIATE_DIR)\n",
    "    \n",
    "    # Load intermediate raw data\n",
    "    train_df = pd.read_csv(INTERMEDIATE_DIR / subset_name / f\"train_{subset_name}_raw.csv\")\n",
    "    test_df  = pd.read_csv(INTERMEDIATE_DIR / subset_name / f\"test_{subset_name}_raw.csv\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 2: CLEANING\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\")\n",
    "    train_df = time_cleaning.align_cycles(train_df)\n",
    "    train_df = time_cleaning.impute_missing(train_df)\n",
    "    train_df = time_cleaning.cap_outliers(train_df)\n",
    "\n",
    "    test_df = time_cleaning.align_cycles(test_df)\n",
    "    test_df = time_cleaning.impute_missing(test_df)\n",
    "    test_df = time_cleaning.cap_outliers(test_df)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 3: FEATURE ENGINEERING (On Physical Values)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"3ï¸âƒ£ Engineering Features...\")\n",
    "    # Train\n",
    "    train_df = feature_tools.create_temporal_features(train_df)\n",
    "    train_df = feature_tools.create_anomaly_indicators(train_df)\n",
    "    train_df = feature_tools.compute_health_index(train_df)\n",
    "    \n",
    "    # Test\n",
    "    test_df = feature_tools.create_temporal_features(test_df)\n",
    "    test_df = feature_tools.create_anomaly_indicators(test_df)\n",
    "    test_df = feature_tools.compute_health_index(test_df)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 4: SCALING (Prepare for ML Model)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"4ï¸âƒ£ Scaling features...\")\n",
    "    \n",
    "    # Identify feature columns (exclude metadata)\n",
    "    # We exclude 'unit', 'cycle', 'RUL', 'gap_flag' and the raw 'op_settings' if we want\n",
    "    # Usually we KEEP op_settings as features, but we scale them.\n",
    "    cols_to_exclude = ['unit', 'cycle', 'RUL', 'gap_flag', 'anom_score'] \n",
    "    # Note: 'anom_score' is 0-1 flag based, usually doesn't need scaling, but can be scaled.\n",
    "    # Let's include everything else.\n",
    "    feature_cols = [c for c in train_df.columns if c not in cols_to_exclude]\n",
    "\n",
    "    # Logic: FD001/FD003 -> Global Scaling\n",
    "    #        FD002/FD004 -> Conditional Scaling (due to multiple operating conditions)\n",
    "    if subset_name in [\"FD001\", \"FD003\"]:\n",
    "        print(f\"   -> Using Global Standardization\")\n",
    "        train_scaled, test_scaled, _ = scaling.global_standardize(\n",
    "            train_df, test_df, feature_cols, subset_name=subset_name\n",
    "        )\n",
    "    else:\n",
    "        print(f\"   -> Using Conditional Standardization (Clustering)\")\n",
    "        op_cols = [\"op_setting_1\", \"op_setting_2\", \"op_setting_3\"]\n",
    "        train_scaled, test_scaled, _, _ = scaling.conditional_standardize(\n",
    "            train_df, test_df, feature_cols, op_cols, subset_name=subset_name\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 5: SAVE FINAL DATA\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"5ï¸âƒ£ Saving final processed data...\")\n",
    "    final_train_path = PROCESSED_DIR / f\"train_{subset_name}_final.csv\"\n",
    "    final_test_path = PROCESSED_DIR / f\"test_{subset_name}_final.csv\"\n",
    "    \n",
    "    train_scaled.to_csv(final_train_path, index=False)\n",
    "    test_scaled.to_csv(final_test_path, index=False)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"âœ… Done with {subset_name} in {elapsed:.2f} seconds.\")\n",
    "    print(f\"   Saved shape: Train {train_scaled.shape}, Test {test_scaled.shape}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION LOOP\n",
    "# ==========================================\n",
    "print(\"ðŸ“¢ Starting Batch Processing for All Subsets...\")\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    try:\n",
    "        run_full_pipeline(subset)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ FAILED on {subset}: {e}\")\n",
    "        # Uncomment 'raise' if you want to stop the whole notebook on error\n",
    "        # raise e \n",
    "\n",
    "print(\"\\nðŸŽ‰ðŸŽ‰ ALL DATASETS PROCESSED SUCCESSFULLY! ðŸŽ‰ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d633a83-bb02-4e11-b372-c328302bde24",
   "metadata": {},
   "source": [
    "### Labeling & Problem Framing\n",
    "\n",
    "#### 1. Task Definition\n",
    "For this project, we explicitly define the prediction task as:\n",
    "\n",
    "- **(B) Remaining Useful Life (RUL) Regression**  \n",
    "  The model predicts the number of cycles remaining before the asset reaches end-of-life (failure threshold).  \n",
    "  Alternative tasks (A: time-to-failure regression, C: binary/multi-class maintenance classification) were considered but not selected for this iteration.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Assumptions\n",
    "- Each *cycle* in the CMAPSS dataset represents a consistent time step (uniform sampling frequency).  \n",
    "- The degradation process is monotonic toward failure within each unitâ€™s operational trajectory.  \n",
    "- Units in the training set run until failure; units in the test set are truncated before failure.  \n",
    "- Sensor measurements are assumed to be correctly calibrated and synchronized.  \n",
    "- No maintenance occurs during each unitâ€™s recorded run unless explicitly annotated.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Sampling Frequency\n",
    "- **Sampling interval:** One record per engine per cycle (i.e., *per-cycle sampling*).  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Label Generation Rules\n",
    "\n",
    "##### **Training Data**\n",
    "- Each unit runs until failure; therefore:\n",
    "  \n",
    "  \\[\n",
    "  RUL_{train}(unit, t) = \\text{max\\_cycle(unit)} - t\n",
    "  \\]\n",
    "\n",
    "##### **Test Data**\n",
    "- Test trajectories end before failure. Ground-truth final RUL values are provided separately.\n",
    "  \n",
    "  \\[\n",
    "  RUL_{test}(unit, t) = RUL_{given}(unit) + (\\text{final\\_cycle(unit)} - t)\n",
    "  \\]\n",
    "\n",
    "##### **Optional Enhancements**\n",
    "- Clip large RUL values (e.g., max 130 cycles) to stabilize model training.  \n",
    "- Apply transformations (e.g., `log1p(RUL)`) when using models sensitive to scale.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Example Asset Timelines (Annotated)\n",
    "\n",
    "Below we illustrate two example trajectories:\n",
    "\n",
    "1. **Training unit (full run):**\n",
    "   - Starts healthy, degrades over time, ends in a failure event.  \n",
    "   - RUL decreases linearly with respect to cycle index until reaching zero at the final cycle.\n",
    "\n",
    "2. **Test unit (truncated run):**\n",
    "   - Sequence ends before failure.  \n",
    "   - Final RUL label is assigned by combining the provided RUL file with the time remaining from the last observed cycle.\n",
    "\n",
    "These annotated timelines help verify label correctness, confirm continuity, and validate assumptions about degradation behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4811fd-658d-4687-9e9c-0cf1f84bd25a",
   "metadata": {},
   "source": [
    "# ðŸ“ Project Status Checkpoint: Data Pipeline & Feature Engineering\n",
    "\n",
    "At this stage, we have successfully implemented the **Data Engineering** and **Tool Definition** layers of our Agentic Predictive Maintenance system. Instead of raw processing within the notebook, we have modularized our code into the `agentic_pm` package for reproducibility and scalability.\n",
    "\n",
    "### Summary of Accomplishments:\n",
    "\n",
    "#### 1. Data Ingestion & Cleaning (Layer 1)\n",
    "We processed the raw CMAPSS datasets (FD001-FD004) through a rigorous cleaning pipeline:\n",
    "* **Ingestion:** Loaded raw text files and computed the **Remaining Useful Life (RUL)** target.\n",
    "* **Alignment:** Used `align_cycles` to create a continuous time index for each asset, handling missing timestamps.\n",
    "* **Imputation:** Filled sensor gaps using linear interpolation (`impute_missing`).\n",
    "* **Noise Reduction:** Applied a rolling Z-score filter (`cap_outliers`) to smooth extreme sensor spikes while retaining the signal.\n",
    "\n",
    "#### 2. Feature Engineering (Layer 2)\n",
    "We generated advanced features on the *cleaned physical values* (before normalization) to capture temporal dynamics:\n",
    "* **Temporal Features:** Rolling Means & Standard Deviations (window sizes 5, 15, 60), Exponential Moving Averages (EMA), and Lag features.\n",
    "* **Anomaly Indicators:** Computed Z-scores and change-point detection flags to highlight abnormal sensor behavior.\n",
    "* **Health Index:** Created a composite score combining weighted sensor values to represent overall asset health.\n",
    "\n",
    "#### 3. Agent Tools (Layer 3)\n",
    "We implemented deterministic tools that our AI Agent will call later:\n",
    "* **`diagnostic_checker`:** A rule-based tool that checks specific physical thresholds (e.g., *Temperature > 800Â°C*) to flag immediate risks.\n",
    "* **`maintenance_simulator`:** A \"what-if\" tool to simulate the impact of preventive maintenance on failure probability.\n",
    "\n",
    "#### 4. Scaling & Normalization (Layer 4)\n",
    "To prepare the data for Machine Learning models, we applied dataset-specific scaling:\n",
    "* **Global Standardization:** Applied to **FD001 & FD003** (single operating condition).\n",
    "* **Conditional Standardization:** Applied to **FD002 & FD004** (multiple operating conditions), using KMeans clustering to normalize data within specific operating regimes.\n",
    "\n",
    "---\n",
    "**âœ… Current State:** Cleaned, feature-engineered, and normalized datasets are saved in `data/processed/CMAPSS/`.\n",
    "**ðŸ‘‰ Next Step:** We will now proceed to **Step 3: Model Selection**, where we will train and evaluate models (XGBoost, etc.) using time-aware validation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111447f4-09ec-4058-b602-b7ca1d494e08",
   "metadata": {},
   "source": [
    "## 3. Model Selection, Hyperparameter Tuning & Evaluation\n",
    "\n",
    "CMAPSS Predictive Maintenance â€” Full Modeling Pipeline\n",
    "\n",
    "Tabular + Sequence Models + Anomaly Detection + Comparison\n",
    "\n",
    "This notebook uses the final processed datasets created by the preprocessing pipeline:\n",
    "   data/processed/CMAPSS/train_FD00X_final.csv\n",
    "   data/processed/CMAPSS/test_FD00X_final.csv\n",
    "\n",
    "It evaluates:\n",
    "- Classical tabular models (RandomForest, ElasticNet, LightGBM)\n",
    "- Sequence models (LSTM, GRU, Mini-TCN)\n",
    "- Anomaly model (IsolationForest) and using its score as a feature\n",
    "- Comparison table summarizing metrics\n",
    "\n",
    "### 3.1 Import & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12648b07-24ad-4a12-a0b5-c34f5504d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready. Torch: True LightGBM: True Optuna: True\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# modeling utilities we created\n",
    "from agentic_pm.modeling import model_selection as ms\n",
    "\n",
    "# optional libs - we'll check availability\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "except Exception:\n",
    "    optuna = None\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "except Exception:\n",
    "    torch = None\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import joblib\n",
    "\n",
    "print(\"Environment ready. Torch:\", bool(torch), \"LightGBM:\", bool(lgb), \"Optuna:\", bool(optuna))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40bc9c0-667c-4458-b995-47d914200573",
   "metadata": {},
   "source": [
    "### 3.2 Load Final Datasets\n",
    "Choose subset (FD001..FD004) and load the final train/test CSVs produced by your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d14d73-e549-4276-9309-b3821c56a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files:\n",
      " - data\\processed\\CMAPSS\\train_FD001_final.csv (20631, 428)\n",
      " - data\\processed\\CMAPSS\\test_FD001_final.csv (13096, 428)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>unit</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_13_norm_unit</th>\n",
       "      <th>sensor_14_norm_unit</th>\n",
       "      <th>sensor_15_norm_unit</th>\n",
       "      <th>sensor_16_norm_unit</th>\n",
       "      <th>sensor_17_norm_unit</th>\n",
       "      <th>sensor_18_norm_unit</th>\n",
       "      <th>sensor_19_norm_unit</th>\n",
       "      <th>sensor_20_norm_unit</th>\n",
       "      <th>sensor_21_norm_unit</th>\n",
       "      <th>health_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.315980</td>\n",
       "      <td>-1.372953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.721725</td>\n",
       "      <td>-0.134255</td>\n",
       "      <td>-0.925936</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278164</td>\n",
       "      <td>1.997798</td>\n",
       "      <td>-0.380157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.354811</td>\n",
       "      <td>1.317629</td>\n",
       "      <td>-0.534520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872722</td>\n",
       "      <td>-1.031720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.061780</td>\n",
       "      <td>0.211528</td>\n",
       "      <td>-0.643726</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636957</td>\n",
       "      <td>1.072544</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991643</td>\n",
       "      <td>1.360548</td>\n",
       "      <td>-0.438211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.961874</td>\n",
       "      <td>1.015677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-0.413166</td>\n",
       "      <td>-0.525953</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.149922</td>\n",
       "      <td>1.298342</td>\n",
       "      <td>-0.435259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.053313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689003</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>-0.618248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324090</td>\n",
       "      <td>-0.008022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-1.261314</td>\n",
       "      <td>-0.784831</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508715</td>\n",
       "      <td>1.376204</td>\n",
       "      <td>-2.042955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265307</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>-0.765705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.864611</td>\n",
       "      <td>-0.690488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621816</td>\n",
       "      <td>-1.251528</td>\n",
       "      <td>-0.301518</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021681</td>\n",
       "      <td>1.372310</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.223972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386363</td>\n",
       "      <td>1.181405</td>\n",
       "      <td>-0.317219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cycle  unit  op_setting_1  op_setting_2  op_setting_3  sensor_1  sensor_2  \\\n",
       "0      1     1     -0.315980     -1.372953           0.0       0.0 -1.721725   \n",
       "1      2     1      0.872722     -1.031720           0.0       0.0 -1.061780   \n",
       "2      3     1     -1.961874      1.015677           0.0       0.0 -0.661813   \n",
       "3      4     1      0.324090     -0.008022           0.0       0.0 -0.661813   \n",
       "4      5     1     -0.864611     -0.690488           0.0       0.0 -0.621816   \n",
       "\n",
       "   sensor_3  sensor_4      sensor_5  ...  sensor_13_norm_unit  \\\n",
       "0 -0.134255 -0.925936 -5.329071e-15  ...            -1.278164   \n",
       "1  0.211528 -0.643726 -5.329071e-15  ...            -0.636957   \n",
       "2 -0.413166 -0.525953 -5.329071e-15  ...            -1.149922   \n",
       "3 -1.261314 -0.784831 -5.329071e-15  ...            -0.508715   \n",
       "4 -1.251528 -0.301518 -5.329071e-15  ...            -1.021681   \n",
       "\n",
       "   sensor_14_norm_unit  sensor_15_norm_unit  sensor_16_norm_unit  \\\n",
       "0             1.997798            -0.380157                  0.0   \n",
       "1             1.072544             0.018526                  0.0   \n",
       "2             1.298342            -0.435259                  0.0   \n",
       "3             1.376204            -2.042955                  0.0   \n",
       "4             1.372310            -0.059266                  0.0   \n",
       "\n",
       "   sensor_17_norm_unit  sensor_18_norm_unit  sensor_19_norm_unit  \\\n",
       "0            -0.833752                  0.0                  0.0   \n",
       "1            -0.833752                  0.0                  0.0   \n",
       "2            -2.053313                  0.0                  0.0   \n",
       "3            -0.833752                  0.0                  0.0   \n",
       "4            -0.223972                  0.0                  0.0   \n",
       "\n",
       "   sensor_20_norm_unit  sensor_21_norm_unit  health_index  \n",
       "0             1.354811             1.317629     -0.534520  \n",
       "1             0.991643             1.360548     -0.438211  \n",
       "2             0.689003             0.619718     -0.618248  \n",
       "3             0.265307             0.896829     -0.765705  \n",
       "4             0.386363             1.181405     -0.317219  \n",
       "\n",
       "[5 rows x 428 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SUBSET = \"FD001\"   # change if you want FD002/FD003/FD004\n",
    "\n",
    "train_path = DATA_DIR / f\"train_{SUBSET}_final.csv\"\n",
    "test_path  = DATA_DIR / f\"test_{SUBSET}_final.csv\"\n",
    "\n",
    "assert train_path.exists(), f\"Train file missing: {train_path}\"\n",
    "assert test_path.exists(),  f\"Test file missing: {test_path}\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Loaded files:\")\n",
    "print(\" -\", train_path, train_df.shape)\n",
    "print(\" -\", test_path, test_df.shape)\n",
    "display(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532787d-1ab6-4966-aad0-8292de4df389",
   "metadata": {},
   "source": [
    "### 3.3 Basic sanity checks\n",
    "Check RUL, missing values, and columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c783d5d-68cc-4622-b47c-65145f2e5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUL range (train): 0 361\n",
      "Nulls per column (train):\n",
      "sensor_21_lag_6    600\n",
      "sensor_20_lag_6    600\n",
      "sensor_19_lag_6    600\n",
      "sensor_18_lag_6    600\n",
      "sensor_17_lag_6    600\n",
      "sensor_16_lag_6    600\n",
      "sensor_15_lag_6    600\n",
      "sensor_14_lag_6    600\n",
      "sensor_13_lag_6    600\n",
      "sensor_12_lag_6    600\n",
      "dtype: int64\n",
      "Total columns: 428\n",
      "Sample columns: ['cycle', 'unit', 'op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15', 'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19', 'sensor_20', 'sensor_21', 'RUL', 'sensor_1_rm_5', 'sensor_1_rstd_5', 'sensor_1_slope_5']\n"
     ]
    }
   ],
   "source": [
    "# sanity\n",
    "print(\"RUL range (train):\", train_df[\"RUL\"].min(), train_df[\"RUL\"].max())\n",
    "print(\"Nulls per column (train):\")\n",
    "print(train_df.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# list of columns\n",
    "cols = train_df.columns.tolist()\n",
    "print(\"Total columns:\", len(cols))\n",
    "print(\"Sample columns:\", cols[:30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30c882-a0f5-44c3-8dbe-45ed6238ece7",
   "metadata": {},
   "source": [
    "### 3.4 Feature Selection\n",
    "We have too many features. We need feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fddf6210-5ef1-42d9-bdbc-d1196b70cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning feature space...\n",
      "Removing lag columns: 63 columns removed\n",
      "NaN fix complete:\n",
      "cycle           0\n",
      "unit            0\n",
      "op_setting_1    0\n",
      "op_setting_2    0\n",
      "op_setting_3    0\n",
      "dtype: int64\n",
      " Tabular features selected: 125\n",
      "Sequence features selected: 29\n",
      "Examples (tabular): ['anom_score', 'health_index', 'op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_10_slope_15', 'sensor_11_rm_15', 'sensor_11_rm_60', 'sensor_11_slope_15', 'sensor_11_slope_5']\n",
      "Examples (sequence): ['anom_score', 'health_index', 'sensor_11_rm_15', 'sensor_11_rm_60', 'sensor_13', 'sensor_13_rm_5', 'sensor_13_rstd_5', 'sensor_14_rm_15', 'sensor_14_rm_5', 'sensor_15_rm_5']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5) Feature Cleanup & Selection (Tabular + Sequence)\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Cleaning feature space...\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Drop all lag columns (lag features cause NaN at sequence start)\n",
    "# ------------------------------------------------------------\n",
    "lag_cols = [c for c in train_df.columns if \"_lag_\" in c]\n",
    "print(f\"Removing lag columns: {len(lag_cols)} columns removed\")\n",
    "train_df = train_df.drop(columns=lag_cols)\n",
    "test_df  = test_df.drop(columns=lag_cols)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Fix NaN values (per-unit backfill â†’ forward fill)\n",
    "# ------------------------------------------------------------\n",
    "def fix_nans(df):\n",
    "    return (df.groupby(\"unit\")\n",
    "              .apply(lambda g: g.bfill().ffill())\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "train_df = fix_nans(train_df)\n",
    "test_df  = fix_nans(test_df)\n",
    "\n",
    "print(\"NaN fix complete:\")\n",
    "print(train_df.isna().sum().sort_values(ascending=False).head(5))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Construct tabular feature list\n",
    "# ------------------------------------------------------------\n",
    "META_EXCLUDE = {\"unit\", \"cycle\", \"RUL\", \"gap_flag\"}\n",
    "\n",
    "all_features = [c for c in train_df.columns if c not in META_EXCLUDE]\n",
    "\n",
    "# Variance filtering: keep top-k highest variance features\n",
    "k = 120\n",
    "variances = train_df[all_features].var().sort_values(ascending=False)\n",
    "topk = list(variances.index[:k])\n",
    "\n",
    "# Always keep key domain indicators\n",
    "domain_keep = [\n",
    "    \"health_index\",\n",
    "    \"anom_score\",\n",
    "    \"op_setting_1\",\n",
    "    \"op_setting_2\",\n",
    "    \"op_setting_3\"\n",
    "]\n",
    "domain_keep = [c for c in domain_keep if c in train_df.columns]\n",
    "\n",
    "tabular_features = sorted(set(topk + domain_keep))\n",
    "\n",
    "print(f\" Tabular features selected: {len(tabular_features)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Build sequence features (reduced set for LSTM/TCN efficiency)\n",
    "# ------------------------------------------------------------\n",
    "keep_patterns = [\n",
    "    r'^sensor_\\d+$',        # raw sensor values\n",
    "    r'^sensor_\\d+_rm_5$',   # short rolling means\n",
    "    r'^sensor_\\d+_rm_15$',\n",
    "    r'^sensor_\\d+_rm_60$',\n",
    "    r'^sensor_\\d+_rstd_5$', # short rolling std\n",
    "    r'^health_index$',      # degradation signal\n",
    "    r'^anom_score$'         # anomaly indicator\n",
    "]\n",
    "\n",
    "def match_any(col):\n",
    "    return any(re.match(p, col) for p in keep_patterns)\n",
    "\n",
    "sequence_features = [c for c in tabular_features if match_any(c)]\n",
    "\n",
    "# fallback if pattern too restrictive\n",
    "if len(sequence_features) < 12:\n",
    "    sequence_features = tabular_features[:40]\n",
    "\n",
    "print(f\"Sequence features selected: {len(sequence_features)}\")\n",
    "\n",
    "# Show samples\n",
    "print(\"Examples (tabular):\", tabular_features[:10])\n",
    "print(\"Examples (sequence):\", sequence_features[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91582f00-25ad-4ce3-8dd7-1a3a6e04bb27",
   "metadata": {},
   "source": [
    "### 3.5 Train/Validation Split (per-unit holdout)\n",
    "Use per-unit holdout (last portion of cycles per unit) to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3213aca3-57af-41a9-b62a-db7f4af78614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 14398 Val rows: 6233\n"
     ]
    }
   ],
   "source": [
    "# Get row indices for per-unit holdout\n",
    "train_idx, val_idx = ms.per_unit_holdout(train_df, holdout_frac=0.3)\n",
    "print(\"Train rows:\", len(train_idx), \"Val rows:\", len(val_idx))\n",
    "\n",
    "# Prepare arrays for tabular models\n",
    "X = train_df[tabular_features].values\n",
    "y = train_df[\"RUL\"].values\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_val   = X[val_idx]\n",
    "y_train = y[train_idx]\n",
    "y_val   = y[val_idx]\n",
    "\n",
    "# Standardize features for sklearn models (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25499f5-13bf-491e-ad61-c8678c7f305c",
   "metadata": {},
   "source": [
    "### 3.6 Baselines (Persistence & Moving-average linear map)\n",
    "Evaluate leakage-free baselines to anchor model expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d17d5b-de55-442f-ab7c-e4c298faa763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence baseline (shifted) metrics: {'MAE': 0.9839563613027434, 'RMSE': 0.9919457451407024, 'R2': 0.9977172069450396}\n",
      "Moving-average baseline metrics: {'MAE': 108.3474749721799, 'RMSE': 110.31866168564305, 'R2': -27.23505734065863}\n"
     ]
    }
   ],
   "source": [
    "# Baseline: persistence (shifted)\n",
    "y_val_persist = ms.baseline_persistence_shift(train_df.iloc[val_idx])  # make sure method accepts dataframe slice\n",
    "# The baseline impl may expect full df aligned; use ms.baseline_persistence_shift on the val slice\n",
    "# We need y_true for validation rows:\n",
    "y_true = y[val_idx]\n",
    "\n",
    "# For moving-average baseline: fit on train_df and predict on validation portion of train_df (or test later)\n",
    "# Here demonstrate using same split: compute on rows corresponding to val_idx (they are rows in train_df)\n",
    "ma_preds = ms.baseline_ma_linear_map(train_df.iloc[train_idx], train_df.iloc[val_idx], sensor_col=\"sensor_1\", window=10)\n",
    "\n",
    "# Evaluate\n",
    "try:\n",
    "    metrics_persist = ms.regression_metrics(y_true, y_val_persist)\n",
    "except Exception:\n",
    "    # fallback compute on simple approach (if shapes mismatch)\n",
    "    metrics_persist = {\"MAE\": float(\"nan\"), \"RMSE\": float(\"nan\"), \"R2\": float(\"nan\")}\n",
    "\n",
    "metrics_ma = ms.regression_metrics(y_true, ma_preds)\n",
    "\n",
    "print(\"Persistence baseline (shifted) metrics:\", metrics_persist)\n",
    "print(\"Moving-average baseline metrics:\", metrics_ma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7d964b-7d29-470e-a98d-adbec1b8b66f",
   "metadata": {},
   "source": [
    "### 3.7 Tabular Model\n",
    "#### 3.7.1 Random Forest\n",
    "Train a RandomForest on the standardized tabular features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6250ca-0efa-410e-b5d6-a1236c4e23d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF metrics: {'MAE': 27.662710956963686, 'RMSE': 31.64981748161584, 'R2': -1.323983950866963}\n",
      "Precision@100 (rf): 0.02\n",
      "Early-warning@7 (rf): 0.0\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\"n_estimators\":200, \"max_depth\":12, \"min_samples_leaf\":2}\n",
    "rf = ms.fit_random_forest(X_train_s, y_train, params=rf_params)\n",
    "y_val_pred_rf = rf.predict(X_val_s)\n",
    "metrics_rf = ms.regression_metrics(y_val, y_val_pred_rf)\n",
    "print(\"RF metrics:\", metrics_rf)\n",
    "print(\"Precision@100 (rf):\", ms.precision_at_k_rul(y_val, y_val_pred_rf, k=100))\n",
    "print(\"Early-warning@7 (rf):\", ms.early_warning_rate(train_df.iloc[val_idx], y_val, y_val_pred_rf, lead=7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca54c92-bc09-4452-842a-0d580f291ddb",
   "metadata": {},
   "source": [
    "#### 3.7.2 ElasticNet\n",
    "Train a regularized linear model (ElasticNet) for benchmarking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d80abf9-3e7f-4e02-ae2e-38607af6e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet metrics: {'MAE': 75.38697489734093, 'RMSE': 101.54092259576085, 'R2': -22.920646601780117}\n",
      "Precision@100 (en): 0.22\n"
     ]
    }
   ],
   "source": [
    "en_params = {\"alpha\": 0.01, \"l1_ratio\": 0.2}\n",
    "en = ms.fit_elasticnet(X_train_s, y_train, params=en_params)\n",
    "y_val_pred_en = en.predict(X_val_s)\n",
    "metrics_en = ms.regression_metrics(y_val, y_val_pred_en)\n",
    "print(\"ElasticNet metrics:\", metrics_en)\n",
    "print(\"Precision@100 (en):\", ms.precision_at_k_rul(y_val, y_val_pred_en, k=100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50518fe6-df5c-480e-8fdf-9e6829086f37",
   "metadata": {},
   "source": [
    "#### 3.7.3 LightGBM (version-safe)\n",
    "Train LightGBM using ms.fit_lightgbm. If LightGBM not installed, skip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ae24fe-8142-4a46-8b9a-b68142fcdf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's l1: 22.7097\n",
      "LightGBM metrics: {'MAE': 22.709666182561556, 'RMSE': 27.10636182058728, 'R2': -0.7046419305422893}\n",
      "Precision@100 (lgb): 0.0\n",
      "Early-warning@7 (lgb): 0.0\n"
     ]
    }
   ],
   "source": [
    "if lgb is None:\n",
    "    print(\"LightGBM not installed â€” skipping LGBM.\")\n",
    "else:\n",
    "    lgb_params = {\"objective\":\"regression\", \"metric\":\"mae\", \"learning_rate\":0.05, \"num_leaves\":48, \"verbosity\":-1}\n",
    "    try:\n",
    "        lgb_model, lgb_info = ms.fit_lightgbm(X_train_s, y_train, X_val_s, y_val, params=lgb_params, rounds=1000, early=50)\n",
    "        y_val_pred_lgb = lgb_model.predict(X_val_s)\n",
    "        metrics_lgb = ms.regression_metrics(y_val, y_val_pred_lgb)\n",
    "        print(\"LightGBM metrics:\", metrics_lgb)\n",
    "        print(\"Precision@100 (lgb):\", ms.precision_at_k_rul(y_val, y_val_pred_lgb, k=100))\n",
    "        print(\"Early-warning@7 (lgb):\", ms.early_warning_rate(train_df.iloc[val_idx], y_val, y_val_pred_lgb, lead=7))\n",
    "    except Exception as e:\n",
    "        print(\"LightGBM training error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354ecdf-92df-4332-a83b-28ca332c1817",
   "metadata": {},
   "source": [
    "### 3.8 Anomaly Model: IsolationForest\n",
    "Fit IsolationForest on training features, compute anomaly score for train/val and optionally add as a feature for model retraining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793b057a-0150-4201-ab7d-fb8ee87746a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly score (train) stats: 0.3509437643130367 0.6964313243918464 0.4067106093380277\n",
      "Anomaly score (val)   stats: 0.3635086542925437 0.6586642447075471 0.49786727881221426\n",
      "RF enriched (with anomaly) metrics: {'MAE': 27.67307100422802, 'RMSE': 31.669657734252304, 'R2': -1.326898525693852}\n"
     ]
    }
   ],
   "source": [
    "iso = IsolationForest(contamination=0.02, random_state=42)\n",
    "iso.fit(X_train_s)\n",
    "train_anom = iso.score_samples(X_train_s)   # higher = less anomalous; we can invert\n",
    "val_anom   = iso.score_samples(X_val_s)\n",
    "\n",
    "# Invert to get anomaly magnitude (higher means more anomalous)\n",
    "train_anom_score = -train_anom\n",
    "val_anom_score = -val_anom\n",
    "\n",
    "print(\"Anomaly score (train) stats:\", np.nanmin(train_anom_score), np.nanmax(train_anom_score), np.nanmean(train_anom_score))\n",
    "print(\"Anomaly score (val)   stats:\", np.nanmin(val_anom_score), np.nanmax(val_anom_score), np.nanmean(val_anom_score))\n",
    "\n",
    "# Optionally attach to features and retrain RF quickly to see impact\n",
    "X_train_enriched = np.hstack([X_train_s, train_anom_score.reshape(-1,1)])\n",
    "X_val_enriched   = np.hstack([X_val_s, val_anom_score.reshape(-1,1)])\n",
    "\n",
    "rf_enriched = ms.fit_random_forest(X_train_enriched, y_train, params=rf_params)\n",
    "y_val_pred_rf_enriched = rf_enriched.predict(X_val_enriched)\n",
    "metrics_rf_enriched = ms.regression_metrics(y_val, y_val_pred_rf_enriched)\n",
    "print(\"RF enriched (with anomaly) metrics:\", metrics_rf_enriched)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96237ab1-6a54-4f8e-bdf4-a4b4956ea1b8",
   "metadata": {},
   "source": [
    "### 3.9 Sequence pipeline (unit-level split â†’ windowing â†’ train LSTM/GRU/TCN)\n",
    "This section:\n",
    "- Creates a **unit-level train/val split** (no leakage).\n",
    "- Builds sliding windows for sequence models.\n",
    "- Trains LSTM / GRU / a small TCN with a generic training loop.\n",
    "- Optionally runs a short Optuna tuning loop for LSTM.\n",
    "- Evaluates and saves the best sequence model.\n",
    "Notes:\n",
    "- Use `seq_len` = 50â€“120 depending on memory (we'll use 94 by default).\n",
    "- If you have GPU, set device = \"cuda\" for speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79e189ce-0e05-4fe6-ae62-640a3bb50c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files exist: True True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# B2: Imports and configuration\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# modeling utilities (make sure agentic_pm.modeling.model_selection is in your PYTHONPATH)\n",
    "from agentic_pm.modeling.model_selection import (\n",
    "    make_windows,\n",
    "    LSTMRegressor,\n",
    "    GRURegressor,\n",
    "    MiniTCN,\n",
    "    SequenceDataset,\n",
    "    train_sequence_model,\n",
    "    regression_metrics\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Paths & subset\n",
    "DATA_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SUBSET = \"FD001\"\n",
    "TRAIN_PATH = DATA_DIR / f\"train_{SUBSET}_final.csv\"\n",
    "TEST_PATH  = DATA_DIR / f\"test_{SUBSET}_final.csv\"\n",
    "\n",
    "print(\"files exist:\", TRAIN_PATH.exists(), TEST_PATH.exists())\n",
    "\n",
    "# hyperparams (tune these)\n",
    "SEQ_LEN = 94          # window length (as you used before)\n",
    "BATCH = 32\n",
    "EPOCHS = 40\n",
    "PATIENCE = 6\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "399b460b-1cf8-4d76-b833-f88fc1407579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation units: [np.int64(99), np.int64(100)]\n",
      "Train units: 98 Val units: 2\n"
     ]
    }
   ],
   "source": [
    "# B3: Load processed train and produce unit-level split (no leakage for sequence)\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# Choose validation units (hold out complete units). Pick last N units or specific ids.\n",
    "# Example: hold out 2 units for validation\n",
    "VAL_UNITS = sorted(train_df[\"unit\"].unique())[-2:]  # last 2 units\n",
    "print(\"Validation units:\", VAL_UNITS)\n",
    "\n",
    "train_units_df = train_df[~train_df[\"unit\"].isin(VAL_UNITS)].reset_index(drop=True)\n",
    "val_units_df   = train_df[ train_df[\"unit\"].isin(VAL_UNITS)].reset_index(drop=True)\n",
    "print(\"Train units:\", train_units_df[\"unit\"].nunique(), \"Val units:\", val_units_df[\"unit\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a86adb5f-02c0-4ee6-bcea-8e201d61d31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence features: 107\n",
      "['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15', 'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19', 'sensor_20']\n"
     ]
    }
   ],
   "source": [
    "# Select sequence features (from earlier created sequence_features or fallback)\n",
    "# Use precomputed list if available; else build heuristics:\n",
    "import re\n",
    "\n",
    "# Only features guaranteed to exist in final dataset\n",
    "PATTERNS = [\n",
    "    r'^sensor_\\d+$',\n",
    "    r'^sensor_\\d+_rm_5$',\n",
    "    r'^sensor_\\d+_rm_15$',\n",
    "    r'^sensor_\\d+_rm_60$',\n",
    "    r'^sensor_\\d+_rstd_5$',\n",
    "    r'^health_index$',\n",
    "    r'^anom_score$'\n",
    "]\n",
    "\n",
    "def matches_any(col):\n",
    "    return any(re.match(p, col) for p in PATTERNS)\n",
    "\n",
    "sequence_features = [c for c in train_df.columns if matches_any(c)]\n",
    "\n",
    "print(\"Sequence features:\", len(sequence_features))\n",
    "print(sequence_features[:20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a124511-bf05-4a64-9be3-49ea58b37a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: (11132, 94, 107) Val windows: (199, 94, 107)\n"
     ]
    }
   ],
   "source": [
    "# Build windows for train and val, create DataLoader\n",
    "SEQ_LEN = SEQ_LEN\n",
    "\n",
    "Xtr, ytr, _ = make_windows(train_units_df, sequence_features, seq_len=SEQ_LEN)\n",
    "Xva, yva, _ = make_windows(val_units_df, sequence_features, seq_len=SEQ_LEN)\n",
    "\n",
    "print(\"Train windows:\", Xtr.shape, \"Val windows:\", Xva.shape)\n",
    "\n",
    "train_loader = DataLoader(SequenceDataset(Xtr, ytr), batch_size=BATCH, shuffle=True)\n",
    "val_loader   = DataLoader(SequenceDataset(Xva, yva), batch_size=BATCH, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d6797-d148-48d8-b0f3-c787b3147605",
   "metadata": {},
   "source": [
    "### Train sequence models\n",
    "We will train three lightweight sequence models:\n",
    "- LSTM (default best performing)\n",
    "- GRU (for comparison)\n",
    "- MiniTCN (light conv-based)\n",
    "We use the same `train_sequence_model` which performs MAE training + early stopping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aaf4763d-9e40-4662-baee-222ee4a4803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 00:57:59,343 INFO [SEQ] Epoch 00  val_MAE=32.1221\n",
      "2025-11-23 00:58:00,653 INFO [SEQ] Epoch 01  val_MAE=25.4475\n",
      "2025-11-23 00:58:01,778 INFO [SEQ] Epoch 02  val_MAE=19.6314\n",
      "2025-11-23 00:58:02,966 INFO [SEQ] Epoch 03  val_MAE=14.8161\n",
      "2025-11-23 00:58:04,062 INFO [SEQ] Epoch 04  val_MAE=11.6083\n",
      "2025-11-23 00:58:05,174 INFO [SEQ] Epoch 05  val_MAE=9.5802\n",
      "2025-11-23 00:58:06,327 INFO [SEQ] Epoch 06  val_MAE=8.4468\n",
      "2025-11-23 00:58:07,516 INFO [SEQ] Epoch 07  val_MAE=6.6694\n",
      "2025-11-23 00:58:08,819 INFO [SEQ] Epoch 08  val_MAE=6.5589\n",
      "2025-11-23 00:58:10,396 INFO [SEQ] Epoch 09  val_MAE=6.7190\n",
      "2025-11-23 00:58:11,601 INFO [SEQ] Epoch 10  val_MAE=5.7965\n",
      "2025-11-23 00:58:12,736 INFO [SEQ] Epoch 11  val_MAE=8.2981\n",
      "2025-11-23 00:58:13,649 INFO [SEQ] Epoch 12  val_MAE=8.6287\n",
      "2025-11-23 00:58:14,885 INFO [SEQ] Epoch 13  val_MAE=9.9373\n",
      "2025-11-23 00:58:15,953 INFO [SEQ] Epoch 14  val_MAE=8.0671\n",
      "2025-11-23 00:58:17,118 INFO [SEQ] Epoch 15  val_MAE=10.1581\n",
      "2025-11-23 00:58:18,260 INFO [SEQ] Epoch 16  val_MAE=10.6014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM val MAE: 5.796503441674369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 00:58:19,604 INFO [SEQ] Epoch 00  val_MAE=24.4022\n",
      "2025-11-23 00:58:20,999 INFO [SEQ] Epoch 01  val_MAE=13.1605\n",
      "2025-11-23 00:58:22,215 INFO [SEQ] Epoch 02  val_MAE=7.5025\n",
      "2025-11-23 00:58:23,399 INFO [SEQ] Epoch 03  val_MAE=5.3549\n",
      "2025-11-23 00:58:24,683 INFO [SEQ] Epoch 04  val_MAE=5.9137\n",
      "2025-11-23 00:58:25,869 INFO [SEQ] Epoch 05  val_MAE=6.9665\n",
      "2025-11-23 00:58:26,918 INFO [SEQ] Epoch 06  val_MAE=8.3546\n",
      "2025-11-23 00:58:28,086 INFO [SEQ] Epoch 07  val_MAE=11.4060\n",
      "2025-11-23 00:58:29,556 INFO [SEQ] Epoch 08  val_MAE=11.3086\n",
      "2025-11-23 00:58:30,634 INFO [SEQ] Epoch 09  val_MAE=11.0859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU val MAE: 5.354915107999529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 00:58:31,975 INFO [SEQ] Epoch 00  val_MAE=10.8489\n",
      "2025-11-23 00:58:33,114 INFO [SEQ] Epoch 01  val_MAE=15.7114\n",
      "2025-11-23 00:58:34,274 INFO [SEQ] Epoch 02  val_MAE=14.1200\n",
      "2025-11-23 00:58:35,489 INFO [SEQ] Epoch 03  val_MAE=16.5177\n",
      "2025-11-23 00:58:36,878 INFO [SEQ] Epoch 04  val_MAE=16.4467\n",
      "2025-11-23 00:58:38,178 INFO [SEQ] Epoch 05  val_MAE=12.8580\n",
      "2025-11-23 00:58:39,254 INFO [SEQ] Epoch 06  val_MAE=16.7822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCN val MAE: 10.848923410688128\n",
      "LSTM metrics: {'MAE': 5.9034528732299805, 'RMSE': 7.427989360516169, 'R2': 0.9353151917457581}\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM, GRU, TCN (quick, reproducible)\n",
    "n_features = Xtr.shape[-1]\n",
    "print(\"n_features:\", n_features)\n",
    "\n",
    "# LSTM\n",
    "lstm = LSTMRegressor(n_features=n_features, hidden_size=64, num_layers=1, dropout=0.12).to(DEVICE)\n",
    "lstm, lstm_val_mae = train_sequence_model(lstm, train_loader, val_loader, lr=4.4e-4, epochs=EPOCHS, patience=PATIENCE, device=DEVICE)\n",
    "print(\"LSTM val MAE:\", lstm_val_mae)\n",
    "\n",
    "# GRU (if implemented in your model_selection)\n",
    "try:\n",
    "    from agentic_pm.modeling.model_selection import GRURegressor\n",
    "    gru = GRURegressor(n_features=n_features, hidden_size=64, num_layers=1).to(DEVICE)\n",
    "    gru, gru_val_mae = train_sequence_model(gru, train_loader, val_loader, lr=1e-3, epochs=EPOCHS, patience=PATIENCE, device=DEVICE)\n",
    "    print(\"GRU val MAE:\", gru_val_mae)\n",
    "except Exception:\n",
    "    print(\"GRU unavailable or not implemented â€” skipping GRU.\")\n",
    "\n",
    "# TCN\n",
    "tcn = MiniTCN(n_features=n_features, hidden=48).to(DEVICE)\n",
    "tcn, tcn_val_mae = train_sequence_model(tcn, train_loader, val_loader, lr=1e-3, epochs=EPOCHS, patience=PATIENCE, device=DEVICE)\n",
    "print(\"TCN val MAE:\", tcn_val_mae)\n",
    "\n",
    "# Predictions & metrics (window-level)\n",
    "def predict_seq_model(model, X):\n",
    "    model.eval()\n",
    "    out = []\n",
    "    dl = DataLoader(SequenceDataset(X, np.zeros(len(X))), batch_size=64, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in dl:\n",
    "            xb = xb.to(DEVICE)\n",
    "            pred = model(xb).cpu().numpy()\n",
    "            out.extend(pred)\n",
    "    return np.array(out)\n",
    "\n",
    "y_pred_lstm = predict_seq_model(lstm, Xva)\n",
    "print(\"LSTM metrics:\", regression_metrics(yva, y_pred_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "deb35d93-3233-47f5-8fd5-d670771f28d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LSTM to artifacts\\models\\lstm_seq_FD001.pth\n"
     ]
    }
   ],
   "source": [
    "# Save best sequence model (pick LSTM if best)\n",
    "ART_DIR = Path(\"artifacts/models\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(lstm.state_dict(), ART_DIR / f\"lstm_seq_{SUBSET}.pth\")\n",
    "print(\"Saved LSTM to\", ART_DIR / f\"lstm_seq_{SUBSET}.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e20d4-2c83-4260-ba5a-74f3dd024f65",
   "metadata": {},
   "source": [
    "### 3.10 Sequence Nested CV (LSTM + GRU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4c02bbf-3364-4412-b0dd-4efa5f8c1b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:04:26,612] A new study created in memory with name: no-name-0ff585e8-186e-4800-9fb7-e1135e7ffe2a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "==============================\n",
      " OUTER FOLD 1/3\n",
      "==============================\n",
      "Train units: 25  Val units: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c77c1ac9894c168ff66a04eee0967f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:04:27,521 INFO [SEQ] Epoch 00  val_MAE=55.7043\n",
      "2025-11-23 11:04:27,973 INFO [SEQ] Epoch 01  val_MAE=53.4988\n",
      "2025-11-23 11:04:28,484 INFO [SEQ] Epoch 02  val_MAE=52.2037\n",
      "2025-11-23 11:04:28,948 INFO [SEQ] Epoch 03  val_MAE=51.1280\n",
      "2025-11-23 11:04:29,397 INFO [SEQ] Epoch 04  val_MAE=50.1670\n",
      "2025-11-23 11:04:29,840 INFO [SEQ] Epoch 05  val_MAE=49.2678\n",
      "2025-11-23 11:04:30,438 INFO [SEQ] Epoch 06  val_MAE=48.4201\n",
      "2025-11-23 11:04:31,032 INFO [SEQ] Epoch 07  val_MAE=47.3804\n",
      "2025-11-23 11:04:31,526 INFO [SEQ] Epoch 08  val_MAE=46.3819\n",
      "2025-11-23 11:04:32,020 INFO [SEQ] Epoch 09  val_MAE=45.4433\n",
      "2025-11-23 11:04:32,458 INFO [SEQ] Epoch 10  val_MAE=44.4808\n",
      "2025-11-23 11:04:32,958 INFO [SEQ] Epoch 11  val_MAE=43.5660\n",
      "2025-11-23 11:04:33,521 INFO [SEQ] Epoch 12  val_MAE=42.7226\n",
      "2025-11-23 11:04:34,064 INFO [SEQ] Epoch 13  val_MAE=41.8595\n",
      "2025-11-23 11:04:34,578 INFO [SEQ] Epoch 14  val_MAE=41.0704\n",
      "2025-11-23 11:04:35,121 INFO [SEQ] Epoch 15  val_MAE=40.2651\n",
      "2025-11-23 11:04:35,672 INFO [SEQ] Epoch 16  val_MAE=39.4906\n",
      "2025-11-23 11:04:36,279 INFO [SEQ] Epoch 17  val_MAE=38.7594\n",
      "2025-11-23 11:04:36,802 INFO [SEQ] Epoch 18  val_MAE=38.0058\n",
      "2025-11-23 11:04:37,409 INFO [SEQ] Epoch 19  val_MAE=37.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:04:37,428] Trial 0 finished with value: 37.296317267691954 and parameters: {'seq_len': 82, 'hidden': 43, 'layers': 2, 'lr': 0.00024316933120840736, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 0 with value: 37.296317267691954.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:04:38,050 INFO [SEQ] Epoch 00  val_MAE=37.2842\n",
      "2025-11-23 11:04:38,487 INFO [SEQ] Epoch 01  val_MAE=31.8332\n",
      "2025-11-23 11:04:38,935 INFO [SEQ] Epoch 02  val_MAE=24.4852\n",
      "2025-11-23 11:04:39,407 INFO [SEQ] Epoch 03  val_MAE=17.9152\n",
      "2025-11-23 11:04:39,877 INFO [SEQ] Epoch 04  val_MAE=13.6410\n",
      "2025-11-23 11:04:40,360 INFO [SEQ] Epoch 05  val_MAE=11.5972\n",
      "2025-11-23 11:04:40,799 INFO [SEQ] Epoch 06  val_MAE=9.6439\n",
      "2025-11-23 11:04:41,205 INFO [SEQ] Epoch 07  val_MAE=8.5370\n",
      "2025-11-23 11:04:41,625 INFO [SEQ] Epoch 08  val_MAE=8.1803\n",
      "2025-11-23 11:04:42,057 INFO [SEQ] Epoch 09  val_MAE=7.7214\n",
      "2025-11-23 11:04:42,462 INFO [SEQ] Epoch 10  val_MAE=8.4779\n",
      "2025-11-23 11:04:42,899 INFO [SEQ] Epoch 11  val_MAE=7.7227\n",
      "2025-11-23 11:04:43,294 INFO [SEQ] Epoch 12  val_MAE=7.5971\n",
      "2025-11-23 11:04:43,682 INFO [SEQ] Epoch 13  val_MAE=8.1107\n",
      "2025-11-23 11:04:44,105 INFO [SEQ] Epoch 14  val_MAE=7.6483\n",
      "2025-11-23 11:04:44,511 INFO [SEQ] Epoch 15  val_MAE=7.9770\n",
      "2025-11-23 11:04:44,962 INFO [SEQ] Epoch 16  val_MAE=8.3353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:04:44,983] Trial 1 finished with value: 7.5971457942536 and parameters: {'seq_len': 96, 'hidden': 110, 'layers': 2, 'lr': 0.0013631998017238842, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:04:45,990 INFO [SEQ] Epoch 00  val_MAE=60.0575\n",
      "2025-11-23 11:04:46,816 INFO [SEQ] Epoch 01  val_MAE=56.7627\n",
      "2025-11-23 11:04:47,688 INFO [SEQ] Epoch 02  val_MAE=53.3691\n",
      "2025-11-23 11:04:48,530 INFO [SEQ] Epoch 03  val_MAE=50.1890\n",
      "2025-11-23 11:04:49,475 INFO [SEQ] Epoch 04  val_MAE=47.1978\n",
      "2025-11-23 11:04:50,427 INFO [SEQ] Epoch 05  val_MAE=44.5761\n",
      "2025-11-23 11:04:51,367 INFO [SEQ] Epoch 06  val_MAE=42.0296\n",
      "2025-11-23 11:04:52,399 INFO [SEQ] Epoch 07  val_MAE=39.6269\n",
      "2025-11-23 11:04:53,384 INFO [SEQ] Epoch 08  val_MAE=37.3172\n",
      "2025-11-23 11:04:54,293 INFO [SEQ] Epoch 09  val_MAE=35.2076\n",
      "2025-11-23 11:04:55,176 INFO [SEQ] Epoch 10  val_MAE=33.3369\n",
      "2025-11-23 11:04:56,120 INFO [SEQ] Epoch 11  val_MAE=31.3693\n",
      "2025-11-23 11:04:57,134 INFO [SEQ] Epoch 12  val_MAE=29.7379\n",
      "2025-11-23 11:04:58,031 INFO [SEQ] Epoch 13  val_MAE=27.8843\n",
      "2025-11-23 11:04:58,854 INFO [SEQ] Epoch 14  val_MAE=26.3270\n",
      "2025-11-23 11:04:59,774 INFO [SEQ] Epoch 15  val_MAE=24.9912\n",
      "2025-11-23 11:05:00,676 INFO [SEQ] Epoch 16  val_MAE=23.6394\n",
      "2025-11-23 11:05:01,590 INFO [SEQ] Epoch 17  val_MAE=22.1918\n",
      "2025-11-23 11:05:02,579 INFO [SEQ] Epoch 18  val_MAE=20.9348\n",
      "2025-11-23 11:05:03,481 INFO [SEQ] Epoch 19  val_MAE=19.7373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:03,504] Trial 2 finished with value: 19.737259775544135 and parameters: {'seq_len': 61, 'hidden': 88, 'layers': 2, 'lr': 0.000179465755030272, 'batch_size': 16, 'model_type': 'gru'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:04,137 INFO [SEQ] Epoch 00  val_MAE=56.5319\n",
      "2025-11-23 11:05:04,622 INFO [SEQ] Epoch 01  val_MAE=53.7431\n",
      "2025-11-23 11:05:05,091 INFO [SEQ] Epoch 02  val_MAE=52.0541\n",
      "2025-11-23 11:05:05,546 INFO [SEQ] Epoch 03  val_MAE=50.5949\n",
      "2025-11-23 11:05:06,006 INFO [SEQ] Epoch 04  val_MAE=49.2774\n",
      "2025-11-23 11:05:06,496 INFO [SEQ] Epoch 05  val_MAE=48.0147\n",
      "2025-11-23 11:05:06,975 INFO [SEQ] Epoch 06  val_MAE=46.2303\n",
      "2025-11-23 11:05:07,428 INFO [SEQ] Epoch 07  val_MAE=44.5904\n",
      "2025-11-23 11:05:07,905 INFO [SEQ] Epoch 08  val_MAE=43.1807\n",
      "2025-11-23 11:05:08,433 INFO [SEQ] Epoch 09  val_MAE=41.8509\n",
      "2025-11-23 11:05:09,045 INFO [SEQ] Epoch 10  val_MAE=40.3130\n",
      "2025-11-23 11:05:09,599 INFO [SEQ] Epoch 11  val_MAE=39.0686\n",
      "2025-11-23 11:05:10,201 INFO [SEQ] Epoch 12  val_MAE=37.9324\n",
      "2025-11-23 11:05:10,650 INFO [SEQ] Epoch 13  val_MAE=36.7078\n",
      "2025-11-23 11:05:11,110 INFO [SEQ] Epoch 14  val_MAE=35.5641\n",
      "2025-11-23 11:05:11,579 INFO [SEQ] Epoch 15  val_MAE=34.4804\n",
      "2025-11-23 11:05:12,010 INFO [SEQ] Epoch 16  val_MAE=33.4564\n",
      "2025-11-23 11:05:12,468 INFO [SEQ] Epoch 17  val_MAE=32.4582\n",
      "2025-11-23 11:05:12,917 INFO [SEQ] Epoch 18  val_MAE=31.5116\n",
      "2025-11-23 11:05:13,388 INFO [SEQ] Epoch 19  val_MAE=30.6168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:13,415] Trial 3 finished with value: 30.61679364660735 and parameters: {'seq_len': 74, 'hidden': 95, 'layers': 2, 'lr': 0.00017378225688787337, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:14,401 INFO [SEQ] Epoch 00  val_MAE=30.5473\n",
      "2025-11-23 11:05:15,343 INFO [SEQ] Epoch 01  val_MAE=17.0984\n",
      "2025-11-23 11:05:16,185 INFO [SEQ] Epoch 02  val_MAE=12.9399\n",
      "2025-11-23 11:05:17,062 INFO [SEQ] Epoch 03  val_MAE=11.1968\n",
      "2025-11-23 11:05:17,995 INFO [SEQ] Epoch 04  val_MAE=11.4297\n",
      "2025-11-23 11:05:18,906 INFO [SEQ] Epoch 05  val_MAE=11.2675\n",
      "2025-11-23 11:05:19,798 INFO [SEQ] Epoch 06  val_MAE=11.2193\n",
      "2025-11-23 11:05:20,724 INFO [SEQ] Epoch 07  val_MAE=11.3356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:20,747] Trial 4 finished with value: 11.19675463438034 and parameters: {'seq_len': 53, 'hidden': 99, 'layers': 1, 'lr': 0.0022224253183996965, 'batch_size': 16, 'model_type': 'lstm'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:21,367 INFO [SEQ] Epoch 00  val_MAE=64.7426\n",
      "2025-11-23 11:05:21,757 INFO [SEQ] Epoch 01  val_MAE=61.6684\n",
      "2025-11-23 11:05:22,138 INFO [SEQ] Epoch 02  val_MAE=59.6965\n",
      "2025-11-23 11:05:22,560 INFO [SEQ] Epoch 03  val_MAE=58.0074\n",
      "2025-11-23 11:05:23,020 INFO [SEQ] Epoch 04  val_MAE=56.4692\n",
      "2025-11-23 11:05:23,362 INFO [SEQ] Epoch 05  val_MAE=55.0240\n",
      "2025-11-23 11:05:23,700 INFO [SEQ] Epoch 06  val_MAE=53.2739\n",
      "2025-11-23 11:05:24,061 INFO [SEQ] Epoch 07  val_MAE=51.1110\n",
      "2025-11-23 11:05:24,364 INFO [SEQ] Epoch 08  val_MAE=49.4289\n",
      "2025-11-23 11:05:24,726 INFO [SEQ] Epoch 09  val_MAE=47.8511\n",
      "2025-11-23 11:05:25,046 INFO [SEQ] Epoch 10  val_MAE=46.1836\n",
      "2025-11-23 11:05:25,384 INFO [SEQ] Epoch 11  val_MAE=44.7554\n",
      "2025-11-23 11:05:25,685 INFO [SEQ] Epoch 12  val_MAE=43.3660\n",
      "2025-11-23 11:05:26,056 INFO [SEQ] Epoch 13  val_MAE=41.9412\n",
      "2025-11-23 11:05:26,404 INFO [SEQ] Epoch 14  val_MAE=40.7881\n",
      "2025-11-23 11:05:26,789 INFO [SEQ] Epoch 15  val_MAE=39.3394\n",
      "2025-11-23 11:05:27,089 INFO [SEQ] Epoch 16  val_MAE=38.2245\n",
      "2025-11-23 11:05:27,402 INFO [SEQ] Epoch 17  val_MAE=37.2281\n",
      "2025-11-23 11:05:27,750 INFO [SEQ] Epoch 18  val_MAE=35.9041\n",
      "2025-11-23 11:05:28,095 INFO [SEQ] Epoch 19  val_MAE=34.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:28,206] Trial 5 finished with value: 34.95002735311335 and parameters: {'seq_len': 54, 'hidden': 106, 'layers': 2, 'lr': 0.0003083671503294388, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:28,633 INFO [SEQ] Epoch 00  val_MAE=45.3336\n",
      "2025-11-23 11:05:28,886 INFO [SEQ] Epoch 01  val_MAE=43.9647\n",
      "2025-11-23 11:05:29,171 INFO [SEQ] Epoch 02  val_MAE=41.7201\n",
      "2025-11-23 11:05:29,423 INFO [SEQ] Epoch 03  val_MAE=40.5814\n",
      "2025-11-23 11:05:29,699 INFO [SEQ] Epoch 04  val_MAE=39.8887\n",
      "2025-11-23 11:05:29,953 INFO [SEQ] Epoch 05  val_MAE=39.3561\n",
      "2025-11-23 11:05:30,188 INFO [SEQ] Epoch 06  val_MAE=38.9150\n",
      "2025-11-23 11:05:30,466 INFO [SEQ] Epoch 07  val_MAE=38.4990\n",
      "2025-11-23 11:05:30,713 INFO [SEQ] Epoch 08  val_MAE=38.1218\n",
      "2025-11-23 11:05:30,986 INFO [SEQ] Epoch 09  val_MAE=37.7618\n",
      "2025-11-23 11:05:31,280 INFO [SEQ] Epoch 10  val_MAE=37.4268\n",
      "2025-11-23 11:05:31,544 INFO [SEQ] Epoch 11  val_MAE=37.0985\n",
      "2025-11-23 11:05:31,831 INFO [SEQ] Epoch 12  val_MAE=36.7843\n",
      "2025-11-23 11:05:32,114 INFO [SEQ] Epoch 13  val_MAE=36.4910\n",
      "2025-11-23 11:05:32,395 INFO [SEQ] Epoch 14  val_MAE=36.2002\n",
      "2025-11-23 11:05:32,670 INFO [SEQ] Epoch 15  val_MAE=35.9151\n",
      "2025-11-23 11:05:32,907 INFO [SEQ] Epoch 16  val_MAE=35.6307\n",
      "2025-11-23 11:05:33,141 INFO [SEQ] Epoch 17  val_MAE=35.3668\n",
      "2025-11-23 11:05:33,400 INFO [SEQ] Epoch 18  val_MAE=35.1000\n",
      "2025-11-23 11:05:33,658 INFO [SEQ] Epoch 19  val_MAE=34.8383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:33,679] Trial 6 finished with value: 34.83828367906458 and parameters: {'seq_len': 108, 'hidden': 63, 'layers': 2, 'lr': 0.00016802404983284108, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:34,916 INFO [SEQ] Epoch 00  val_MAE=43.7404\n",
      "2025-11-23 11:05:35,936 INFO [SEQ] Epoch 01  val_MAE=29.3728\n",
      "2025-11-23 11:05:36,902 INFO [SEQ] Epoch 02  val_MAE=19.0260\n",
      "2025-11-23 11:05:38,089 INFO [SEQ] Epoch 03  val_MAE=13.7973\n",
      "2025-11-23 11:05:39,021 INFO [SEQ] Epoch 04  val_MAE=11.5340\n",
      "2025-11-23 11:05:39,971 INFO [SEQ] Epoch 05  val_MAE=11.1479\n",
      "2025-11-23 11:05:40,910 INFO [SEQ] Epoch 06  val_MAE=10.8651\n",
      "2025-11-23 11:05:41,656 INFO [SEQ] Epoch 07  val_MAE=11.1396\n",
      "2025-11-23 11:05:42,367 INFO [SEQ] Epoch 08  val_MAE=11.0339\n",
      "2025-11-23 11:05:43,111 INFO [SEQ] Epoch 09  val_MAE=10.8853\n",
      "2025-11-23 11:05:43,827 INFO [SEQ] Epoch 10  val_MAE=11.4166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:43,843] Trial 7 finished with value: 10.865086804847328 and parameters: {'seq_len': 68, 'hidden': 39, 'layers': 2, 'lr': 0.00298711916695537, 'batch_size': 16, 'model_type': 'gru'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:44,528 INFO [SEQ] Epoch 00  val_MAE=52.6991\n",
      "2025-11-23 11:05:44,931 INFO [SEQ] Epoch 01  val_MAE=49.9557\n",
      "2025-11-23 11:05:45,300 INFO [SEQ] Epoch 02  val_MAE=48.5856\n",
      "2025-11-23 11:05:45,718 INFO [SEQ] Epoch 03  val_MAE=47.4246\n",
      "2025-11-23 11:05:46,141 INFO [SEQ] Epoch 04  val_MAE=46.3722\n",
      "2025-11-23 11:05:46,549 INFO [SEQ] Epoch 05  val_MAE=45.3949\n",
      "2025-11-23 11:05:46,973 INFO [SEQ] Epoch 06  val_MAE=43.9540\n",
      "2025-11-23 11:05:47,372 INFO [SEQ] Epoch 07  val_MAE=42.6720\n",
      "2025-11-23 11:05:47,762 INFO [SEQ] Epoch 08  val_MAE=41.4727\n",
      "2025-11-23 11:05:48,393 INFO [SEQ] Epoch 09  val_MAE=40.3647\n",
      "2025-11-23 11:05:48,812 INFO [SEQ] Epoch 10  val_MAE=39.3279\n",
      "2025-11-23 11:05:49,246 INFO [SEQ] Epoch 11  val_MAE=38.3677\n",
      "2025-11-23 11:05:49,743 INFO [SEQ] Epoch 12  val_MAE=37.3812\n",
      "2025-11-23 11:05:50,197 INFO [SEQ] Epoch 13  val_MAE=36.3850\n",
      "2025-11-23 11:05:50,638 INFO [SEQ] Epoch 14  val_MAE=35.4736\n",
      "2025-11-23 11:05:51,114 INFO [SEQ] Epoch 15  val_MAE=34.5403\n",
      "2025-11-23 11:05:51,625 INFO [SEQ] Epoch 16  val_MAE=33.6337\n",
      "2025-11-23 11:05:52,122 INFO [SEQ] Epoch 17  val_MAE=32.8047\n",
      "2025-11-23 11:05:52,557 INFO [SEQ] Epoch 18  val_MAE=31.9802\n",
      "2025-11-23 11:05:53,043 INFO [SEQ] Epoch 19  val_MAE=31.2241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:53,059] Trial 8 finished with value: 31.224138616822486 and parameters: {'seq_len': 84, 'hidden': 72, 'layers': 2, 'lr': 0.00018885773728118078, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:54,084 INFO [SEQ] Epoch 00  val_MAE=42.8347\n",
      "2025-11-23 11:05:54,952 INFO [SEQ] Epoch 01  val_MAE=35.4149\n",
      "2025-11-23 11:05:55,831 INFO [SEQ] Epoch 02  val_MAE=24.8006\n",
      "2025-11-23 11:05:56,808 INFO [SEQ] Epoch 03  val_MAE=18.8937\n",
      "2025-11-23 11:05:57,724 INFO [SEQ] Epoch 04  val_MAE=15.6176\n",
      "2025-11-23 11:05:58,581 INFO [SEQ] Epoch 05  val_MAE=12.7205\n",
      "2025-11-23 11:05:59,393 INFO [SEQ] Epoch 06  val_MAE=10.8062\n",
      "2025-11-23 11:06:00,203 INFO [SEQ] Epoch 07  val_MAE=9.7485\n",
      "2025-11-23 11:06:01,147 INFO [SEQ] Epoch 08  val_MAE=9.3422\n",
      "2025-11-23 11:06:01,991 INFO [SEQ] Epoch 09  val_MAE=8.9410\n",
      "2025-11-23 11:06:02,902 INFO [SEQ] Epoch 10  val_MAE=9.0126\n",
      "2025-11-23 11:06:03,714 INFO [SEQ] Epoch 11  val_MAE=8.9639\n",
      "2025-11-23 11:06:04,788 INFO [SEQ] Epoch 12  val_MAE=9.2733\n",
      "2025-11-23 11:06:05,636 INFO [SEQ] Epoch 13  val_MAE=8.7052\n",
      "2025-11-23 11:06:06,470 INFO [SEQ] Epoch 14  val_MAE=8.9027\n",
      "2025-11-23 11:06:07,227 INFO [SEQ] Epoch 15  val_MAE=9.3366\n",
      "2025-11-23 11:06:07,916 INFO [SEQ] Epoch 16  val_MAE=9.1309\n",
      "2025-11-23 11:06:08,653 INFO [SEQ] Epoch 17  val_MAE=9.8103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:06:08,671] Trial 9 finished with value: 8.705241174684407 and parameters: {'seq_len': 80, 'hidden': 96, 'layers': 2, 'lr': 0.000799369631687782, 'batch_size': 16, 'model_type': 'gru'}. Best is trial 1 with value: 7.5971457942536.\n",
      "Best inner params: {'seq_len': 96, 'hidden': 110, 'layers': 2, 'lr': 0.0013631998017238842, 'batch_size': 32, 'model_type': 'gru'}\n",
      "Train windows: (2735, 96, 107)  Val windows: (2424, 96, 107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:06:09,456 INFO [SEQ] Epoch 00  val_MAE=37.1244\n",
      "2025-11-23 11:06:09,880 INFO [SEQ] Epoch 01  val_MAE=30.5213\n",
      "2025-11-23 11:06:10,323 INFO [SEQ] Epoch 02  val_MAE=22.7786\n",
      "2025-11-23 11:06:10,882 INFO [SEQ] Epoch 03  val_MAE=16.8419\n",
      "2025-11-23 11:06:11,402 INFO [SEQ] Epoch 04  val_MAE=13.5719\n",
      "2025-11-23 11:06:11,860 INFO [SEQ] Epoch 05  val_MAE=11.3550\n",
      "2025-11-23 11:06:12,336 INFO [SEQ] Epoch 06  val_MAE=9.6908\n",
      "2025-11-23 11:06:12,814 INFO [SEQ] Epoch 07  val_MAE=8.9137\n",
      "2025-11-23 11:06:13,336 INFO [SEQ] Epoch 08  val_MAE=7.9031\n",
      "2025-11-23 11:06:13,738 INFO [SEQ] Epoch 09  val_MAE=7.4179\n",
      "2025-11-23 11:06:14,134 INFO [SEQ] Epoch 10  val_MAE=7.4920\n",
      "2025-11-23 11:06:14,657 INFO [SEQ] Epoch 11  val_MAE=7.5717\n",
      "2025-11-23 11:06:15,161 INFO [SEQ] Epoch 12  val_MAE=7.4176\n",
      "2025-11-23 11:06:15,622 INFO [SEQ] Epoch 13  val_MAE=7.9952\n",
      "2025-11-23 11:06:16,082 INFO [SEQ] Epoch 14  val_MAE=7.5790\n",
      "2025-11-23 11:06:16,466 INFO [SEQ] Epoch 15  val_MAE=7.8636\n",
      "2025-11-23 11:06:17,080 INFO [SEQ] Epoch 16  val_MAE=7.7411\n",
      "2025-11-23 11:06:17,493 INFO [SEQ] Epoch 17  val_MAE=7.9024\n",
      "[I 2025-11-23 11:06:17,639] A new study created in memory with name: no-name-425e4f02-51f7-4db0-af74-41e28b927006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 METRICS: {'MAE': 7.437922954559326, 'RMSE': 11.00126259233404, 'R2': 0.8949770927429199}\n",
      "\n",
      "==============================\n",
      " OUTER FOLD 2/3\n",
      "==============================\n",
      "Train units: 50  Val units: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5692ba0328194fa1928368efadaa795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:06:18,347 INFO [SEQ] Epoch 00  val_MAE=72.0096\n",
      "2025-11-23 11:06:18,852 INFO [SEQ] Epoch 01  val_MAE=66.4233\n",
      "2025-11-23 11:06:19,318 INFO [SEQ] Epoch 02  val_MAE=63.3775\n",
      "2025-11-23 11:06:19,742 INFO [SEQ] Epoch 03  val_MAE=60.5985\n",
      "2025-11-23 11:06:20,141 INFO [SEQ] Epoch 04  val_MAE=58.0456\n",
      "2025-11-23 11:06:20,602 INFO [SEQ] Epoch 05  val_MAE=55.7764\n",
      "2025-11-23 11:06:21,045 INFO [SEQ] Epoch 06  val_MAE=53.5750\n",
      "2025-11-23 11:06:21,476 INFO [SEQ] Epoch 07  val_MAE=51.5616\n",
      "2025-11-23 11:06:21,912 INFO [SEQ] Epoch 08  val_MAE=49.5394\n",
      "2025-11-23 11:06:22,359 INFO [SEQ] Epoch 09  val_MAE=47.8245\n",
      "2025-11-23 11:06:22,812 INFO [SEQ] Epoch 10  val_MAE=45.6783\n",
      "2025-11-23 11:06:23,308 INFO [SEQ] Epoch 11  val_MAE=44.2382\n",
      "2025-11-23 11:06:23,748 INFO [SEQ] Epoch 12  val_MAE=42.5816\n",
      "2025-11-23 11:06:24,254 INFO [SEQ] Epoch 13  val_MAE=41.2038\n",
      "2025-11-23 11:06:24,674 INFO [SEQ] Epoch 14  val_MAE=39.8025\n",
      "2025-11-23 11:06:25,252 INFO [SEQ] Epoch 15  val_MAE=38.3963\n",
      "2025-11-23 11:06:25,823 INFO [SEQ] Epoch 16  val_MAE=37.1295\n",
      "2025-11-23 11:06:26,337 INFO [SEQ] Epoch 17  val_MAE=35.9848\n",
      "2025-11-23 11:06:26,881 INFO [SEQ] Epoch 18  val_MAE=34.8000\n",
      "2025-11-23 11:06:27,493 INFO [SEQ] Epoch 19  val_MAE=33.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:06:27,517] Trial 0 finished with value: 33.714992626658024 and parameters: {'seq_len': 77, 'hidden': 54, 'layers': 1, 'lr': 0.0005579477056594108, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 0 with value: 33.714992626658024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:06:28,362 INFO [SEQ] Epoch 00  val_MAE=60.2022\n",
      "2025-11-23 11:06:28,861 INFO [SEQ] Epoch 01  val_MAE=53.1418\n",
      "2025-11-23 11:06:29,306 INFO [SEQ] Epoch 02  val_MAE=47.9442\n",
      "2025-11-23 11:06:29,770 INFO [SEQ] Epoch 03  val_MAE=38.4222\n",
      "2025-11-23 11:06:30,326 INFO [SEQ] Epoch 04  val_MAE=33.9630\n",
      "2025-11-23 11:06:31,019 INFO [SEQ] Epoch 05  val_MAE=29.8660\n",
      "2025-11-23 11:06:31,634 INFO [SEQ] Epoch 06  val_MAE=27.6359\n",
      "2025-11-23 11:06:32,117 INFO [SEQ] Epoch 07  val_MAE=25.6039\n",
      "2025-11-23 11:06:32,595 INFO [SEQ] Epoch 08  val_MAE=25.2084\n",
      "2025-11-23 11:06:33,079 INFO [SEQ] Epoch 09  val_MAE=24.0998\n",
      "2025-11-23 11:06:33,507 INFO [SEQ] Epoch 10  val_MAE=23.6269\n",
      "2025-11-23 11:06:33,930 INFO [SEQ] Epoch 11  val_MAE=23.5465\n",
      "2025-11-23 11:06:34,353 INFO [SEQ] Epoch 12  val_MAE=23.4614\n",
      "2025-11-23 11:06:34,903 INFO [SEQ] Epoch 13  val_MAE=22.9749\n",
      "2025-11-23 11:06:35,336 INFO [SEQ] Epoch 14  val_MAE=22.8492\n",
      "2025-11-23 11:06:35,764 INFO [SEQ] Epoch 15  val_MAE=23.1883\n",
      "2025-11-23 11:06:36,200 INFO [SEQ] Epoch 16  val_MAE=22.4244\n",
      "2025-11-23 11:06:36,626 INFO [SEQ] Epoch 17  val_MAE=22.0382\n",
      "2025-11-23 11:06:37,094 INFO [SEQ] Epoch 18  val_MAE=22.9675\n",
      "2025-11-23 11:06:37,535 INFO [SEQ] Epoch 19  val_MAE=22.4678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:06:37,560] Trial 1 finished with value: 22.03823642253876 and parameters: {'seq_len': 83, 'hidden': 36, 'layers': 2, 'lr': 0.0037689659000820007, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 1 with value: 22.03823642253876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:06:38,596 INFO [SEQ] Epoch 00  val_MAE=78.4705\n",
      "2025-11-23 11:06:39,439 INFO [SEQ] Epoch 01  val_MAE=75.5563\n",
      "2025-11-23 11:06:40,264 INFO [SEQ] Epoch 02  val_MAE=73.1309\n",
      "2025-11-23 11:06:41,059 INFO [SEQ] Epoch 03  val_MAE=70.4721\n",
      "2025-11-23 11:06:41,907 INFO [SEQ] Epoch 04  val_MAE=67.9090\n",
      "2025-11-23 11:06:42,794 INFO [SEQ] Epoch 05  val_MAE=65.5559\n",
      "2025-11-23 11:06:43,919 INFO [SEQ] Epoch 06  val_MAE=63.4646\n",
      "2025-11-23 11:06:45,024 INFO [SEQ] Epoch 07  val_MAE=61.3109\n",
      "2025-11-23 11:06:46,423 INFO [SEQ] Epoch 08  val_MAE=59.3290\n",
      "2025-11-23 11:06:47,422 INFO [SEQ] Epoch 09  val_MAE=57.2040\n",
      "2025-11-23 11:06:48,384 INFO [SEQ] Epoch 10  val_MAE=55.3176\n",
      "2025-11-23 11:06:49,331 INFO [SEQ] Epoch 11  val_MAE=53.6349\n",
      "2025-11-23 11:06:50,361 INFO [SEQ] Epoch 12  val_MAE=51.7932\n",
      "2025-11-23 11:06:51,403 INFO [SEQ] Epoch 13  val_MAE=50.2305\n",
      "2025-11-23 11:06:52,581 INFO [SEQ] Epoch 14  val_MAE=48.6210\n",
      "2025-11-23 11:06:53,436 INFO [SEQ] Epoch 15  val_MAE=47.1359\n",
      "2025-11-23 11:06:54,340 INFO [SEQ] Epoch 16  val_MAE=45.6058\n",
      "2025-11-23 11:06:55,208 INFO [SEQ] Epoch 17  val_MAE=44.0805\n",
      "2025-11-23 11:06:56,131 INFO [SEQ] Epoch 18  val_MAE=42.8283\n",
      "2025-11-23 11:06:57,046 INFO [SEQ] Epoch 19  val_MAE=41.3444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:06:57,068] Trial 2 finished with value: 41.34436807671531 and parameters: {'seq_len': 55, 'hidden': 114, 'layers': 2, 'lr': 0.00010777560178518667, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 1 with value: 22.03823642253876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:06:58,031 INFO [SEQ] Epoch 00  val_MAE=60.8100\n",
      "2025-11-23 11:06:58,766 INFO [SEQ] Epoch 01  val_MAE=44.8476\n",
      "2025-11-23 11:06:59,519 INFO [SEQ] Epoch 02  val_MAE=35.4701\n",
      "2025-11-23 11:07:00,302 INFO [SEQ] Epoch 03  val_MAE=29.5665\n",
      "2025-11-23 11:07:01,099 INFO [SEQ] Epoch 04  val_MAE=26.7888\n",
      "2025-11-23 11:07:01,936 INFO [SEQ] Epoch 05  val_MAE=24.9785\n",
      "2025-11-23 11:07:02,745 INFO [SEQ] Epoch 06  val_MAE=24.7258\n",
      "2025-11-23 11:07:03,570 INFO [SEQ] Epoch 07  val_MAE=23.9724\n",
      "2025-11-23 11:07:04,402 INFO [SEQ] Epoch 08  val_MAE=24.0437\n",
      "2025-11-23 11:07:05,215 INFO [SEQ] Epoch 09  val_MAE=23.6248\n",
      "2025-11-23 11:07:06,044 INFO [SEQ] Epoch 10  val_MAE=24.1185\n",
      "2025-11-23 11:07:06,890 INFO [SEQ] Epoch 11  val_MAE=24.7359\n",
      "2025-11-23 11:07:07,724 INFO [SEQ] Epoch 12  val_MAE=24.3301\n",
      "2025-11-23 11:07:08,708 INFO [SEQ] Epoch 13  val_MAE=24.4939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:07:08,741] Trial 3 finished with value: 23.62475204070409 and parameters: {'seq_len': 58, 'hidden': 76, 'layers': 1, 'lr': 0.0014298435361441038, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 1 with value: 22.03823642253876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:07:09,518 INFO [SEQ] Epoch 00  val_MAE=81.7929\n",
      "2025-11-23 11:07:10,047 INFO [SEQ] Epoch 01  val_MAE=77.1918\n",
      "2025-11-23 11:07:10,598 INFO [SEQ] Epoch 02  val_MAE=74.1847\n",
      "2025-11-23 11:07:11,131 INFO [SEQ] Epoch 03  val_MAE=71.3797\n",
      "2025-11-23 11:07:11,711 INFO [SEQ] Epoch 04  val_MAE=68.8671\n",
      "2025-11-23 11:07:12,260 INFO [SEQ] Epoch 05  val_MAE=66.5938\n",
      "2025-11-23 11:07:12,836 INFO [SEQ] Epoch 06  val_MAE=64.2660\n",
      "2025-11-23 11:07:13,426 INFO [SEQ] Epoch 07  val_MAE=62.1653\n",
      "2025-11-23 11:07:13,995 INFO [SEQ] Epoch 08  val_MAE=60.1184\n",
      "2025-11-23 11:07:14,566 INFO [SEQ] Epoch 09  val_MAE=58.2302\n",
      "2025-11-23 11:07:15,103 INFO [SEQ] Epoch 10  val_MAE=56.4833\n",
      "2025-11-23 11:07:15,692 INFO [SEQ] Epoch 11  val_MAE=54.5029\n",
      "2025-11-23 11:07:16,254 INFO [SEQ] Epoch 12  val_MAE=52.9629\n",
      "2025-11-23 11:07:16,834 INFO [SEQ] Epoch 13  val_MAE=51.3401\n",
      "2025-11-23 11:07:17,420 INFO [SEQ] Epoch 14  val_MAE=49.4813\n",
      "2025-11-23 11:07:17,954 INFO [SEQ] Epoch 15  val_MAE=48.0882\n",
      "2025-11-23 11:07:18,521 INFO [SEQ] Epoch 16  val_MAE=46.5109\n",
      "2025-11-23 11:07:19,102 INFO [SEQ] Epoch 17  val_MAE=45.0276\n",
      "2025-11-23 11:07:19,740 INFO [SEQ] Epoch 18  val_MAE=43.8003\n",
      "2025-11-23 11:07:20,319 INFO [SEQ] Epoch 19  val_MAE=42.5447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:07:20,370] Trial 4 finished with value: 42.54471618031699 and parameters: {'seq_len': 51, 'hidden': 68, 'layers': 1, 'lr': 0.0003553431972117803, 'batch_size': 64, 'model_type': 'gru'}. Best is trial 1 with value: 22.03823642253876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:07:21,228 INFO [SEQ] Epoch 00  val_MAE=32.1023\n",
      "2025-11-23 11:07:21,706 INFO [SEQ] Epoch 01  val_MAE=23.3741\n",
      "2025-11-23 11:07:22,233 INFO [SEQ] Epoch 02  val_MAE=19.3078\n",
      "2025-11-23 11:07:22,762 INFO [SEQ] Epoch 03  val_MAE=19.7519\n",
      "2025-11-23 11:07:23,308 INFO [SEQ] Epoch 04  val_MAE=19.7572\n",
      "2025-11-23 11:07:23,862 INFO [SEQ] Epoch 05  val_MAE=18.8600\n",
      "2025-11-23 11:07:24,403 INFO [SEQ] Epoch 06  val_MAE=19.7307\n",
      "2025-11-23 11:07:24,986 INFO [SEQ] Epoch 07  val_MAE=19.2755\n",
      "2025-11-23 11:07:25,539 INFO [SEQ] Epoch 08  val_MAE=18.9873\n",
      "2025-11-23 11:07:26,178 INFO [SEQ] Epoch 09  val_MAE=18.5578\n",
      "2025-11-23 11:07:26,751 INFO [SEQ] Epoch 10  val_MAE=19.8094\n",
      "2025-11-23 11:07:27,384 INFO [SEQ] Epoch 11  val_MAE=19.9313\n",
      "2025-11-23 11:07:27,940 INFO [SEQ] Epoch 12  val_MAE=19.1091\n",
      "2025-11-23 11:07:28,547 INFO [SEQ] Epoch 13  val_MAE=19.6025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:07:28,599] Trial 5 finished with value: 18.557767937212816 and parameters: {'seq_len': 108, 'hidden': 115, 'layers': 1, 'lr': 0.002862459049213856, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 5 with value: 18.557767937212816.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:07:29,671 INFO [SEQ] Epoch 00  val_MAE=77.1772\n",
      "2025-11-23 11:07:30,542 INFO [SEQ] Epoch 01  val_MAE=70.1701\n",
      "2025-11-23 11:07:31,501 INFO [SEQ] Epoch 02  val_MAE=64.3962\n",
      "2025-11-23 11:07:32,452 INFO [SEQ] Epoch 03  val_MAE=59.4450\n",
      "2025-11-23 11:07:33,445 INFO [SEQ] Epoch 04  val_MAE=54.5527\n",
      "2025-11-23 11:07:34,335 INFO [SEQ] Epoch 05  val_MAE=50.6231\n",
      "2025-11-23 11:07:35,214 INFO [SEQ] Epoch 06  val_MAE=46.6765\n",
      "2025-11-23 11:07:36,159 INFO [SEQ] Epoch 07  val_MAE=43.3576\n",
      "2025-11-23 11:07:37,029 INFO [SEQ] Epoch 08  val_MAE=40.4405\n",
      "2025-11-23 11:07:37,868 INFO [SEQ] Epoch 09  val_MAE=37.6756\n",
      "2025-11-23 11:07:38,719 INFO [SEQ] Epoch 10  val_MAE=35.3897\n",
      "2025-11-23 11:07:39,626 INFO [SEQ] Epoch 11  val_MAE=33.3759\n",
      "2025-11-23 11:07:40,480 INFO [SEQ] Epoch 12  val_MAE=32.0473\n",
      "2025-11-23 11:07:41,304 INFO [SEQ] Epoch 13  val_MAE=30.3977\n",
      "2025-11-23 11:07:42,208 INFO [SEQ] Epoch 14  val_MAE=29.2010\n",
      "2025-11-23 11:07:43,182 INFO [SEQ] Epoch 15  val_MAE=28.4159\n",
      "2025-11-23 11:07:44,216 INFO [SEQ] Epoch 16  val_MAE=27.5827\n",
      "2025-11-23 11:07:45,225 INFO [SEQ] Epoch 17  val_MAE=26.8815\n",
      "2025-11-23 11:07:46,211 INFO [SEQ] Epoch 18  val_MAE=26.0321\n",
      "2025-11-23 11:07:47,175 INFO [SEQ] Epoch 19  val_MAE=25.3886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:07:47,212] Trial 6 finished with value: 25.388641927185958 and parameters: {'seq_len': 49, 'hidden': 79, 'layers': 1, 'lr': 0.0003793419605681494, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 5 with value: 18.557767937212816.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:07:48,367 INFO [SEQ] Epoch 00  val_MAE=58.7712\n",
      "2025-11-23 11:07:49,229 INFO [SEQ] Epoch 01  val_MAE=43.0559\n",
      "2025-11-23 11:07:50,120 INFO [SEQ] Epoch 02  val_MAE=33.2689\n",
      "2025-11-23 11:07:50,942 INFO [SEQ] Epoch 03  val_MAE=27.8481\n",
      "2025-11-23 11:07:51,729 INFO [SEQ] Epoch 04  val_MAE=26.2440\n",
      "2025-11-23 11:07:52,500 INFO [SEQ] Epoch 05  val_MAE=25.9734\n",
      "2025-11-23 11:07:53,275 INFO [SEQ] Epoch 06  val_MAE=24.9662\n",
      "2025-11-23 11:07:54,068 INFO [SEQ] Epoch 07  val_MAE=22.9759\n",
      "2025-11-23 11:07:54,839 INFO [SEQ] Epoch 08  val_MAE=23.1119\n",
      "2025-11-23 11:07:55,625 INFO [SEQ] Epoch 09  val_MAE=24.0579\n",
      "2025-11-23 11:07:56,408 INFO [SEQ] Epoch 10  val_MAE=23.4977\n",
      "2025-11-23 11:07:57,221 INFO [SEQ] Epoch 11  val_MAE=23.3482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:07:57,267] Trial 7 finished with value: 22.975898991643856 and parameters: {'seq_len': 67, 'hidden': 70, 'layers': 2, 'lr': 0.001679022861454024, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 5 with value: 18.557767937212816.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:07:58,100 INFO [SEQ] Epoch 00  val_MAE=54.4880\n",
      "2025-11-23 11:07:58,609 INFO [SEQ] Epoch 01  val_MAE=51.5194\n",
      "2025-11-23 11:07:59,216 INFO [SEQ] Epoch 02  val_MAE=49.2028\n",
      "2025-11-23 11:07:59,769 INFO [SEQ] Epoch 03  val_MAE=47.2931\n",
      "2025-11-23 11:08:00,420 INFO [SEQ] Epoch 04  val_MAE=45.6906\n",
      "2025-11-23 11:08:01,125 INFO [SEQ] Epoch 05  val_MAE=44.2763\n",
      "2025-11-23 11:08:01,797 INFO [SEQ] Epoch 06  val_MAE=41.1098\n",
      "2025-11-23 11:08:02,360 INFO [SEQ] Epoch 07  val_MAE=38.6982\n",
      "2025-11-23 11:08:02,929 INFO [SEQ] Epoch 08  val_MAE=36.2889\n",
      "2025-11-23 11:08:03,497 INFO [SEQ] Epoch 09  val_MAE=34.4395\n",
      "2025-11-23 11:08:04,040 INFO [SEQ] Epoch 10  val_MAE=32.7505\n",
      "2025-11-23 11:08:04,590 INFO [SEQ] Epoch 11  val_MAE=31.2883\n",
      "2025-11-23 11:08:05,168 INFO [SEQ] Epoch 12  val_MAE=30.4243\n",
      "2025-11-23 11:08:05,719 INFO [SEQ] Epoch 13  val_MAE=29.4493\n",
      "2025-11-23 11:08:06,241 INFO [SEQ] Epoch 14  val_MAE=28.5334\n",
      "2025-11-23 11:08:06,923 INFO [SEQ] Epoch 15  val_MAE=27.6351\n",
      "2025-11-23 11:08:07,571 INFO [SEQ] Epoch 16  val_MAE=26.5166\n",
      "2025-11-23 11:08:08,225 INFO [SEQ] Epoch 17  val_MAE=25.6366\n",
      "2025-11-23 11:08:08,839 INFO [SEQ] Epoch 18  val_MAE=24.6937\n",
      "2025-11-23 11:08:09,553 INFO [SEQ] Epoch 19  val_MAE=24.1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:08:09,600] Trial 8 finished with value: 24.164627157353067 and parameters: {'seq_len': 117, 'hidden': 45, 'layers': 2, 'lr': 0.0005770488792010813, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 5 with value: 18.557767937212816.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:08:10,921 INFO [SEQ] Epoch 00  val_MAE=47.3137\n",
      "2025-11-23 11:08:11,887 INFO [SEQ] Epoch 01  val_MAE=38.8546\n",
      "2025-11-23 11:08:12,891 INFO [SEQ] Epoch 02  val_MAE=32.4539\n",
      "2025-11-23 11:08:13,895 INFO [SEQ] Epoch 03  val_MAE=27.5284\n",
      "2025-11-23 11:08:15,041 INFO [SEQ] Epoch 04  val_MAE=24.0701\n",
      "2025-11-23 11:08:16,312 INFO [SEQ] Epoch 05  val_MAE=21.8984\n",
      "2025-11-23 11:08:17,537 INFO [SEQ] Epoch 06  val_MAE=20.0417\n",
      "2025-11-23 11:08:18,618 INFO [SEQ] Epoch 07  val_MAE=19.1601\n",
      "2025-11-23 11:08:19,643 INFO [SEQ] Epoch 08  val_MAE=18.0205\n",
      "2025-11-23 11:08:20,606 INFO [SEQ] Epoch 09  val_MAE=17.8202\n",
      "2025-11-23 11:08:21,624 INFO [SEQ] Epoch 10  val_MAE=17.7791\n",
      "2025-11-23 11:08:22,757 INFO [SEQ] Epoch 11  val_MAE=17.7177\n",
      "2025-11-23 11:08:23,895 INFO [SEQ] Epoch 12  val_MAE=17.2122\n",
      "2025-11-23 11:08:25,118 INFO [SEQ] Epoch 13  val_MAE=17.2917\n",
      "2025-11-23 11:08:26,465 INFO [SEQ] Epoch 14  val_MAE=16.3925\n",
      "2025-11-23 11:08:27,516 INFO [SEQ] Epoch 15  val_MAE=16.3333\n",
      "2025-11-23 11:08:28,611 INFO [SEQ] Epoch 16  val_MAE=15.7765\n",
      "2025-11-23 11:08:29,730 INFO [SEQ] Epoch 17  val_MAE=15.8902\n",
      "2025-11-23 11:08:30,813 INFO [SEQ] Epoch 18  val_MAE=16.5952\n",
      "2025-11-23 11:08:31,895 INFO [SEQ] Epoch 19  val_MAE=15.8013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:08:31,941] Trial 9 finished with value: 15.776484062145283 and parameters: {'seq_len': 113, 'hidden': 49, 'layers': 1, 'lr': 0.0010586001963975513, 'batch_size': 16, 'model_type': 'lstm'}. Best is trial 9 with value: 15.776484062145283.\n",
      "Best inner params: {'seq_len': 113, 'hidden': 49, 'layers': 1, 'lr': 0.0010586001963975513, 'batch_size': 16, 'model_type': 'lstm'}\n",
      "Train windows: (4309, 113, 107)  Val windows: (2450, 113, 107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:08:33,310 INFO [SEQ] Epoch 00  val_MAE=46.8945\n",
      "2025-11-23 11:08:34,376 INFO [SEQ] Epoch 01  val_MAE=37.9125\n",
      "2025-11-23 11:08:35,429 INFO [SEQ] Epoch 02  val_MAE=31.6992\n",
      "2025-11-23 11:08:36,464 INFO [SEQ] Epoch 03  val_MAE=27.3605\n",
      "2025-11-23 11:08:37,465 INFO [SEQ] Epoch 04  val_MAE=24.7236\n",
      "2025-11-23 11:08:38,459 INFO [SEQ] Epoch 05  val_MAE=22.4707\n",
      "2025-11-23 11:08:39,467 INFO [SEQ] Epoch 06  val_MAE=20.6489\n",
      "2025-11-23 11:08:40,533 INFO [SEQ] Epoch 07  val_MAE=19.1425\n",
      "2025-11-23 11:08:41,583 INFO [SEQ] Epoch 08  val_MAE=17.9748\n",
      "2025-11-23 11:08:42,642 INFO [SEQ] Epoch 09  val_MAE=18.3659\n",
      "2025-11-23 11:08:43,714 INFO [SEQ] Epoch 10  val_MAE=17.4246\n",
      "2025-11-23 11:08:44,781 INFO [SEQ] Epoch 11  val_MAE=17.2037\n",
      "2025-11-23 11:08:45,891 INFO [SEQ] Epoch 12  val_MAE=16.6159\n",
      "2025-11-23 11:08:46,984 INFO [SEQ] Epoch 13  val_MAE=16.5370\n",
      "2025-11-23 11:08:48,057 INFO [SEQ] Epoch 14  val_MAE=16.5841\n",
      "2025-11-23 11:08:49,174 INFO [SEQ] Epoch 15  val_MAE=16.7540\n",
      "2025-11-23 11:08:50,210 INFO [SEQ] Epoch 16  val_MAE=16.9404\n",
      "2025-11-23 11:08:51,236 INFO [SEQ] Epoch 17  val_MAE=16.7046\n",
      "2025-11-23 11:08:52,261 INFO [SEQ] Epoch 18  val_MAE=17.2323\n",
      "[I 2025-11-23 11:08:52,527] A new study created in memory with name: no-name-8ec04c6f-be4c-41a5-bbfa-ebea69e389d5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2 METRICS: {'MAE': 16.621173858642578, 'RMSE': 30.084636064749688, 'R2': 0.6446547508239746}\n",
      "\n",
      "==============================\n",
      " OUTER FOLD 3/3\n",
      "==============================\n",
      "Train units: 75  Val units: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9fb5d8b73e4456a14e35171410048f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:08:53,841 INFO [SEQ] Epoch 00  val_MAE=41.4038\n",
      "2025-11-23 11:08:54,331 INFO [SEQ] Epoch 01  val_MAE=41.7049\n",
      "2025-11-23 11:08:54,839 INFO [SEQ] Epoch 02  val_MAE=20.3036\n",
      "2025-11-23 11:08:55,342 INFO [SEQ] Epoch 03  val_MAE=17.3035\n",
      "2025-11-23 11:08:55,854 INFO [SEQ] Epoch 04  val_MAE=15.8812\n",
      "2025-11-23 11:08:56,353 INFO [SEQ] Epoch 05  val_MAE=15.5100\n",
      "2025-11-23 11:08:56,827 INFO [SEQ] Epoch 06  val_MAE=13.9050\n",
      "2025-11-23 11:08:57,357 INFO [SEQ] Epoch 07  val_MAE=13.7196\n",
      "2025-11-23 11:08:57,868 INFO [SEQ] Epoch 08  val_MAE=13.9159\n",
      "2025-11-23 11:08:58,366 INFO [SEQ] Epoch 09  val_MAE=15.1027\n",
      "2025-11-23 11:08:58,864 INFO [SEQ] Epoch 10  val_MAE=13.7089\n",
      "2025-11-23 11:08:59,402 INFO [SEQ] Epoch 11  val_MAE=13.7723\n",
      "2025-11-23 11:08:59,981 INFO [SEQ] Epoch 12  val_MAE=16.0100\n",
      "2025-11-23 11:09:00,561 INFO [SEQ] Epoch 13  val_MAE=13.9260\n",
      "2025-11-23 11:09:01,112 INFO [SEQ] Epoch 14  val_MAE=15.3490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:09:01,148] Trial 0 finished with value: 13.708879609440649 and parameters: {'seq_len': 110, 'hidden': 105, 'layers': 2, 'lr': 0.007882845761349068, 'batch_size': 64, 'model_type': 'gru'}. Best is trial 0 with value: 13.708879609440649.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:09:04,017 INFO [SEQ] Epoch 00  val_MAE=54.0538\n",
      "2025-11-23 11:09:06,200 INFO [SEQ] Epoch 01  val_MAE=41.1554\n",
      "2025-11-23 11:09:08,303 INFO [SEQ] Epoch 02  val_MAE=32.1097\n",
      "2025-11-23 11:09:10,356 INFO [SEQ] Epoch 03  val_MAE=26.9246\n",
      "2025-11-23 11:09:12,402 INFO [SEQ] Epoch 04  val_MAE=23.8179\n",
      "2025-11-23 11:09:14,414 INFO [SEQ] Epoch 05  val_MAE=21.5425\n",
      "2025-11-23 11:09:16,444 INFO [SEQ] Epoch 06  val_MAE=20.5330\n",
      "2025-11-23 11:09:18,329 INFO [SEQ] Epoch 07  val_MAE=19.0418\n",
      "2025-11-23 11:09:20,587 INFO [SEQ] Epoch 08  val_MAE=19.0144\n",
      "2025-11-23 11:09:22,793 INFO [SEQ] Epoch 09  val_MAE=19.1914\n",
      "2025-11-23 11:09:24,958 INFO [SEQ] Epoch 10  val_MAE=19.0153\n",
      "2025-11-23 11:09:27,110 INFO [SEQ] Epoch 11  val_MAE=18.6748\n",
      "2025-11-23 11:09:29,381 INFO [SEQ] Epoch 12  val_MAE=18.8206\n",
      "2025-11-23 11:09:31,209 INFO [SEQ] Epoch 13  val_MAE=19.0988\n",
      "2025-11-23 11:09:32,954 INFO [SEQ] Epoch 14  val_MAE=19.0356\n",
      "2025-11-23 11:09:34,659 INFO [SEQ] Epoch 15  val_MAE=19.1913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:09:34,692] Trial 1 finished with value: 18.674838058326554 and parameters: {'seq_len': 88, 'hidden': 40, 'layers': 2, 'lr': 0.0010103287914332072, 'batch_size': 16, 'model_type': 'gru'}. Best is trial 0 with value: 13.708879609440649.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:09:35,737 INFO [SEQ] Epoch 00  val_MAE=56.6409\n",
      "2025-11-23 11:09:36,604 INFO [SEQ] Epoch 01  val_MAE=40.6775\n",
      "2025-11-23 11:09:37,350 INFO [SEQ] Epoch 02  val_MAE=29.1153\n",
      "2025-11-23 11:09:38,004 INFO [SEQ] Epoch 03  val_MAE=23.7223\n",
      "2025-11-23 11:09:38,563 INFO [SEQ] Epoch 04  val_MAE=21.4650\n",
      "2025-11-23 11:09:39,220 INFO [SEQ] Epoch 05  val_MAE=19.2553\n",
      "2025-11-23 11:09:39,959 INFO [SEQ] Epoch 06  val_MAE=17.9148\n",
      "2025-11-23 11:09:40,759 INFO [SEQ] Epoch 07  val_MAE=19.3580\n",
      "2025-11-23 11:09:41,555 INFO [SEQ] Epoch 08  val_MAE=18.3918\n",
      "2025-11-23 11:09:42,400 INFO [SEQ] Epoch 09  val_MAE=17.0478\n",
      "2025-11-23 11:09:43,135 INFO [SEQ] Epoch 10  val_MAE=18.3744\n",
      "2025-11-23 11:09:43,874 INFO [SEQ] Epoch 11  val_MAE=17.5358\n",
      "2025-11-23 11:09:44,668 INFO [SEQ] Epoch 12  val_MAE=17.2151\n",
      "2025-11-23 11:09:45,469 INFO [SEQ] Epoch 13  val_MAE=16.6901\n",
      "2025-11-23 11:09:46,303 INFO [SEQ] Epoch 14  val_MAE=17.5665\n",
      "2025-11-23 11:09:47,062 INFO [SEQ] Epoch 15  val_MAE=17.3312\n",
      "2025-11-23 11:09:47,763 INFO [SEQ] Epoch 16  val_MAE=17.9278\n",
      "2025-11-23 11:09:48,499 INFO [SEQ] Epoch 17  val_MAE=17.6580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:09:48,533] Trial 2 finished with value: 16.69009660419665 and parameters: {'seq_len': 75, 'hidden': 80, 'layers': 2, 'lr': 0.002590917812063434, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 0 with value: 13.708879609440649.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:09:49,635 INFO [SEQ] Epoch 00  val_MAE=27.7553\n",
      "2025-11-23 11:09:50,461 INFO [SEQ] Epoch 01  val_MAE=19.6003\n",
      "2025-11-23 11:09:51,220 INFO [SEQ] Epoch 02  val_MAE=17.1317\n",
      "2025-11-23 11:09:51,984 INFO [SEQ] Epoch 03  val_MAE=14.9467\n",
      "2025-11-23 11:09:52,774 INFO [SEQ] Epoch 04  val_MAE=13.7999\n",
      "2025-11-23 11:09:53,541 INFO [SEQ] Epoch 05  val_MAE=13.7294\n",
      "2025-11-23 11:09:54,383 INFO [SEQ] Epoch 06  val_MAE=12.8784\n",
      "2025-11-23 11:09:55,132 INFO [SEQ] Epoch 07  val_MAE=12.1338\n",
      "2025-11-23 11:09:55,923 INFO [SEQ] Epoch 08  val_MAE=12.6890\n",
      "2025-11-23 11:09:56,749 INFO [SEQ] Epoch 09  val_MAE=13.3904\n",
      "2025-11-23 11:09:57,578 INFO [SEQ] Epoch 10  val_MAE=11.9004\n",
      "2025-11-23 11:09:58,342 INFO [SEQ] Epoch 11  val_MAE=12.5144\n",
      "2025-11-23 11:09:59,282 INFO [SEQ] Epoch 12  val_MAE=12.0707\n",
      "2025-11-23 11:10:00,278 INFO [SEQ] Epoch 13  val_MAE=10.9967\n",
      "2025-11-23 11:10:01,151 INFO [SEQ] Epoch 14  val_MAE=13.7643\n",
      "2025-11-23 11:10:02,141 INFO [SEQ] Epoch 15  val_MAE=11.1064\n",
      "2025-11-23 11:10:03,030 INFO [SEQ] Epoch 16  val_MAE=11.3670\n",
      "2025-11-23 11:10:03,889 INFO [SEQ] Epoch 17  val_MAE=10.8285\n",
      "2025-11-23 11:10:04,750 INFO [SEQ] Epoch 18  val_MAE=10.6057\n",
      "2025-11-23 11:10:05,663 INFO [SEQ] Epoch 19  val_MAE=12.5752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:10:05,700] Trial 3 finished with value: 10.60570379857267 and parameters: {'seq_len': 107, 'hidden': 108, 'layers': 1, 'lr': 0.0030698427779806132, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:10:07,166 INFO [SEQ] Epoch 00  val_MAE=55.3936\n",
      "2025-11-23 11:10:08,128 INFO [SEQ] Epoch 01  val_MAE=42.9187\n",
      "2025-11-23 11:10:09,151 INFO [SEQ] Epoch 02  val_MAE=33.9583\n",
      "2025-11-23 11:10:10,244 INFO [SEQ] Epoch 03  val_MAE=28.0471\n",
      "2025-11-23 11:10:11,235 INFO [SEQ] Epoch 04  val_MAE=23.9831\n",
      "2025-11-23 11:10:12,200 INFO [SEQ] Epoch 05  val_MAE=21.3638\n",
      "2025-11-23 11:10:13,163 INFO [SEQ] Epoch 06  val_MAE=19.4682\n",
      "2025-11-23 11:10:14,115 INFO [SEQ] Epoch 07  val_MAE=18.5127\n",
      "2025-11-23 11:10:15,119 INFO [SEQ] Epoch 08  val_MAE=17.8725\n",
      "2025-11-23 11:10:16,173 INFO [SEQ] Epoch 09  val_MAE=16.8733\n",
      "2025-11-23 11:10:17,252 INFO [SEQ] Epoch 10  val_MAE=16.4990\n",
      "2025-11-23 11:10:18,337 INFO [SEQ] Epoch 11  val_MAE=15.9046\n",
      "2025-11-23 11:10:19,463 INFO [SEQ] Epoch 12  val_MAE=15.8532\n",
      "2025-11-23 11:10:20,576 INFO [SEQ] Epoch 13  val_MAE=15.8595\n",
      "2025-11-23 11:10:21,654 INFO [SEQ] Epoch 14  val_MAE=16.2230\n",
      "2025-11-23 11:10:22,692 INFO [SEQ] Epoch 15  val_MAE=16.3804\n",
      "2025-11-23 11:10:23,704 INFO [SEQ] Epoch 16  val_MAE=15.6435\n",
      "2025-11-23 11:10:24,662 INFO [SEQ] Epoch 17  val_MAE=15.0427\n",
      "2025-11-23 11:10:25,661 INFO [SEQ] Epoch 18  val_MAE=15.8073\n",
      "2025-11-23 11:10:26,655 INFO [SEQ] Epoch 19  val_MAE=15.6322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:10:26,703] Trial 4 finished with value: 15.042698900310361 and parameters: {'seq_len': 95, 'hidden': 76, 'layers': 2, 'lr': 0.0009486657803992307, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:10:29,223 INFO [SEQ] Epoch 00  val_MAE=23.6764\n",
      "2025-11-23 11:10:31,384 INFO [SEQ] Epoch 01  val_MAE=20.2981\n",
      "2025-11-23 11:10:33,590 INFO [SEQ] Epoch 02  val_MAE=19.3953\n",
      "2025-11-23 11:10:35,774 INFO [SEQ] Epoch 03  val_MAE=21.6863\n",
      "2025-11-23 11:10:38,021 INFO [SEQ] Epoch 04  val_MAE=18.9988\n",
      "2025-11-23 11:10:40,259 INFO [SEQ] Epoch 05  val_MAE=18.6391\n",
      "2025-11-23 11:10:42,472 INFO [SEQ] Epoch 06  val_MAE=18.1702\n",
      "2025-11-23 11:10:44,700 INFO [SEQ] Epoch 07  val_MAE=19.1898\n",
      "2025-11-23 11:10:46,895 INFO [SEQ] Epoch 08  val_MAE=18.8266\n",
      "2025-11-23 11:10:48,988 INFO [SEQ] Epoch 09  val_MAE=17.8260\n",
      "2025-11-23 11:10:51,125 INFO [SEQ] Epoch 10  val_MAE=19.9049\n",
      "2025-11-23 11:10:53,379 INFO [SEQ] Epoch 11  val_MAE=20.0333\n",
      "2025-11-23 11:10:55,516 INFO [SEQ] Epoch 12  val_MAE=18.1439\n",
      "2025-11-23 11:10:57,698 INFO [SEQ] Epoch 13  val_MAE=19.4511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:10:57,732] Trial 5 finished with value: 17.826012342330444 and parameters: {'seq_len': 61, 'hidden': 95, 'layers': 2, 'lr': 0.0040411997706326815, 'batch_size': 16, 'model_type': 'gru'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:10:58,710 INFO [SEQ] Epoch 00  val_MAE=66.6261\n",
      "2025-11-23 11:10:59,230 INFO [SEQ] Epoch 01  val_MAE=61.7958\n",
      "2025-11-23 11:10:59,724 INFO [SEQ] Epoch 02  val_MAE=59.0577\n",
      "2025-11-23 11:11:00,228 INFO [SEQ] Epoch 03  val_MAE=56.5956\n",
      "2025-11-23 11:11:00,790 INFO [SEQ] Epoch 04  val_MAE=54.4594\n",
      "2025-11-23 11:11:01,296 INFO [SEQ] Epoch 05  val_MAE=52.3360\n",
      "2025-11-23 11:11:01,839 INFO [SEQ] Epoch 06  val_MAE=50.3878\n",
      "2025-11-23 11:11:02,379 INFO [SEQ] Epoch 07  val_MAE=48.6267\n",
      "2025-11-23 11:11:02,923 INFO [SEQ] Epoch 08  val_MAE=46.9060\n",
      "2025-11-23 11:11:03,456 INFO [SEQ] Epoch 09  val_MAE=45.2268\n",
      "2025-11-23 11:11:03,998 INFO [SEQ] Epoch 10  val_MAE=43.7556\n",
      "2025-11-23 11:11:04,642 INFO [SEQ] Epoch 11  val_MAE=42.3023\n",
      "2025-11-23 11:11:05,283 INFO [SEQ] Epoch 12  val_MAE=40.8449\n",
      "2025-11-23 11:11:05,859 INFO [SEQ] Epoch 13  val_MAE=39.6805\n",
      "2025-11-23 11:11:06,414 INFO [SEQ] Epoch 14  val_MAE=38.2644\n",
      "2025-11-23 11:11:06,982 INFO [SEQ] Epoch 15  val_MAE=37.0124\n",
      "2025-11-23 11:11:07,520 INFO [SEQ] Epoch 16  val_MAE=35.9638\n",
      "2025-11-23 11:11:08,033 INFO [SEQ] Epoch 17  val_MAE=34.6995\n",
      "2025-11-23 11:11:08,622 INFO [SEQ] Epoch 18  val_MAE=33.6888\n",
      "2025-11-23 11:11:09,155 INFO [SEQ] Epoch 19  val_MAE=32.7697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:11:09,195] Trial 6 finished with value: 32.76965533693632 and parameters: {'seq_len': 99, 'hidden': 107, 'layers': 1, 'lr': 0.00019235288824998988, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:11:11,719 INFO [SEQ] Epoch 00  val_MAE=27.5496\n",
      "2025-11-23 11:11:14,181 INFO [SEQ] Epoch 01  val_MAE=20.7852\n",
      "2025-11-23 11:11:16,536 INFO [SEQ] Epoch 02  val_MAE=21.3547\n",
      "2025-11-23 11:11:18,581 INFO [SEQ] Epoch 03  val_MAE=20.5416\n",
      "2025-11-23 11:11:20,856 INFO [SEQ] Epoch 04  val_MAE=21.5792\n",
      "2025-11-23 11:11:23,684 INFO [SEQ] Epoch 05  val_MAE=21.5135\n",
      "2025-11-23 11:11:26,319 INFO [SEQ] Epoch 06  val_MAE=21.4016\n",
      "2025-11-23 11:11:28,913 INFO [SEQ] Epoch 07  val_MAE=25.6757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:11:28,945] Trial 7 finished with value: 20.54162232066593 and parameters: {'seq_len': 45, 'hidden': 80, 'layers': 1, 'lr': 0.007030828893449769, 'batch_size': 16, 'model_type': 'lstm'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:11:31,865 INFO [SEQ] Epoch 00  val_MAE=77.8206\n",
      "2025-11-23 11:11:33,849 INFO [SEQ] Epoch 01  val_MAE=72.9692\n",
      "2025-11-23 11:11:35,793 INFO [SEQ] Epoch 02  val_MAE=68.9167\n",
      "2025-11-23 11:11:37,471 INFO [SEQ] Epoch 03  val_MAE=65.2877\n",
      "2025-11-23 11:11:39,409 INFO [SEQ] Epoch 04  val_MAE=61.7944\n",
      "2025-11-23 11:11:41,479 INFO [SEQ] Epoch 05  val_MAE=58.3931\n",
      "2025-11-23 11:11:43,771 INFO [SEQ] Epoch 06  val_MAE=55.3140\n",
      "2025-11-23 11:11:46,085 INFO [SEQ] Epoch 07  val_MAE=52.3929\n",
      "2025-11-23 11:11:48,140 INFO [SEQ] Epoch 08  val_MAE=49.5071\n",
      "2025-11-23 11:11:49,998 INFO [SEQ] Epoch 09  val_MAE=46.7791\n",
      "2025-11-23 11:11:51,971 INFO [SEQ] Epoch 10  val_MAE=44.2887\n",
      "2025-11-23 11:11:54,362 INFO [SEQ] Epoch 11  val_MAE=41.8809\n",
      "2025-11-23 11:11:56,433 INFO [SEQ] Epoch 12  val_MAE=39.7653\n",
      "2025-11-23 11:11:58,577 INFO [SEQ] Epoch 13  val_MAE=37.7256\n",
      "2025-11-23 11:12:00,725 INFO [SEQ] Epoch 14  val_MAE=35.7698\n",
      "2025-11-23 11:12:03,288 INFO [SEQ] Epoch 15  val_MAE=33.9958\n",
      "2025-11-23 11:12:05,697 INFO [SEQ] Epoch 16  val_MAE=32.4034\n",
      "2025-11-23 11:12:08,084 INFO [SEQ] Epoch 17  val_MAE=30.9460\n",
      "2025-11-23 11:12:10,264 INFO [SEQ] Epoch 18  val_MAE=29.6889\n",
      "2025-11-23 11:12:12,580 INFO [SEQ] Epoch 19  val_MAE=28.5572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:12:12,620] Trial 8 finished with value: 28.557238303774124 and parameters: {'seq_len': 66, 'hidden': 39, 'layers': 1, 'lr': 0.00017997044101444114, 'batch_size': 16, 'model_type': 'lstm'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:12:14,042 INFO [SEQ] Epoch 00  val_MAE=41.0988\n",
      "2025-11-23 11:12:15,093 INFO [SEQ] Epoch 01  val_MAE=27.3748\n",
      "2025-11-23 11:12:16,080 INFO [SEQ] Epoch 02  val_MAE=21.0441\n",
      "2025-11-23 11:12:16,971 INFO [SEQ] Epoch 03  val_MAE=18.4877\n",
      "2025-11-23 11:12:17,901 INFO [SEQ] Epoch 04  val_MAE=17.4932\n",
      "2025-11-23 11:12:18,865 INFO [SEQ] Epoch 05  val_MAE=16.4507\n",
      "2025-11-23 11:12:19,784 INFO [SEQ] Epoch 06  val_MAE=18.1745\n",
      "2025-11-23 11:12:20,764 INFO [SEQ] Epoch 07  val_MAE=16.7064\n",
      "2025-11-23 11:12:21,947 INFO [SEQ] Epoch 08  val_MAE=15.8572\n",
      "2025-11-23 11:12:22,980 INFO [SEQ] Epoch 09  val_MAE=14.5108\n",
      "2025-11-23 11:12:24,063 INFO [SEQ] Epoch 10  val_MAE=14.6344\n",
      "2025-11-23 11:12:25,182 INFO [SEQ] Epoch 11  val_MAE=15.3155\n",
      "2025-11-23 11:12:26,235 INFO [SEQ] Epoch 12  val_MAE=15.1199\n",
      "2025-11-23 11:12:27,217 INFO [SEQ] Epoch 13  val_MAE=13.9629\n",
      "2025-11-23 11:12:28,201 INFO [SEQ] Epoch 14  val_MAE=15.1280\n",
      "2025-11-23 11:12:29,163 INFO [SEQ] Epoch 15  val_MAE=14.3415\n",
      "2025-11-23 11:12:30,273 INFO [SEQ] Epoch 16  val_MAE=15.0912\n",
      "2025-11-23 11:12:31,282 INFO [SEQ] Epoch 17  val_MAE=14.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:12:31,325] Trial 9 finished with value: 13.96290086180556 and parameters: {'seq_len': 90, 'hidden': 123, 'layers': 1, 'lr': 0.0012259228316582405, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 3 with value: 10.60570379857267.\n",
      "Best inner params: {'seq_len': 107, 'hidden': 108, 'layers': 1, 'lr': 0.0030698427779806132, 'batch_size': 32, 'model_type': 'lstm'}\n",
      "Train windows: (7209, 107, 107)  Val windows: (2822, 107, 107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:12:32,683 INFO [SEQ] Epoch 00  val_MAE=28.2923\n",
      "2025-11-23 11:12:33,474 INFO [SEQ] Epoch 01  val_MAE=19.4247\n",
      "2025-11-23 11:12:34,339 INFO [SEQ] Epoch 02  val_MAE=16.2611\n",
      "2025-11-23 11:12:35,185 INFO [SEQ] Epoch 03  val_MAE=15.1007\n",
      "2025-11-23 11:12:35,936 INFO [SEQ] Epoch 04  val_MAE=14.1597\n",
      "2025-11-23 11:12:36,792 INFO [SEQ] Epoch 05  val_MAE=14.6914\n",
      "2025-11-23 11:12:37,586 INFO [SEQ] Epoch 06  val_MAE=14.2662\n",
      "2025-11-23 11:12:38,404 INFO [SEQ] Epoch 07  val_MAE=13.3075\n",
      "2025-11-23 11:12:39,184 INFO [SEQ] Epoch 08  val_MAE=14.2080\n",
      "2025-11-23 11:12:39,986 INFO [SEQ] Epoch 09  val_MAE=18.7420\n",
      "2025-11-23 11:12:40,874 INFO [SEQ] Epoch 10  val_MAE=16.4655\n",
      "2025-11-23 11:12:41,684 INFO [SEQ] Epoch 11  val_MAE=15.6809\n",
      "2025-11-23 11:12:42,527 INFO [SEQ] Epoch 12  val_MAE=15.2432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 3 METRICS: {'MAE': 13.404685974121094, 'RMSE': 22.837573175255645, 'R2': 0.8074919581413269}\n",
      "\n",
      "==============================\n",
      " FINAL Nested CV Results\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.437923</td>\n",
       "      <td>11.001263</td>\n",
       "      <td>0.894977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.621174</td>\n",
       "      <td>30.084636</td>\n",
       "      <td>0.644655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.404686</td>\n",
       "      <td>22.837573</td>\n",
       "      <td>0.807492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE       RMSE        R2\n",
       "0   7.437923  11.001263  0.894977\n",
       "1  16.621174  30.084636  0.644655\n",
       "2  13.404686  22.837573  0.807492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: MAE     12.487928\n",
      "RMSE    21.307824\n",
      "R2       0.782375\n",
      "dtype: float64\n",
      "Std: MAE     4.659760\n",
      "RMSE    9.633218\n",
      "R2      0.127037\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import optuna\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ------------------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------------------\n",
    "OUTER_FOLDS = 3\n",
    "INNER_TRIALS = 10\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# ------------------------------------------\n",
    "# Helper: inner objective for Optuna\n",
    "# ------------------------------------------\n",
    "def inner_objective(trial, train_df, val_df, sequence_features):\n",
    "\n",
    "    seq_len  = trial.suggest_int(\"seq_len\", 40, 120)\n",
    "    hidden   = trial.suggest_int(\"hidden\", 32, 128)\n",
    "    layers   = trial.suggest_int(\"layers\", 1, 2)\n",
    "    lr       = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    batch_sz = trial.suggest_categorical(\"batch_size\", [16,32,64])\n",
    "\n",
    "    # --- build windows ---\n",
    "    Xtr, ytr, _ = make_windows(train_df, sequence_features, seq_len=seq_len)\n",
    "    Xva, yva, _ = make_windows(val_df,  sequence_features, seq_len=seq_len)\n",
    "\n",
    "    if len(Xtr) == 0 or len(Xva) == 0:\n",
    "        return float(\"inf\")\n",
    "\n",
    "    train_loader = DataLoader(SequenceDataset(Xtr, ytr), batch_size=batch_sz, shuffle=True)\n",
    "    val_loader   = DataLoader(SequenceDataset(Xva, yva), batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    # Try both LSTM and GRU inside nested CV.\n",
    "    model_type = trial.suggest_categorical(\"model_type\", [\"lstm\", \"gru\"])\n",
    "\n",
    "    n_features = len(sequence_features)\n",
    "\n",
    "    if model_type == \"lstm\":\n",
    "        model = LSTMRegressor(n_features, hidden, layers)\n",
    "    else:\n",
    "        model = GRURegressor(n_features, hidden, layers)\n",
    "\n",
    "    model, best_mae = train_sequence_model(\n",
    "        model, train_loader, val_loader,\n",
    "        lr=lr, epochs=20, patience=4, device=DEVICE\n",
    "    )\n",
    "\n",
    "    return best_mae\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# OUTER NESTED CV LOOP\n",
    "# -----------------------------------------------------\n",
    "units = train_df[\"unit\"].unique()\n",
    "outer_tscv = TimeSeriesSplit(n_splits=OUTER_FOLDS)\n",
    "\n",
    "outer_results = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(outer_tscv.split(units)):\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" OUTER FOLD {fold+1}/{OUTER_FOLDS}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    train_units = units[tr_idx]\n",
    "    val_units   = units[va_idx]\n",
    "\n",
    "    train_units_df = train_df[train_df[\"unit\"].isin(train_units)].copy()\n",
    "    val_units_df   = train_df[train_df[\"unit\"].isin(val_units)].copy()\n",
    "\n",
    "    print(\"Train units:\", len(train_units), \" Val units:\", len(val_units))\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # INNER OPTUNA\n",
    "    # ------------------------------------------\n",
    "    def objective(trial):\n",
    "        return inner_objective(trial, train_units_df, val_units_df, sequence_features)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=INNER_TRIALS, show_progress_bar=True)\n",
    "\n",
    "    print(\"Best inner params:\", study.best_params)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    seq_len     = best_params[\"seq_len\"]\n",
    "    hidden      = best_params[\"hidden\"]\n",
    "    layers      = best_params[\"layers\"]\n",
    "    lr          = best_params[\"lr\"]\n",
    "    batch_sz    = best_params[\"batch_size\"]\n",
    "    model_type  = best_params[\"model_type\"]\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Retrain best model on outer-train\n",
    "    # ------------------------------------------\n",
    "    Xtr, ytr, _ = make_windows(train_units_df, sequence_features, seq_len=seq_len)\n",
    "    Xva, yva, _ = make_windows(val_units_df,   sequence_features, seq_len=seq_len)\n",
    "\n",
    "    print(\"Train windows:\", Xtr.shape, \" Val windows:\", Xva.shape)\n",
    "\n",
    "    train_loader = DataLoader(SequenceDataset(Xtr, ytr), batch_size=batch_sz, shuffle=True)\n",
    "    val_loader   = DataLoader(SequenceDataset(Xva, yva), batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    n_features = len(sequence_features)\n",
    "\n",
    "    if model_type == \"lstm\":\n",
    "        model = LSTMRegressor(n_features, hidden, layers)\n",
    "    else:\n",
    "        model = GRURegressor(n_features, hidden, layers)\n",
    "\n",
    "    model, _ = train_sequence_model(\n",
    "        model, train_loader, val_loader,\n",
    "        lr=lr, epochs=25, patience=5, device=DEVICE\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Evaluate outer fold\n",
    "    # ------------------------------------------\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in val_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            preds.extend(model(xb).cpu().numpy())\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    metrics = regression_metrics(yva, preds)\n",
    "\n",
    "    print(f\"FOLD {fold+1} METRICS:\", metrics)\n",
    "    outer_results.append(metrics)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# FINAL AGGREGATED RESULTS\n",
    "# -----------------------------------------------------\n",
    "outer_df = pd.DataFrame(outer_results)\n",
    "print(\"\\n==============================\")\n",
    "print(\" FINAL Nested CV Results\")\n",
    "print(\"==============================\")\n",
    "display(outer_df)\n",
    "print(\"Mean:\", outer_df.mean())\n",
    "print(\"Std:\", outer_df.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7783596a-d500-48e2-acb8-f3f0ddb113db",
   "metadata": {},
   "source": [
    "#### Final RUL Model Selection for the Agent (LSTM)\n",
    "\n",
    "In previous experiments, we observed that:\n",
    "\n",
    "Simple train/validation splits produced unrealistically strong results (MAE â‰ˆ 5â€“6).\n",
    "\n",
    "After running Sequence Nested Cross-Validation (LSTM + GRU), we obtained more reliable and unbiased estimates:\n",
    "\n",
    "| Fold | MAE   | RMSE  | R2   |\n",
    "| ---- | ----- | ----- | ---- |\n",
    "| 0    | ~7.4  | ~11.0 | 0.89 |\n",
    "| 1    | ~16.6 | ~30.0 | 0.64 |\n",
    "| 2    | ~13.4 | ~22.8 | 0.80 |\n",
    "\n",
    "The mean performance of the sequence model family is:\n",
    "\n",
    "MAE â‰ˆ 12.5\n",
    "\n",
    "RMSE â‰ˆ 21.3\n",
    "\n",
    "RÂ² â‰ˆ 0.78\n",
    "\n",
    "These values are realistic and consistent with published CMAPSS RUL benchmarks, unlike the overly optimistic single-split results.\n",
    "\n",
    "Final proposed model:\n",
    "\n",
    "Model type: GRU\n",
    "\n",
    "seq_len: 96\n",
    "\n",
    "hidden_size: 110\n",
    "\n",
    "num_layers: 2\n",
    "\n",
    "lr: 0.001363\n",
    "\n",
    "batch_size: 32\n",
    "\n",
    "This model showed:\n",
    "\n",
    "Most stable learning\n",
    "\n",
    "Lowest MAE\n",
    "\n",
    "No divergence\n",
    "\n",
    "Seq_len suitable for CMAPSS\n",
    "\n",
    "Suitable feature dimension space (75 engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d55bc7e-d745-4653-a9c5-0e69e93147c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using final GRU hyperparameters: {'seq_len': 96, 'hidden': 110, 'layers': 2, 'lr': 0.001363, 'batch_size': 32}\n",
      "Using 107 sequence features.\n",
      "Train rows: (18525, 428) Val rows: (2106, 428)\n",
      "Final training windows: (9025, 96, 107) Val windows: (0, 96, 107)\n",
      "Training on: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 12:12:16,970 INFO [SEQ] Epoch 00  val_MAE=nan\n",
      "2025-11-23 12:12:17,792 INFO [SEQ] Epoch 01  val_MAE=nan\n",
      "2025-11-23 12:12:18,656 INFO [SEQ] Epoch 02  val_MAE=nan\n",
      "2025-11-23 12:12:19,658 INFO [SEQ] Epoch 03  val_MAE=nan\n",
      "2025-11-23 12:12:20,638 INFO [SEQ] Epoch 04  val_MAE=nan\n",
      "2025-11-23 12:12:21,627 INFO [SEQ] Epoch 05  val_MAE=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation MAE: inf\n",
      "Saved final GRU model and metadata to: artifacts\\final_model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from agentic_pm.modeling.model_selection import make_windows, SequenceDataset, train_sequence_model\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Load final processed dataset\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"data/processed/CMAPSS/train_FD001_final.csv\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Best hyperparameters (Fold 1 winner)\n",
    "# ----------------------------\n",
    "SEQ_LEN    = 96\n",
    "HIDDEN     = 110\n",
    "LAYERS     = 2\n",
    "LR         = 0.001363\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS     = 40\n",
    "PATIENCE   = 6\n",
    "\n",
    "print(\"Using final GRU hyperparameters:\", {\n",
    "    \"seq_len\": SEQ_LEN,\n",
    "    \"hidden\": HIDDEN,\n",
    "    \"layers\": LAYERS,\n",
    "    \"lr\": LR,\n",
    "    \"batch_size\": BATCH_SIZE\n",
    "})\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Features to use (sequence features)\n",
    "# ----------------------------\n",
    "assert \"sequence_features\" in globals(), \"âŒ You must define sequence_features before running this cell\"\n",
    "\n",
    "print(f\"Using {len(sequence_features)} sequence features.\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Create holdout validation (Last 10% for each unit)\n",
    "# ----------------------------\n",
    "def per_unit_holdout_df(df, val_frac=0.10):\n",
    "    train_rows = []\n",
    "    val_rows = []\n",
    "\n",
    "    for u, g in df.groupby(\"unit\"):\n",
    "        cutoff = int(len(g) * (1 - val_frac))\n",
    "        train_rows.append(g.iloc[:cutoff])\n",
    "        val_rows.append(g.iloc[cutoff:])\n",
    "\n",
    "    return pd.concat(train_rows), pd.concat(val_rows)\n",
    "\n",
    "train_df, val_df = per_unit_holdout_df(df, val_frac=0.10)\n",
    "\n",
    "print(\"Train rows:\", train_df.shape, \"Val rows:\", val_df.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Create final windows\n",
    "# ----------------------------\n",
    "Xtr, ytr, _ = make_windows(train_df, sequence_features, seq_len=SEQ_LEN)\n",
    "Xva, yva, _ = make_windows(val_df, sequence_features, seq_len=SEQ_LEN)\n",
    "\n",
    "print(\"Final training windows:\", Xtr.shape, \"Val windows:\", Xva.shape)\n",
    "\n",
    "train_loader = DataLoader(SequenceDataset(Xtr, ytr), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(SequenceDataset(Xva, yva), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Define GRU model\n",
    "# ----------------------------\n",
    "class GRURegressor(nn.Module):\n",
    "    def __init__(self, n_features, hidden_size=64, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=n_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, h_n = self.gru(x)\n",
    "        last = h_n[-1]\n",
    "        return self.fc(last).squeeze(1)\n",
    "\n",
    "# instantiate model\n",
    "model = GRURegressor(\n",
    "    n_features=len(sequence_features),\n",
    "    hidden_size=HIDDEN,\n",
    "    num_layers=LAYERS,\n",
    "    dropout=0.10\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Training on:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Train final model\n",
    "# ----------------------------\n",
    "model, best_val = train_sequence_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    lr=LR,\n",
    "    epochs=EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Final validation MAE:\", best_val)\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Save model + metadata\n",
    "# ----------------------------\n",
    "SAVE_DIR = Path(\"artifacts/final_model\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), SAVE_DIR / \"gru_final_weights.pth\")\n",
    "\n",
    "metadata = {\n",
    "    \"model_type\": \"GRU\",\n",
    "    \"seq_len\": SEQ_LEN,\n",
    "    \"hidden\": HIDDEN,\n",
    "    \"layers\": LAYERS,\n",
    "    \"dropout\": 0.10,\n",
    "    \"lr\": LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"features\": sequence_features\n",
    "}\n",
    "\n",
    "joblib.dump(metadata, SAVE_DIR / \"gru_final_metadata.pkl\")\n",
    "\n",
    "print(\"Saved final GRU model and metadata to:\", SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb413a0a-bcf9-4c22-a329-1147ac85015a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
