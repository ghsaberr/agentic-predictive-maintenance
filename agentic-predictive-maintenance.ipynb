{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902a7186-2e68-403e-9622-84053bfbafc8",
   "metadata": {},
   "source": [
    "# Agentic Predictive Maintenance for Insured Assets\n",
    "---\n",
    "**Objective:** Develop an agentic predictive maintenance solution using time-series sensor data.\n",
    "\n",
    "**Core Components:**\n",
    "* **Data:** Time-series sensor data, policy data, and maintenance logs/manuals.\n",
    "* **Model:** Time-aware model selection (forecasting/classification) and hyperparameter tuning.\n",
    "* **Agent:** An AI agent combining deterministic checks, RAG (retrieval from manuals), and LLM reasoning to provide explainable maintenance recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1ec4a0-3ffc-43b3-b998-f243d9d1b38e",
   "metadata": {},
   "source": [
    "## Batch Processing: Full Pipeline for All Datasets (FD001-FD004)\n",
    "\n",
    "This cell executes the complete **Data Engineering Pipeline** for all four CMAPSS subsets.\n",
    "It orchestrates the modules we created earlier (`data_ingest`, `time_cleaning`, `feature_tools`, `scaling`).\n",
    "\n",
    "**Pipeline Logic per Dataset:**\n",
    "1.  **Ingest:** Loads raw text files, computes RUL, saves intermediate CSVs.\n",
    "2.  **Clean:** Aligns cycles, fills missing values (imputation), and caps outliers.\n",
    "3.  **Feature Engineering:** Generates temporal features (rolling mean/std, lag, trends) and anomaly indicators on the *physical* (unscaled) values.\n",
    "4.  **Scaling:**\n",
    "    * **FD001 & FD003:** Uses `Global Standardization` (single scaler).\n",
    "    * **FD002 & FD004:** Uses `Conditional Standardization` (clusters data by operating conditions first, then scales per cluster) to handle complex regimes.\n",
    "5.  **Save:** exports the final, model-ready data to `data/processed/CMAPSS/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea67e712-d29a-4150-85b0-70a5f5b9acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Batch Processing for All Subsets...\n",
      "\n",
      "========================================\n",
      "Processing Subset: FD001\n",
      "========================================\n",
      "Ingesting data...\n",
      "[data_ingest] Processing FD001 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD001\\train_FD001_raw.csv, data\\intermediate\\CMAPSS\\FD001\\test_FD001_raw.csv\n",
      "Cleaning data (Align, Impute, Cap Outliers)...\n",
      "Engineering Features...\n",
      "Scaling features...\n",
      "   -> Using Global Standardization\n",
      "[scaling] Saved global scaler: artifacts\\scalers\\FD001_global_scaler.pkl\n",
      "Saving final processed data...\n",
      "Done with FD001 in 876.66 seconds.\n",
      "   Saved shape: Train (20631, 428), Test (13096, 428)\n",
      "\n",
      "========================================\n",
      "Processing Subset: FD002\n",
      "========================================\n",
      "Ingesting data...\n",
      "[data_ingest] Processing FD002 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD002\\train_FD002_raw.csv, data\\intermediate\\CMAPSS\\FD002\\test_FD002_raw.csv\n",
      "Cleaning data (Align, Impute, Cap Outliers)...\n",
      "Engineering Features...\n",
      "Scaling features...\n",
      "   -> Using Conditional Standardization (Clustering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.02310017 -0.02310017 -0.02310017 ... -0.02310017 -0.02310017\n",
      " -0.02310017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0326773 -0.0326773 -0.0326773 ... -0.0326773 -0.0326773 -0.0326773]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.06121538 -0.06121538 -0.06121538 ... -0.06121538 -0.06121538\n",
      " -0.06121538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03906578 -0.03906578 -0.03906578 ... -0.03906578 -0.03906578\n",
      " -0.03906578]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00872905 -0.00872905 -0.00872905 ... -0.00872905 -0.00872905\n",
      " -0.00872905]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.02310017 -0.02310017 -0.02310017 ... -0.02310017 -0.02310017\n",
      " -0.02310017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0326773 -0.0326773 -0.0326773 ... -0.0326773 -0.0326773 -0.0326773]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.06121538 -0.06121538 -0.06121538 ... -0.06121538 -0.06121538\n",
      " -0.06121538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03906578 -0.03906578 -0.03906578 ... -0.03906578 -0.03906578\n",
      " -0.03906578]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00872905 -0.00872905 -0.00872905 ... -0.00872905 -0.00872905\n",
      " -0.00872905]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scaling] Saved 6 cluster scalers and unit->cluster map for FD002\n",
      "Saving final processed data...\n",
      "Done with FD002 in 11630.11 seconds.\n",
      "   Saved shape: Train (53759, 429), Test (33991, 429)\n",
      "\n",
      "========================================\n",
      "Processing Subset: FD003\n",
      "========================================\n",
      "Ingesting data...\n",
      "[data_ingest] Processing FD003 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD003\\train_FD003_raw.csv, data\\intermediate\\CMAPSS\\FD003\\test_FD003_raw.csv\n",
      "Cleaning data (Align, Impute, Cap Outliers)...\n",
      "Engineering Features...\n",
      "Scaling features...\n",
      "   -> Using Global Standardization\n",
      "[scaling] Saved global scaler: artifacts\\scalers\\FD003_global_scaler.pkl\n",
      "Saving final processed data...\n",
      "Done with FD003 in 931.12 seconds.\n",
      "   Saved shape: Train (24720, 428), Test (16596, 428)\n",
      "\n",
      "========================================\n",
      "Processing Subset: FD004\n",
      "========================================\n",
      "Ingesting data...\n",
      "[data_ingest] Processing FD004 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD004\\train_FD004_raw.csv, data\\intermediate\\CMAPSS\\FD004\\test_FD004_raw.csv\n",
      "Cleaning data (Align, Impute, Cap Outliers)...\n",
      "Engineering Features...\n",
      "Scaling features...\n",
      "   -> Using Conditional Standardization (Clustering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01730062 -0.01730062 -0.01730062 ... -0.01730062 -0.01730062\n",
      " -0.01730062]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.09715425 -0.09715425 -0.09715425 ... -0.09715425 -0.09715425\n",
      " -0.09715425]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03119965 -0.03119965 -0.03119965 ... -0.03119965 -0.03119965\n",
      " -0.03119965]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0561403 -0.0561403 -0.0561403 ... -0.0561403 -0.0561403 -0.0561403]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03772701 -0.03772701 -0.03772701 ... -0.03772701 -0.03772701\n",
      " -0.03772701]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0967612 -0.0967612 -0.0967612 ... -0.0967612 -0.0967612 -0.0967612]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01730062 -0.01730062 -0.01730062 ... -0.01730062 -0.01730062\n",
      " -0.01730062]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.09715425 -0.09715425 -0.09715425 ... -0.09715425 -0.09715425\n",
      " -0.09715425]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03119965 -0.03119965 -0.03119965 ... -0.03119965 -0.03119965\n",
      " -0.03119965]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0561403 -0.0561403 -0.0561403 ... -0.0561403 -0.0561403 -0.0561403]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03772701 -0.03772701 -0.03772701 ... -0.03772701 -0.03772701\n",
      " -0.03772701]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0967612 -0.0967612 -0.0967612 ... -0.0967612 -0.0967612 -0.0967612]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01140124 -0.01140124 -0.01140124 ... -0.01140124 -0.01140124\n",
      " -0.01140124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01140124 -0.01140124 -0.01140124 ... -0.01140124 -0.01140124\n",
      " -0.01140124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scaling] Saved 6 cluster scalers and unit->cluster map for FD004\n",
      "Saving final processed data...\n",
      "Done with FD004 in 2228.22 seconds.\n",
      "   Saved shape: Train (61249, 429), Test (41214, 429)\n",
      "\n",
      " ALL DATASETS PROCESSED SUCCESSFULLY! \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# --- 1. Suppress Warnings ---\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# 1. Import Modules\n",
    "from agentic_pm import data_ingest, time_cleaning, feature_tools, scaling\n",
    "\n",
    "# --- CONFIG ---\n",
    "SUBSETS = [\"FD001\", \"FD002\", \"FD003\", \"FD004\"]\n",
    "\n",
    "RAW_DIR = Path(\"data/raw/CMAPSS\")\n",
    "INTERMEDIATE_DIR = Path(\"data/intermediate/CMAPSS\")\n",
    "PROCESSED_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SCALER_DIR = Path(\"artifacts/scalers\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SCALER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def run_full_pipeline(subset_name):\n",
    "    \"\"\"\n",
    "    Runs the End-to-End Pipeline for a single subset:\n",
    "    Ingest -> Clean -> Feature Eng -> Scale -> Save\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Processing Subset: {subset_name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 1: INGEST (Load Raw & Compute RUL)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"Ingesting data...\")\n",
    "    data_ingest.process_subset(subset_name, raw_base=RAW_DIR, out_base=INTERMEDIATE_DIR)\n",
    "    \n",
    "    # Load intermediate raw data\n",
    "    train_df = pd.read_csv(INTERMEDIATE_DIR / subset_name / f\"train_{subset_name}_raw.csv\")\n",
    "    test_df  = pd.read_csv(INTERMEDIATE_DIR / subset_name / f\"test_{subset_name}_raw.csv\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 2: CLEANING\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"Cleaning data (Align, Impute, Cap Outliers)...\")\n",
    "    train_df = time_cleaning.align_cycles(train_df)\n",
    "    train_df = time_cleaning.impute_missing(train_df)\n",
    "    train_df = time_cleaning.cap_outliers(train_df)\n",
    "\n",
    "    test_df = time_cleaning.align_cycles(test_df)\n",
    "    test_df = time_cleaning.impute_missing(test_df)\n",
    "    test_df = time_cleaning.cap_outliers(test_df)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 3: FEATURE ENGINEERING (On Physical Values)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"Engineering Features...\")\n",
    "    # Train\n",
    "    train_df = feature_tools.create_temporal_features(train_df)\n",
    "    train_df = feature_tools.create_anomaly_indicators(train_df)\n",
    "    train_df = feature_tools.compute_health_index(train_df)\n",
    "    \n",
    "    # Test\n",
    "    test_df = feature_tools.create_temporal_features(test_df)\n",
    "    test_df = feature_tools.create_anomaly_indicators(test_df)\n",
    "    test_df = feature_tools.compute_health_index(test_df)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 4: SCALING (Prepare for ML Model)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"Scaling features...\")\n",
    "    \n",
    "    # Identify feature columns (exclude metadata)\n",
    "    # We exclude 'unit', 'cycle', 'RUL', 'gap_flag' and the raw 'op_settings' if we want\n",
    "    # Usually we KEEP op_settings as features, but we scale them.\n",
    "    cols_to_exclude = ['unit', 'cycle', 'RUL', 'gap_flag', 'anom_score'] \n",
    "    # Note: 'anom_score' is 0-1 flag based, usually doesn't need scaling, but can be scaled.\n",
    "    # Let's include everything else.\n",
    "    feature_cols = [c for c in train_df.columns if c not in cols_to_exclude]\n",
    "\n",
    "    # Logic: FD001/FD003 -> Global Scaling\n",
    "    #        FD002/FD004 -> Conditional Scaling (due to multiple operating conditions)\n",
    "    if subset_name in [\"FD001\", \"FD003\"]:\n",
    "        print(f\"   -> Using Global Standardization\")\n",
    "        train_scaled, test_scaled, _ = scaling.global_standardize(\n",
    "            train_df, test_df, feature_cols, subset_name=subset_name\n",
    "        )\n",
    "    else:\n",
    "        print(f\"   -> Using Conditional Standardization (Clustering)\")\n",
    "        op_cols = [\"op_setting_1\", \"op_setting_2\", \"op_setting_3\"]\n",
    "        train_scaled, test_scaled, _, _ = scaling.conditional_standardize(\n",
    "            train_df, test_df, feature_cols, op_cols, subset_name=subset_name\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 5: SAVE FINAL DATA\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"Saving final processed data...\")\n",
    "    final_train_path = PROCESSED_DIR / f\"train_{subset_name}_final.csv\"\n",
    "    final_test_path = PROCESSED_DIR / f\"test_{subset_name}_final.csv\"\n",
    "    \n",
    "    train_scaled.to_csv(final_train_path, index=False)\n",
    "    test_scaled.to_csv(final_test_path, index=False)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Done with {subset_name} in {elapsed:.2f} seconds.\")\n",
    "    print(f\"   Saved shape: Train {train_scaled.shape}, Test {test_scaled.shape}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION LOOP\n",
    "# ==========================================\n",
    "print(\"Starting Batch Processing for All Subsets...\")\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    try:\n",
    "        run_full_pipeline(subset)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n FAILED on {subset}: {e}\")\n",
    "        # Uncomment 'raise' if you want to stop the whole notebook on error\n",
    "        # raise e \n",
    "\n",
    "print(\"\\n ALL DATASETS PROCESSED SUCCESSFULLY! \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d633a83-bb02-4e11-b372-c328302bde24",
   "metadata": {},
   "source": [
    "### Labeling & Problem Framing\n",
    "\n",
    "#### 1. Task Definition\n",
    "For this project, we explicitly define the prediction task as:\n",
    "\n",
    "- **Remaining Useful Life (RUL) Regression**  \n",
    "  The model predicts the number of cycles remaining before the asset reaches end-of-life (failure threshold).  \n",
    "  Alternative tasks (A: time-to-failure regression, B: binary/multi-class maintenance classification) were considered but not selected for this iteration.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Assumptions\n",
    "- Each *cycle* in the CMAPSS dataset represents a consistent time step (uniform sampling frequency).  \n",
    "- The degradation process is monotonic toward failure within each units operational trajectory.  \n",
    "- Units in the training set run until failure; units in the test set are truncated before failure.  \n",
    "- Sensor measurements are assumed to be correctly calibrated and synchronized.  \n",
    "- No maintenance occurs during each units recorded run unless explicitly annotated.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Sampling Frequency\n",
    "- **Sampling interval:** One record per engine per cycle (i.e., *per-cycle sampling*).  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Label Generation Rules\n",
    "\n",
    "##### **Training Data**\n",
    "- Each unit runs until failure; therefore:\n",
    "  \n",
    "$$ RUL_{train}(unit, t) = \\text{max\\_cycle}(unit) - t $$\n",
    "\n",
    "##### **Test Data**\n",
    "- Test trajectories end before failure. Ground-truth final RUL values are provided separately.\n",
    "\n",
    "$$ RUL_{test}(unit, t) = RUL_{given}(unit) + (\\text{final\\_cycle}(unit) - t) $$\n",
    "\n",
    "##### **Optional Enhancements**\n",
    "- Clip large RUL values (e.g., max 130 cycles) to stabilize model training.  \n",
    "- Apply transformations (e.g., `log1p(RUL)`) when using models sensitive to scale.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Example Asset Timelines (Annotated)\n",
    "\n",
    "Below we illustrate two example trajectories:\n",
    "\n",
    "1. **Training unit (full run):**\n",
    "   - Starts healthy, degrades over time, ends in a failure event.  \n",
    "   - RUL decreases linearly with respect to cycle index until reaching zero at the final cycle.\n",
    "\n",
    "2. **Test unit (truncated run):**\n",
    "   - Sequence ends before failure.  \n",
    "   - Final RUL label is assigned by combining the provided RUL file with the time remaining from the last observed cycle.\n",
    "\n",
    "These annotated timelines help verify label correctness, confirm continuity, and validate assumptions about degradation behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4811fd-658d-4687-9e9c-0cf1f84bd25a",
   "metadata": {},
   "source": [
    "#  Project Status Checkpoint: Data Pipeline & Feature Engineering\n",
    "\n",
    "At this stage, we have successfully implemented the **Data Engineering** and **Tool Definition** layers of our Agentic Predictive Maintenance system. Instead of raw processing within the notebook, we have modularized our code into the `agentic_pm` package for reproducibility and scalability.\n",
    "\n",
    "### Summary of Accomplishments:\n",
    "\n",
    "#### 1. Data Ingestion & Cleaning (Layer 1)\n",
    "We processed the raw CMAPSS datasets (FD001-FD004) through a rigorous cleaning pipeline:\n",
    "* **Ingestion:** Loaded raw text files and computed the **Remaining Useful Life (RUL)** target.\n",
    "* **Alignment:** Used `align_cycles` to create a continuous time index for each asset, handling missing timestamps.\n",
    "* **Imputation:** Filled sensor gaps using linear interpolation (`impute_missing`).\n",
    "* **Noise Reduction:** Applied a rolling Z-score filter (`cap_outliers`) to smooth extreme sensor spikes while retaining the signal.\n",
    "\n",
    "#### 2. Feature Engineering (Layer 2)\n",
    "We generated advanced features on the *cleaned physical values* (before normalization) to capture temporal dynamics:\n",
    "* **Temporal Features:** Rolling Means & Standard Deviations (window sizes 5, 15, 60), Exponential Moving Averages (EMA), and Lag features.\n",
    "* **Anomaly Indicators:** Computed Z-scores and change-point detection flags to highlight abnormal sensor behavior.\n",
    "* **Health Index:** Created a composite score combining weighted sensor values to represent overall asset health.\n",
    "\n",
    "#### 3. Agent Tools (Layer 3)\n",
    "We implemented deterministic tools that our AI Agent will call later:\n",
    "* **`diagnostic_checker`:** A rule-based tool that checks specific physical thresholds (e.g., *Temperature > 800C*) to flag immediate risks.\n",
    "* **`maintenance_simulator`:** A \"what-if\" tool to simulate the impact of preventive maintenance on failure probability.\n",
    "\n",
    "#### 4. Scaling & Normalization (Layer 4)\n",
    "To prepare the data for Machine Learning models, we applied dataset-specific scaling:\n",
    "* **Global Standardization:** Applied to **FD001 & FD003** (single operating condition).\n",
    "* **Conditional Standardization:** Applied to **FD002 & FD004** (multiple operating conditions), using KMeans clustering to normalize data within specific operating regimes.\n",
    "\n",
    "---\n",
    "** Current State:** Cleaned, feature-engineered, and normalized datasets are saved in `data/processed/CMAPSS/`.\n",
    "** Next Step:** We will now proceed to **Step 3: Model Selection**, where we will train and evaluate models (XGBoost, etc.) using time-aware validation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111447f4-09ec-4058-b602-b7ca1d494e08",
   "metadata": {},
   "source": [
    "## 3. Model Selection, Hyperparameter Tuning & Evaluation\n",
    "\n",
    "CMAPSS Predictive Maintenance  Full Modeling Pipeline\n",
    "\n",
    "Tabular + Sequence Models + Anomaly Detection + Comparison\n",
    "\n",
    "This notebook uses the final processed datasets created by the preprocessing pipeline:\n",
    "   data/processed/CMAPSS/train_FD00X_final.csv\n",
    "   data/processed/CMAPSS/test_FD00X_final.csv\n",
    "\n",
    "It evaluates:\n",
    "- Classical tabular models (RandomForest, ElasticNet, LightGBM)\n",
    "- Sequence models (LSTM, GRU, Mini-TCN)\n",
    "- Anomaly model (IsolationForest) and using its score as a feature\n",
    "- Comparison table summarizing metrics\n",
    "\n",
    "### 3.1 Import & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12648b07-24ad-4a12-a0b5-c34f5504d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready. Torch: True LightGBM: True Optuna: True\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# modeling utilities we created\n",
    "from agentic_pm.modeling import model_selection as ms\n",
    "\n",
    "# optional libs - we'll check availability\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "except Exception:\n",
    "    optuna = None\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "except Exception:\n",
    "    torch = None\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import joblib\n",
    "\n",
    "print(\"Environment ready. Torch:\", bool(torch), \"LightGBM:\", bool(lgb), \"Optuna:\", bool(optuna))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40bc9c0-667c-4458-b995-47d914200573",
   "metadata": {},
   "source": [
    "### 3.2 Load Final Datasets\n",
    "Choose subset (FD001..FD004) and load the final train/test CSVs produced by your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d14d73-e549-4276-9309-b3821c56a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files:\n",
      " - data\\processed\\CMAPSS\\train_FD001_final.csv (20631, 428)\n",
      " - data\\processed\\CMAPSS\\test_FD001_final.csv (13096, 428)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>unit</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_13_norm_unit</th>\n",
       "      <th>sensor_14_norm_unit</th>\n",
       "      <th>sensor_15_norm_unit</th>\n",
       "      <th>sensor_16_norm_unit</th>\n",
       "      <th>sensor_17_norm_unit</th>\n",
       "      <th>sensor_18_norm_unit</th>\n",
       "      <th>sensor_19_norm_unit</th>\n",
       "      <th>sensor_20_norm_unit</th>\n",
       "      <th>sensor_21_norm_unit</th>\n",
       "      <th>health_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.315980</td>\n",
       "      <td>-1.372953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.721725</td>\n",
       "      <td>-0.134255</td>\n",
       "      <td>-0.925936</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278164</td>\n",
       "      <td>1.997798</td>\n",
       "      <td>-0.380157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.354811</td>\n",
       "      <td>1.317629</td>\n",
       "      <td>-0.534520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872722</td>\n",
       "      <td>-1.031720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.061780</td>\n",
       "      <td>0.211528</td>\n",
       "      <td>-0.643726</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636957</td>\n",
       "      <td>1.072544</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991643</td>\n",
       "      <td>1.360548</td>\n",
       "      <td>-0.438211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.961874</td>\n",
       "      <td>1.015677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-0.413166</td>\n",
       "      <td>-0.525953</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.149922</td>\n",
       "      <td>1.298342</td>\n",
       "      <td>-0.435259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.053313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689003</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>-0.618248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324090</td>\n",
       "      <td>-0.008022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-1.261314</td>\n",
       "      <td>-0.784831</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508715</td>\n",
       "      <td>1.376204</td>\n",
       "      <td>-2.042955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265307</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>-0.765705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.864611</td>\n",
       "      <td>-0.690488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621816</td>\n",
       "      <td>-1.251528</td>\n",
       "      <td>-0.301518</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021681</td>\n",
       "      <td>1.372310</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.223972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386363</td>\n",
       "      <td>1.181405</td>\n",
       "      <td>-0.317219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cycle  unit  op_setting_1  op_setting_2  op_setting_3  sensor_1  sensor_2  \\\n",
       "0      1     1     -0.315980     -1.372953           0.0       0.0 -1.721725   \n",
       "1      2     1      0.872722     -1.031720           0.0       0.0 -1.061780   \n",
       "2      3     1     -1.961874      1.015677           0.0       0.0 -0.661813   \n",
       "3      4     1      0.324090     -0.008022           0.0       0.0 -0.661813   \n",
       "4      5     1     -0.864611     -0.690488           0.0       0.0 -0.621816   \n",
       "\n",
       "   sensor_3  sensor_4      sensor_5  ...  sensor_13_norm_unit  \\\n",
       "0 -0.134255 -0.925936 -5.329071e-15  ...            -1.278164   \n",
       "1  0.211528 -0.643726 -5.329071e-15  ...            -0.636957   \n",
       "2 -0.413166 -0.525953 -5.329071e-15  ...            -1.149922   \n",
       "3 -1.261314 -0.784831 -5.329071e-15  ...            -0.508715   \n",
       "4 -1.251528 -0.301518 -5.329071e-15  ...            -1.021681   \n",
       "\n",
       "   sensor_14_norm_unit  sensor_15_norm_unit  sensor_16_norm_unit  \\\n",
       "0             1.997798            -0.380157                  0.0   \n",
       "1             1.072544             0.018526                  0.0   \n",
       "2             1.298342            -0.435259                  0.0   \n",
       "3             1.376204            -2.042955                  0.0   \n",
       "4             1.372310            -0.059266                  0.0   \n",
       "\n",
       "   sensor_17_norm_unit  sensor_18_norm_unit  sensor_19_norm_unit  \\\n",
       "0            -0.833752                  0.0                  0.0   \n",
       "1            -0.833752                  0.0                  0.0   \n",
       "2            -2.053313                  0.0                  0.0   \n",
       "3            -0.833752                  0.0                  0.0   \n",
       "4            -0.223972                  0.0                  0.0   \n",
       "\n",
       "   sensor_20_norm_unit  sensor_21_norm_unit  health_index  \n",
       "0             1.354811             1.317629     -0.534520  \n",
       "1             0.991643             1.360548     -0.438211  \n",
       "2             0.689003             0.619718     -0.618248  \n",
       "3             0.265307             0.896829     -0.765705  \n",
       "4             0.386363             1.181405     -0.317219  \n",
       "\n",
       "[5 rows x 428 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SUBSET = \"FD001\"   # change if you want FD002/FD003/FD004\n",
    "\n",
    "train_path = DATA_DIR / f\"train_{SUBSET}_final.csv\"\n",
    "test_path  = DATA_DIR / f\"test_{SUBSET}_final.csv\"\n",
    "\n",
    "assert train_path.exists(), f\"Train file missing: {train_path}\"\n",
    "assert test_path.exists(),  f\"Test file missing: {test_path}\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Loaded files:\")\n",
    "print(\" -\", train_path, train_df.shape)\n",
    "print(\" -\", test_path, test_df.shape)\n",
    "display(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532787d-1ab6-4966-aad0-8292de4df389",
   "metadata": {},
   "source": [
    "### 3.3 Basic sanity checks\n",
    "Check RUL, missing values, and columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c783d5d-68cc-4622-b47c-65145f2e5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUL range (train): 0 361\n",
      "Nulls per column (train):\n",
      "sensor_21_lag_6    600\n",
      "sensor_20_lag_6    600\n",
      "sensor_19_lag_6    600\n",
      "sensor_18_lag_6    600\n",
      "sensor_17_lag_6    600\n",
      "sensor_16_lag_6    600\n",
      "sensor_15_lag_6    600\n",
      "sensor_14_lag_6    600\n",
      "sensor_13_lag_6    600\n",
      "sensor_12_lag_6    600\n",
      "dtype: int64\n",
      "Total columns: 428\n",
      "Sample columns: ['cycle', 'unit', 'op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15', 'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19', 'sensor_20', 'sensor_21', 'RUL', 'sensor_1_rm_5', 'sensor_1_rstd_5', 'sensor_1_slope_5']\n"
     ]
    }
   ],
   "source": [
    "# sanity\n",
    "print(\"RUL range (train):\", train_df[\"RUL\"].min(), train_df[\"RUL\"].max())\n",
    "print(\"Nulls per column (train):\")\n",
    "print(train_df.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# list of columns\n",
    "cols = train_df.columns.tolist()\n",
    "print(\"Total columns:\", len(cols))\n",
    "print(\"Sample columns:\", cols[:30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30c882-a0f5-44c3-8dbe-45ed6238ece7",
   "metadata": {},
   "source": [
    "### 3.4 Feature Selection\n",
    "We have too many features. We need feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fddf6210-5ef1-42d9-bdbc-d1196b70cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning feature space...\n",
      "Removing lag columns: 63 columns removed\n",
      "NaN fix complete:\n",
      "cycle           0\n",
      "unit            0\n",
      "op_setting_1    0\n",
      "op_setting_2    0\n",
      "op_setting_3    0\n",
      "dtype: int64\n",
      " Tabular features selected: 125\n",
      "Sequence features selected: 29\n",
      "Examples (tabular): ['anom_score', 'health_index', 'op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_10_slope_15', 'sensor_11_rm_15', 'sensor_11_rm_60', 'sensor_11_slope_15', 'sensor_11_slope_5']\n",
      "Examples (sequence): ['anom_score', 'health_index', 'sensor_11_rm_15', 'sensor_11_rm_60', 'sensor_13', 'sensor_13_rm_5', 'sensor_13_rstd_5', 'sensor_14_rm_15', 'sensor_14_rm_5', 'sensor_15_rm_5']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5) Feature Cleanup & Selection (Tabular + Sequence)\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Cleaning feature space...\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Drop all lag columns (lag features cause NaN at sequence start)\n",
    "# ------------------------------------------------------------\n",
    "lag_cols = [c for c in train_df.columns if \"_lag_\" in c]\n",
    "print(f\"Removing lag columns: {len(lag_cols)} columns removed\")\n",
    "train_df = train_df.drop(columns=lag_cols)\n",
    "test_df  = test_df.drop(columns=lag_cols)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Fix NaN values (per-unit backfill  forward fill)\n",
    "# ------------------------------------------------------------\n",
    "def fix_nans(df):\n",
    "    return (df.groupby(\"unit\")\n",
    "              .apply(lambda g: g.bfill().ffill())\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "train_df = fix_nans(train_df)\n",
    "test_df  = fix_nans(test_df)\n",
    "\n",
    "print(\"NaN fix complete:\")\n",
    "print(train_df.isna().sum().sort_values(ascending=False).head(5))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Construct tabular feature list\n",
    "# ------------------------------------------------------------\n",
    "META_EXCLUDE = {\"unit\", \"cycle\", \"RUL\", \"gap_flag\"}\n",
    "\n",
    "all_features = [c for c in train_df.columns if c not in META_EXCLUDE]\n",
    "\n",
    "# Variance filtering: keep top-k highest variance features\n",
    "k = 120\n",
    "variances = train_df[all_features].var().sort_values(ascending=False)\n",
    "topk = list(variances.index[:k])\n",
    "\n",
    "# Always keep key domain indicators\n",
    "domain_keep = [\n",
    "    \"health_index\",\n",
    "    \"anom_score\",\n",
    "    \"op_setting_1\",\n",
    "    \"op_setting_2\",\n",
    "    \"op_setting_3\"\n",
    "]\n",
    "domain_keep = [c for c in domain_keep if c in train_df.columns]\n",
    "\n",
    "tabular_features = sorted(set(topk + domain_keep))\n",
    "\n",
    "print(f\" Tabular features selected: {len(tabular_features)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Build sequence features (reduced set for LSTM/TCN efficiency)\n",
    "# ------------------------------------------------------------\n",
    "keep_patterns = [\n",
    "    r'^sensor_\\d+$',        # raw sensor values\n",
    "    r'^sensor_\\d+_rm_5$',   # short rolling means\n",
    "    r'^sensor_\\d+_rm_15$',\n",
    "    r'^sensor_\\d+_rm_60$',\n",
    "    r'^sensor_\\d+_rstd_5$', # short rolling std\n",
    "    r'^health_index$',      # degradation signal\n",
    "    r'^anom_score$'         # anomaly indicator\n",
    "]\n",
    "\n",
    "def match_any(col):\n",
    "    return any(re.match(p, col) for p in keep_patterns)\n",
    "\n",
    "sequence_features = [c for c in tabular_features if match_any(c)]\n",
    "\n",
    "# fallback if pattern too restrictive\n",
    "if len(sequence_features) < 12:\n",
    "    sequence_features = tabular_features[:40]\n",
    "\n",
    "print(f\"Sequence features selected: {len(sequence_features)}\")\n",
    "\n",
    "# Show samples\n",
    "print(\"Examples (tabular):\", tabular_features[:10])\n",
    "print(\"Examples (sequence):\", sequence_features[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91582f00-25ad-4ce3-8dd7-1a3a6e04bb27",
   "metadata": {},
   "source": [
    "### 3.5 Train/Validation Split (per-unit holdout)\n",
    "Use per-unit holdout (last portion of cycles per unit) to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3213aca3-57af-41a9-b62a-db7f4af78614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 14398 Val rows: 6233\n"
     ]
    }
   ],
   "source": [
    "# Get row indices for per-unit holdout\n",
    "train_idx, val_idx = ms.per_unit_holdout(train_df, holdout_frac=0.3)\n",
    "print(\"Train rows:\", len(train_idx), \"Val rows:\", len(val_idx))\n",
    "\n",
    "# Prepare arrays for tabular models\n",
    "X = train_df[tabular_features].values\n",
    "y = train_df[\"RUL\"].values\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_val   = X[val_idx]\n",
    "y_train = y[train_idx]\n",
    "y_val   = y[val_idx]\n",
    "\n",
    "# Standardize features for sklearn models (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25499f5-13bf-491e-ad61-c8678c7f305c",
   "metadata": {},
   "source": [
    "### 3.6 Baselines (Persistence & Moving-average linear map)\n",
    "Evaluate leakage-free baselines to anchor model expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d17d5b-de55-442f-ab7c-e4c298faa763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence baseline (shifted) metrics: {'MAE': 0.9839563613027434, 'RMSE': 0.9919457451407024, 'R2': 0.9977172069450396}\n",
      "Moving-average baseline metrics: {'MAE': 108.3474749721799, 'RMSE': 110.31866168564305, 'R2': -27.23505734065863}\n"
     ]
    }
   ],
   "source": [
    "# Baseline: persistence (shifted)\n",
    "y_val_persist = ms.baseline_persistence_shift(train_df.iloc[val_idx])  # make sure method accepts dataframe slice\n",
    "# The baseline impl may expect full df aligned; use ms.baseline_persistence_shift on the val slice\n",
    "# We need y_true for validation rows:\n",
    "y_true = y[val_idx]\n",
    "\n",
    "# For moving-average baseline: fit on train_df and predict on validation portion of train_df (or test later)\n",
    "# Here demonstrate using same split: compute on rows corresponding to val_idx (they are rows in train_df)\n",
    "ma_preds = ms.baseline_ma_linear_map(train_df.iloc[train_idx], train_df.iloc[val_idx], sensor_col=\"sensor_1\", window=10)\n",
    "\n",
    "# Evaluate\n",
    "try:\n",
    "    metrics_persist = ms.regression_metrics(y_true, y_val_persist)\n",
    "except Exception:\n",
    "    # fallback compute on simple approach (if shapes mismatch)\n",
    "    metrics_persist = {\"MAE\": float(\"nan\"), \"RMSE\": float(\"nan\"), \"R2\": float(\"nan\")}\n",
    "\n",
    "metrics_ma = ms.regression_metrics(y_true, ma_preds)\n",
    "\n",
    "print(\"Persistence baseline (shifted) metrics:\", metrics_persist)\n",
    "print(\"Moving-average baseline metrics:\", metrics_ma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7d964b-7d29-470e-a98d-adbec1b8b66f",
   "metadata": {},
   "source": [
    "### 3.7 Tabular Model\n",
    "#### 3.7.1 Random Forest\n",
    "Train a RandomForest on the standardized tabular features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6250ca-0efa-410e-b5d6-a1236c4e23d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF metrics: {'MAE': 27.662710956963686, 'RMSE': 31.64981748161584, 'R2': -1.323983950866963}\n",
      "Precision@100 (rf): 0.02\n",
      "Early-warning@7 (rf): 0.0\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\"n_estimators\":200, \"max_depth\":12, \"min_samples_leaf\":2}\n",
    "rf = ms.fit_random_forest(X_train_s, y_train, params=rf_params)\n",
    "y_val_pred_rf = rf.predict(X_val_s)\n",
    "metrics_rf = ms.regression_metrics(y_val, y_val_pred_rf)\n",
    "print(\"RF metrics:\", metrics_rf)\n",
    "print(\"Precision@100 (rf):\", ms.precision_at_k_rul(y_val, y_val_pred_rf, k=100))\n",
    "print(\"Early-warning@7 (rf):\", ms.early_warning_rate(train_df.iloc[val_idx], y_val, y_val_pred_rf, lead=7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca54c92-bc09-4452-842a-0d580f291ddb",
   "metadata": {},
   "source": [
    "#### 3.7.2 ElasticNet\n",
    "Train a regularized linear model (ElasticNet) for benchmarking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d80abf9-3e7f-4e02-ae2e-38607af6e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet metrics: {'MAE': 75.38697489734093, 'RMSE': 101.54092259576085, 'R2': -22.920646601780117}\n",
      "Precision@100 (en): 0.22\n"
     ]
    }
   ],
   "source": [
    "en_params = {\"alpha\": 0.01, \"l1_ratio\": 0.2}\n",
    "en = ms.fit_elasticnet(X_train_s, y_train, params=en_params)\n",
    "y_val_pred_en = en.predict(X_val_s)\n",
    "metrics_en = ms.regression_metrics(y_val, y_val_pred_en)\n",
    "print(\"ElasticNet metrics:\", metrics_en)\n",
    "print(\"Precision@100 (en):\", ms.precision_at_k_rul(y_val, y_val_pred_en, k=100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50518fe6-df5c-480e-8fdf-9e6829086f37",
   "metadata": {},
   "source": [
    "#### 3.7.3 LightGBM (version-safe)\n",
    "Train LightGBM using ms.fit_lightgbm. If LightGBM not installed, skip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ae24fe-8142-4a46-8b9a-b68142fcdf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's l1: 22.7097\n",
      "LightGBM metrics: {'MAE': 22.709666182561556, 'RMSE': 27.10636182058728, 'R2': -0.7046419305422893}\n",
      "Precision@100 (lgb): 0.0\n",
      "Early-warning@7 (lgb): 0.0\n"
     ]
    }
   ],
   "source": [
    "if lgb is None:\n",
    "    print(\"LightGBM not installed  skipping LGBM.\")\n",
    "else:\n",
    "    lgb_params = {\"objective\":\"regression\", \"metric\":\"mae\", \"learning_rate\":0.05, \"num_leaves\":48, \"verbosity\":-1}\n",
    "    try:\n",
    "        lgb_model, lgb_info = ms.fit_lightgbm(X_train_s, y_train, X_val_s, y_val, params=lgb_params, rounds=1000, early=50)\n",
    "        y_val_pred_lgb = lgb_model.predict(X_val_s)\n",
    "        metrics_lgb = ms.regression_metrics(y_val, y_val_pred_lgb)\n",
    "        print(\"LightGBM metrics:\", metrics_lgb)\n",
    "        print(\"Precision@100 (lgb):\", ms.precision_at_k_rul(y_val, y_val_pred_lgb, k=100))\n",
    "        print(\"Early-warning@7 (lgb):\", ms.early_warning_rate(train_df.iloc[val_idx], y_val, y_val_pred_lgb, lead=7))\n",
    "    except Exception as e:\n",
    "        print(\"LightGBM training error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354ecdf-92df-4332-a83b-28ca332c1817",
   "metadata": {},
   "source": [
    "### 3.8 Anomaly Model: IsolationForest\n",
    "Fit IsolationForest on training features, compute anomaly score for train/val and optionally add as a feature for model retraining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793b057a-0150-4201-ab7d-fb8ee87746a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly score (train) stats: 0.3509437643130367 0.6964313243918464 0.4067106093380277\n",
      "Anomaly score (val)   stats: 0.3635086542925437 0.6586642447075471 0.49786727881221426\n",
      "RF enriched (with anomaly) metrics: {'MAE': 27.67307100422802, 'RMSE': 31.669657734252304, 'R2': -1.326898525693852}\n"
     ]
    }
   ],
   "source": [
    "iso = IsolationForest(contamination=0.02, random_state=42)\n",
    "iso.fit(X_train_s)\n",
    "train_anom = iso.score_samples(X_train_s)   # higher = less anomalous; we can invert\n",
    "val_anom   = iso.score_samples(X_val_s)\n",
    "\n",
    "# Invert to get anomaly magnitude (higher means more anomalous)\n",
    "train_anom_score = -train_anom\n",
    "val_anom_score = -val_anom\n",
    "\n",
    "print(\"Anomaly score (train) stats:\", np.nanmin(train_anom_score), np.nanmax(train_anom_score), np.nanmean(train_anom_score))\n",
    "print(\"Anomaly score (val)   stats:\", np.nanmin(val_anom_score), np.nanmax(val_anom_score), np.nanmean(val_anom_score))\n",
    "\n",
    "# Optionally attach to features and retrain RF quickly to see impact\n",
    "X_train_enriched = np.hstack([X_train_s, train_anom_score.reshape(-1,1)])\n",
    "X_val_enriched   = np.hstack([X_val_s, val_anom_score.reshape(-1,1)])\n",
    "\n",
    "rf_enriched = ms.fit_random_forest(X_train_enriched, y_train, params=rf_params)\n",
    "y_val_pred_rf_enriched = rf_enriched.predict(X_val_enriched)\n",
    "metrics_rf_enriched = ms.regression_metrics(y_val, y_val_pred_rf_enriched)\n",
    "print(\"RF enriched (with anomaly) metrics:\", metrics_rf_enriched)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96237ab1-6a54-4f8e-bdf4-a4b4956ea1b8",
   "metadata": {},
   "source": [
    "### 3.9 Sequence pipeline (unit-level split  windowing  train LSTM/GRU/TCN)\n",
    "This section:\n",
    "- Creates a **unit-level train/val split** (no leakage).\n",
    "- Builds sliding windows for sequence models.\n",
    "- Trains LSTM / GRU / a small TCN with a generic training loop.\n",
    "- Optionally runs a short Optuna tuning loop for LSTM.\n",
    "- Evaluates and saves the best sequence model.\n",
    "Notes:\n",
    "- Use `seq_len` = 50120 depending on memory (we'll use 94 by default).\n",
    "- If you have GPU, set device = \"cuda\" for speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79e189ce-0e05-4fe6-ae62-640a3bb50c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files exist: True True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# B2: Imports and configuration\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# modeling utilities (make sure agentic_pm.modeling.model_selection is in your PYTHONPATH)\n",
    "from agentic_pm.modeling.model_selection import (\n",
    "    make_windows,\n",
    "    LSTMRegressor,\n",
    "    GRURegressor,\n",
    "    MiniTCN,\n",
    "    SequenceDataset,\n",
    "    train_sequence_model,\n",
    "    regression_metrics\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Paths & subset\n",
    "DATA_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SUBSET = \"FD001\"\n",
    "TRAIN_PATH = DATA_DIR / f\"train_{SUBSET}_final.csv\"\n",
    "TEST_PATH  = DATA_DIR / f\"test_{SUBSET}_final.csv\"\n",
    "\n",
    "print(\"files exist:\", TRAIN_PATH.exists(), TEST_PATH.exists())\n",
    "\n",
    "# hyperparams (tune these)\n",
    "SEQ_LEN = 94          # window length (as you used before)\n",
    "BATCH = 32\n",
    "EPOCHS = 40\n",
    "PATIENCE = 6\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "399b460b-1cf8-4d76-b833-f88fc1407579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation units: [np.int64(99), np.int64(100)]\n",
      "Train units: 98 Val units: 2\n"
     ]
    }
   ],
   "source": [
    "# B3: Load processed train and produce unit-level split (no leakage for sequence)\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# Choose validation units (hold out complete units). Pick last N units or specific ids.\n",
    "# Example: hold out 2 units for validation\n",
    "VAL_UNITS = sorted(train_df[\"unit\"].unique())[-2:]  # last 2 units\n",
    "print(\"Validation units:\", VAL_UNITS)\n",
    "\n",
    "train_units_df = train_df[~train_df[\"unit\"].isin(VAL_UNITS)].reset_index(drop=True)\n",
    "val_units_df   = train_df[ train_df[\"unit\"].isin(VAL_UNITS)].reset_index(drop=True)\n",
    "print(\"Train units:\", train_units_df[\"unit\"].nunique(), \"Val units:\", val_units_df[\"unit\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a86adb5f-02c0-4ee6-bcea-8e201d61d31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence features: 107\n",
      "['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15', 'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19', 'sensor_20']\n"
     ]
    }
   ],
   "source": [
    "# Select sequence features (from earlier created sequence_features or fallback)\n",
    "# Use precomputed list if available; else build heuristics:\n",
    "import re\n",
    "\n",
    "# Only features guaranteed to exist in final dataset\n",
    "PATTERNS = [\n",
    "    r'^sensor_\\d+$',\n",
    "    r'^sensor_\\d+_rm_5$',\n",
    "    r'^sensor_\\d+_rm_15$',\n",
    "    r'^sensor_\\d+_rm_60$',\n",
    "    r'^sensor_\\d+_rstd_5$',\n",
    "    r'^health_index$',\n",
    "    r'^anom_score$'\n",
    "]\n",
    "\n",
    "def matches_any(col):\n",
    "    return any(re.match(p, col) for p in PATTERNS)\n",
    "\n",
    "sequence_features = [c for c in train_df.columns if matches_any(c)]\n",
    "\n",
    "print(\"Sequence features:\", len(sequence_features))\n",
    "print(sequence_features[:20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a124511-bf05-4a64-9be3-49ea58b37a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: (11132, 94, 107) Val windows: (199, 94, 107)\n"
     ]
    }
   ],
   "source": [
    "# Build windows for train and val, create DataLoader\n",
    "SEQ_LEN = SEQ_LEN\n",
    "\n",
    "Xtr, ytr, _ = make_windows(train_units_df, sequence_features, seq_len=SEQ_LEN)\n",
    "Xva, yva, _ = make_windows(val_units_df, sequence_features, seq_len=SEQ_LEN)\n",
    "\n",
    "print(\"Train windows:\", Xtr.shape, \"Val windows:\", Xva.shape)\n",
    "\n",
    "train_loader = DataLoader(SequenceDataset(Xtr, ytr), batch_size=BATCH, shuffle=True)\n",
    "val_loader   = DataLoader(SequenceDataset(Xva, yva), batch_size=BATCH, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d6797-d148-48d8-b0f3-c787b3147605",
   "metadata": {},
   "source": [
    "### Train sequence models\n",
    "We will train three lightweight sequence models:\n",
    "- LSTM (default best performing)\n",
    "- GRU (for comparison)\n",
    "- MiniTCN (light conv-based)\n",
    "We use the same `train_sequence_model` which performs MAE training + early stopping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aaf4763d-9e40-4662-baee-222ee4a4803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 00:57:59,343 INFO [SEQ] Epoch 00  val_MAE=32.1221\n",
      "2025-11-23 00:58:00,653 INFO [SEQ] Epoch 01  val_MAE=25.4475\n",
      "2025-11-23 00:58:01,778 INFO [SEQ] Epoch 02  val_MAE=19.6314\n",
      "2025-11-23 00:58:02,966 INFO [SEQ] Epoch 03  val_MAE=14.8161\n",
      "2025-11-23 00:58:04,062 INFO [SEQ] Epoch 04  val_MAE=11.6083\n",
      "2025-11-23 00:58:05,174 INFO [SEQ] Epoch 05  val_MAE=9.5802\n",
      "2025-11-23 00:58:06,327 INFO [SEQ] Epoch 06  val_MAE=8.4468\n",
      "2025-11-23 00:58:07,516 INFO [SEQ] Epoch 07  val_MAE=6.6694\n",
      "2025-11-23 00:58:08,819 INFO [SEQ] Epoch 08  val_MAE=6.5589\n",
      "2025-11-23 00:58:10,396 INFO [SEQ] Epoch 09  val_MAE=6.7190\n",
      "2025-11-23 00:58:11,601 INFO [SEQ] Epoch 10  val_MAE=5.7965\n",
      "2025-11-23 00:58:12,736 INFO [SEQ] Epoch 11  val_MAE=8.2981\n",
      "2025-11-23 00:58:13,649 INFO [SEQ] Epoch 12  val_MAE=8.6287\n",
      "2025-11-23 00:58:14,885 INFO [SEQ] Epoch 13  val_MAE=9.9373\n",
      "2025-11-23 00:58:15,953 INFO [SEQ] Epoch 14  val_MAE=8.0671\n",
      "2025-11-23 00:58:17,118 INFO [SEQ] Epoch 15  val_MAE=10.1581\n",
      "2025-11-23 00:58:18,260 INFO [SEQ] Epoch 16  val_MAE=10.6014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM val MAE: 5.796503441674369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 00:58:19,604 INFO [SEQ] Epoch 00  val_MAE=24.4022\n",
      "2025-11-23 00:58:20,999 INFO [SEQ] Epoch 01  val_MAE=13.1605\n",
      "2025-11-23 00:58:22,215 INFO [SEQ] Epoch 02  val_MAE=7.5025\n",
      "2025-11-23 00:58:23,399 INFO [SEQ] Epoch 03  val_MAE=5.3549\n",
      "2025-11-23 00:58:24,683 INFO [SEQ] Epoch 04  val_MAE=5.9137\n",
      "2025-11-23 00:58:25,869 INFO [SEQ] Epoch 05  val_MAE=6.9665\n",
      "2025-11-23 00:58:26,918 INFO [SEQ] Epoch 06  val_MAE=8.3546\n",
      "2025-11-23 00:58:28,086 INFO [SEQ] Epoch 07  val_MAE=11.4060\n",
      "2025-11-23 00:58:29,556 INFO [SEQ] Epoch 08  val_MAE=11.3086\n",
      "2025-11-23 00:58:30,634 INFO [SEQ] Epoch 09  val_MAE=11.0859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU val MAE: 5.354915107999529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 00:58:31,975 INFO [SEQ] Epoch 00  val_MAE=10.8489\n",
      "2025-11-23 00:58:33,114 INFO [SEQ] Epoch 01  val_MAE=15.7114\n",
      "2025-11-23 00:58:34,274 INFO [SEQ] Epoch 02  val_MAE=14.1200\n",
      "2025-11-23 00:58:35,489 INFO [SEQ] Epoch 03  val_MAE=16.5177\n",
      "2025-11-23 00:58:36,878 INFO [SEQ] Epoch 04  val_MAE=16.4467\n",
      "2025-11-23 00:58:38,178 INFO [SEQ] Epoch 05  val_MAE=12.8580\n",
      "2025-11-23 00:58:39,254 INFO [SEQ] Epoch 06  val_MAE=16.7822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCN val MAE: 10.848923410688128\n",
      "LSTM metrics: {'MAE': 5.9034528732299805, 'RMSE': 7.427989360516169, 'R2': 0.9353151917457581}\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM, GRU, TCN (quick, reproducible)\n",
    "n_features = Xtr.shape[-1]\n",
    "print(\"n_features:\", n_features)\n",
    "\n",
    "# LSTM\n",
    "lstm = LSTMRegressor(n_features=n_features, hidden_size=64, num_layers=1, dropout=0.12).to(DEVICE)\n",
    "lstm, lstm_val_mae = train_sequence_model(lstm, train_loader, val_loader, lr=4.4e-4, epochs=EPOCHS, patience=PATIENCE, device=DEVICE)\n",
    "print(\"LSTM val MAE:\", lstm_val_mae)\n",
    "\n",
    "# GRU (if implemented in your model_selection)\n",
    "try:\n",
    "    from agentic_pm.modeling.model_selection import GRURegressor\n",
    "    gru = GRURegressor(n_features=n_features, hidden_size=64, num_layers=1).to(DEVICE)\n",
    "    gru, gru_val_mae = train_sequence_model(gru, train_loader, val_loader, lr=1e-3, epochs=EPOCHS, patience=PATIENCE, device=DEVICE)\n",
    "    print(\"GRU val MAE:\", gru_val_mae)\n",
    "except Exception:\n",
    "    print(\"GRU unavailable or not implemented  skipping GRU.\")\n",
    "\n",
    "# TCN\n",
    "tcn = MiniTCN(n_features=n_features, hidden=48).to(DEVICE)\n",
    "tcn, tcn_val_mae = train_sequence_model(tcn, train_loader, val_loader, lr=1e-3, epochs=EPOCHS, patience=PATIENCE, device=DEVICE)\n",
    "print(\"TCN val MAE:\", tcn_val_mae)\n",
    "\n",
    "# Predictions & metrics (window-level)\n",
    "def predict_seq_model(model, X):\n",
    "    model.eval()\n",
    "    out = []\n",
    "    dl = DataLoader(SequenceDataset(X, np.zeros(len(X))), batch_size=64, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in dl:\n",
    "            xb = xb.to(DEVICE)\n",
    "            pred = model(xb).cpu().numpy()\n",
    "            out.extend(pred)\n",
    "    return np.array(out)\n",
    "\n",
    "y_pred_lstm = predict_seq_model(lstm, Xva)\n",
    "print(\"LSTM metrics:\", regression_metrics(yva, y_pred_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "deb35d93-3233-47f5-8fd5-d670771f28d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LSTM to artifacts\\models\\lstm_seq_FD001.pth\n"
     ]
    }
   ],
   "source": [
    "# Save best sequence model (pick LSTM if best)\n",
    "ART_DIR = Path(\"artifacts/models\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(lstm.state_dict(), ART_DIR / f\"lstm_seq_{SUBSET}.pth\")\n",
    "print(\"Saved LSTM to\", ART_DIR / f\"lstm_seq_{SUBSET}.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e20d4-2c83-4260-ba5a-74f3dd024f65",
   "metadata": {},
   "source": [
    "### 3.10 Sequence Nested CV (LSTM + GRU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4c02bbf-3364-4412-b0dd-4efa5f8c1b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:04:26,612] A new study created in memory with name: no-name-0ff585e8-186e-4800-9fb7-e1135e7ffe2a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "==============================\n",
      " OUTER FOLD 1/3\n",
      "==============================\n",
      "Train units: 25  Val units: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c77c1ac9894c168ff66a04eee0967f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:04:27,521 INFO [SEQ] Epoch 00  val_MAE=55.7043\n",
      "2025-11-23 11:04:27,973 INFO [SEQ] Epoch 01  val_MAE=53.4988\n",
      "2025-11-23 11:04:28,484 INFO [SEQ] Epoch 02  val_MAE=52.2037\n",
      "2025-11-23 11:04:28,948 INFO [SEQ] Epoch 03  val_MAE=51.1280\n",
      "2025-11-23 11:04:29,397 INFO [SEQ] Epoch 04  val_MAE=50.1670\n",
      "2025-11-23 11:04:29,840 INFO [SEQ] Epoch 05  val_MAE=49.2678\n",
      "2025-11-23 11:04:30,438 INFO [SEQ] Epoch 06  val_MAE=48.4201\n",
      "2025-11-23 11:04:31,032 INFO [SEQ] Epoch 07  val_MAE=47.3804\n",
      "2025-11-23 11:04:31,526 INFO [SEQ] Epoch 08  val_MAE=46.3819\n",
      "2025-11-23 11:04:32,020 INFO [SEQ] Epoch 09  val_MAE=45.4433\n",
      "2025-11-23 11:04:32,458 INFO [SEQ] Epoch 10  val_MAE=44.4808\n",
      "2025-11-23 11:04:32,958 INFO [SEQ] Epoch 11  val_MAE=43.5660\n",
      "2025-11-23 11:04:33,521 INFO [SEQ] Epoch 12  val_MAE=42.7226\n",
      "2025-11-23 11:04:34,064 INFO [SEQ] Epoch 13  val_MAE=41.8595\n",
      "2025-11-23 11:04:34,578 INFO [SEQ] Epoch 14  val_MAE=41.0704\n",
      "2025-11-23 11:04:35,121 INFO [SEQ] Epoch 15  val_MAE=40.2651\n",
      "2025-11-23 11:04:35,672 INFO [SEQ] Epoch 16  val_MAE=39.4906\n",
      "2025-11-23 11:04:36,279 INFO [SEQ] Epoch 17  val_MAE=38.7594\n",
      "2025-11-23 11:04:36,802 INFO [SEQ] Epoch 18  val_MAE=38.0058\n",
      "2025-11-23 11:04:37,409 INFO [SEQ] Epoch 19  val_MAE=37.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:04:37,428] Trial 0 finished with value: 37.296317267691954 and parameters: {'seq_len': 82, 'hidden': 43, 'layers': 2, 'lr': 0.00024316933120840736, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 0 with value: 37.296317267691954.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:04:38,050 INFO [SEQ] Epoch 00  val_MAE=37.2842\n",
      "2025-11-23 11:04:38,487 INFO [SEQ] Epoch 01  val_MAE=31.8332\n",
      "2025-11-23 11:04:38,935 INFO [SEQ] Epoch 02  val_MAE=24.4852\n",
      "2025-11-23 11:04:39,407 INFO [SEQ] Epoch 03  val_MAE=17.9152\n",
      "2025-11-23 11:04:39,877 INFO [SEQ] Epoch 04  val_MAE=13.6410\n",
      "2025-11-23 11:04:40,360 INFO [SEQ] Epoch 05  val_MAE=11.5972\n",
      "2025-11-23 11:04:40,799 INFO [SEQ] Epoch 06  val_MAE=9.6439\n",
      "2025-11-23 11:04:41,205 INFO [SEQ] Epoch 07  val_MAE=8.5370\n",
      "2025-11-23 11:04:41,625 INFO [SEQ] Epoch 08  val_MAE=8.1803\n",
      "2025-11-23 11:04:42,057 INFO [SEQ] Epoch 09  val_MAE=7.7214\n",
      "2025-11-23 11:04:42,462 INFO [SEQ] Epoch 10  val_MAE=8.4779\n",
      "2025-11-23 11:04:42,899 INFO [SEQ] Epoch 11  val_MAE=7.7227\n",
      "2025-11-23 11:04:43,294 INFO [SEQ] Epoch 12  val_MAE=7.5971\n",
      "2025-11-23 11:04:43,682 INFO [SEQ] Epoch 13  val_MAE=8.1107\n",
      "2025-11-23 11:04:44,105 INFO [SEQ] Epoch 14  val_MAE=7.6483\n",
      "2025-11-23 11:04:44,511 INFO [SEQ] Epoch 15  val_MAE=7.9770\n",
      "2025-11-23 11:04:44,962 INFO [SEQ] Epoch 16  val_MAE=8.3353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:04:44,983] Trial 1 finished with value: 7.5971457942536 and parameters: {'seq_len': 96, 'hidden': 110, 'layers': 2, 'lr': 0.0013631998017238842, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:04:45,990 INFO [SEQ] Epoch 00  val_MAE=60.0575\n",
      "2025-11-23 11:04:46,816 INFO [SEQ] Epoch 01  val_MAE=56.7627\n",
      "2025-11-23 11:04:47,688 INFO [SEQ] Epoch 02  val_MAE=53.3691\n",
      "2025-11-23 11:04:48,530 INFO [SEQ] Epoch 03  val_MAE=50.1890\n",
      "2025-11-23 11:04:49,475 INFO [SEQ] Epoch 04  val_MAE=47.1978\n",
      "2025-11-23 11:04:50,427 INFO [SEQ] Epoch 05  val_MAE=44.5761\n",
      "2025-11-23 11:04:51,367 INFO [SEQ] Epoch 06  val_MAE=42.0296\n",
      "2025-11-23 11:04:52,399 INFO [SEQ] Epoch 07  val_MAE=39.6269\n",
      "2025-11-23 11:04:53,384 INFO [SEQ] Epoch 08  val_MAE=37.3172\n",
      "2025-11-23 11:04:54,293 INFO [SEQ] Epoch 09  val_MAE=35.2076\n",
      "2025-11-23 11:04:55,176 INFO [SEQ] Epoch 10  val_MAE=33.3369\n",
      "2025-11-23 11:04:56,120 INFO [SEQ] Epoch 11  val_MAE=31.3693\n",
      "2025-11-23 11:04:57,134 INFO [SEQ] Epoch 12  val_MAE=29.7379\n",
      "2025-11-23 11:04:58,031 INFO [SEQ] Epoch 13  val_MAE=27.8843\n",
      "2025-11-23 11:04:58,854 INFO [SEQ] Epoch 14  val_MAE=26.3270\n",
      "2025-11-23 11:04:59,774 INFO [SEQ] Epoch 15  val_MAE=24.9912\n",
      "2025-11-23 11:05:00,676 INFO [SEQ] Epoch 16  val_MAE=23.6394\n",
      "2025-11-23 11:05:01,590 INFO [SEQ] Epoch 17  val_MAE=22.1918\n",
      "2025-11-23 11:05:02,579 INFO [SEQ] Epoch 18  val_MAE=20.9348\n",
      "2025-11-23 11:05:03,481 INFO [SEQ] Epoch 19  val_MAE=19.7373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:03,504] Trial 2 finished with value: 19.737259775544135 and parameters: {'seq_len': 61, 'hidden': 88, 'layers': 2, 'lr': 0.000179465755030272, 'batch_size': 16, 'model_type': 'gru'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:04,137 INFO [SEQ] Epoch 00  val_MAE=56.5319\n",
      "2025-11-23 11:05:04,622 INFO [SEQ] Epoch 01  val_MAE=53.7431\n",
      "2025-11-23 11:05:05,091 INFO [SEQ] Epoch 02  val_MAE=52.0541\n",
      "2025-11-23 11:05:05,546 INFO [SEQ] Epoch 03  val_MAE=50.5949\n",
      "2025-11-23 11:05:06,006 INFO [SEQ] Epoch 04  val_MAE=49.2774\n",
      "2025-11-23 11:05:06,496 INFO [SEQ] Epoch 05  val_MAE=48.0147\n",
      "2025-11-23 11:05:06,975 INFO [SEQ] Epoch 06  val_MAE=46.2303\n",
      "2025-11-23 11:05:07,428 INFO [SEQ] Epoch 07  val_MAE=44.5904\n",
      "2025-11-23 11:05:07,905 INFO [SEQ] Epoch 08  val_MAE=43.1807\n",
      "2025-11-23 11:05:08,433 INFO [SEQ] Epoch 09  val_MAE=41.8509\n",
      "2025-11-23 11:05:09,045 INFO [SEQ] Epoch 10  val_MAE=40.3130\n",
      "2025-11-23 11:05:09,599 INFO [SEQ] Epoch 11  val_MAE=39.0686\n",
      "2025-11-23 11:05:10,201 INFO [SEQ] Epoch 12  val_MAE=37.9324\n",
      "2025-11-23 11:05:10,650 INFO [SEQ] Epoch 13  val_MAE=36.7078\n",
      "2025-11-23 11:05:11,110 INFO [SEQ] Epoch 14  val_MAE=35.5641\n",
      "2025-11-23 11:05:11,579 INFO [SEQ] Epoch 15  val_MAE=34.4804\n",
      "2025-11-23 11:05:12,010 INFO [SEQ] Epoch 16  val_MAE=33.4564\n",
      "2025-11-23 11:05:12,468 INFO [SEQ] Epoch 17  val_MAE=32.4582\n",
      "2025-11-23 11:05:12,917 INFO [SEQ] Epoch 18  val_MAE=31.5116\n",
      "2025-11-23 11:05:13,388 INFO [SEQ] Epoch 19  val_MAE=30.6168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:13,415] Trial 3 finished with value: 30.61679364660735 and parameters: {'seq_len': 74, 'hidden': 95, 'layers': 2, 'lr': 0.00017378225688787337, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:14,401 INFO [SEQ] Epoch 00  val_MAE=30.5473\n",
      "2025-11-23 11:05:15,343 INFO [SEQ] Epoch 01  val_MAE=17.0984\n",
      "2025-11-23 11:05:16,185 INFO [SEQ] Epoch 02  val_MAE=12.9399\n",
      "2025-11-23 11:05:17,062 INFO [SEQ] Epoch 03  val_MAE=11.1968\n",
      "2025-11-23 11:05:17,995 INFO [SEQ] Epoch 04  val_MAE=11.4297\n",
      "2025-11-23 11:05:18,906 INFO [SEQ] Epoch 05  val_MAE=11.2675\n",
      "2025-11-23 11:05:19,798 INFO [SEQ] Epoch 06  val_MAE=11.2193\n",
      "2025-11-23 11:05:20,724 INFO [SEQ] Epoch 07  val_MAE=11.3356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:20,747] Trial 4 finished with value: 11.19675463438034 and parameters: {'seq_len': 53, 'hidden': 99, 'layers': 1, 'lr': 0.0022224253183996965, 'batch_size': 16, 'model_type': 'lstm'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:21,367 INFO [SEQ] Epoch 00  val_MAE=64.7426\n",
      "2025-11-23 11:05:21,757 INFO [SEQ] Epoch 01  val_MAE=61.6684\n",
      "2025-11-23 11:05:22,138 INFO [SEQ] Epoch 02  val_MAE=59.6965\n",
      "2025-11-23 11:05:22,560 INFO [SEQ] Epoch 03  val_MAE=58.0074\n",
      "2025-11-23 11:05:23,020 INFO [SEQ] Epoch 04  val_MAE=56.4692\n",
      "2025-11-23 11:05:23,362 INFO [SEQ] Epoch 05  val_MAE=55.0240\n",
      "2025-11-23 11:05:23,700 INFO [SEQ] Epoch 06  val_MAE=53.2739\n",
      "2025-11-23 11:05:24,061 INFO [SEQ] Epoch 07  val_MAE=51.1110\n",
      "2025-11-23 11:05:24,364 INFO [SEQ] Epoch 08  val_MAE=49.4289\n",
      "2025-11-23 11:05:24,726 INFO [SEQ] Epoch 09  val_MAE=47.8511\n",
      "2025-11-23 11:05:25,046 INFO [SEQ] Epoch 10  val_MAE=46.1836\n",
      "2025-11-23 11:05:25,384 INFO [SEQ] Epoch 11  val_MAE=44.7554\n",
      "2025-11-23 11:05:25,685 INFO [SEQ] Epoch 12  val_MAE=43.3660\n",
      "2025-11-23 11:05:26,056 INFO [SEQ] Epoch 13  val_MAE=41.9412\n",
      "2025-11-23 11:05:26,404 INFO [SEQ] Epoch 14  val_MAE=40.7881\n",
      "2025-11-23 11:05:26,789 INFO [SEQ] Epoch 15  val_MAE=39.3394\n",
      "2025-11-23 11:05:27,089 INFO [SEQ] Epoch 16  val_MAE=38.2245\n",
      "2025-11-23 11:05:27,402 INFO [SEQ] Epoch 17  val_MAE=37.2281\n",
      "2025-11-23 11:05:27,750 INFO [SEQ] Epoch 18  val_MAE=35.9041\n",
      "2025-11-23 11:05:28,095 INFO [SEQ] Epoch 19  val_MAE=34.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:28,206] Trial 5 finished with value: 34.95002735311335 and parameters: {'seq_len': 54, 'hidden': 106, 'layers': 2, 'lr': 0.0003083671503294388, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:28,633 INFO [SEQ] Epoch 00  val_MAE=45.3336\n",
      "2025-11-23 11:05:28,886 INFO [SEQ] Epoch 01  val_MAE=43.9647\n",
      "2025-11-23 11:05:29,171 INFO [SEQ] Epoch 02  val_MAE=41.7201\n",
      "2025-11-23 11:05:29,423 INFO [SEQ] Epoch 03  val_MAE=40.5814\n",
      "2025-11-23 11:05:29,699 INFO [SEQ] Epoch 04  val_MAE=39.8887\n",
      "2025-11-23 11:05:29,953 INFO [SEQ] Epoch 05  val_MAE=39.3561\n",
      "2025-11-23 11:05:30,188 INFO [SEQ] Epoch 06  val_MAE=38.9150\n",
      "2025-11-23 11:05:30,466 INFO [SEQ] Epoch 07  val_MAE=38.4990\n",
      "2025-11-23 11:05:30,713 INFO [SEQ] Epoch 08  val_MAE=38.1218\n",
      "2025-11-23 11:05:30,986 INFO [SEQ] Epoch 09  val_MAE=37.7618\n",
      "2025-11-23 11:05:31,280 INFO [SEQ] Epoch 10  val_MAE=37.4268\n",
      "2025-11-23 11:05:31,544 INFO [SEQ] Epoch 11  val_MAE=37.0985\n",
      "2025-11-23 11:05:31,831 INFO [SEQ] Epoch 12  val_MAE=36.7843\n",
      "2025-11-23 11:05:32,114 INFO [SEQ] Epoch 13  val_MAE=36.4910\n",
      "2025-11-23 11:05:32,395 INFO [SEQ] Epoch 14  val_MAE=36.2002\n",
      "2025-11-23 11:05:32,670 INFO [SEQ] Epoch 15  val_MAE=35.9151\n",
      "2025-11-23 11:05:32,907 INFO [SEQ] Epoch 16  val_MAE=35.6307\n",
      "2025-11-23 11:05:33,141 INFO [SEQ] Epoch 17  val_MAE=35.3668\n",
      "2025-11-23 11:05:33,400 INFO [SEQ] Epoch 18  val_MAE=35.1000\n",
      "2025-11-23 11:05:33,658 INFO [SEQ] Epoch 19  val_MAE=34.8383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:33,679] Trial 6 finished with value: 34.83828367906458 and parameters: {'seq_len': 108, 'hidden': 63, 'layers': 2, 'lr': 0.00016802404983284108, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:34,916 INFO [SEQ] Epoch 00  val_MAE=43.7404\n",
      "2025-11-23 11:05:35,936 INFO [SEQ] Epoch 01  val_MAE=29.3728\n",
      "2025-11-23 11:05:36,902 INFO [SEQ] Epoch 02  val_MAE=19.0260\n",
      "2025-11-23 11:05:38,089 INFO [SEQ] Epoch 03  val_MAE=13.7973\n",
      "2025-11-23 11:05:39,021 INFO [SEQ] Epoch 04  val_MAE=11.5340\n",
      "2025-11-23 11:05:39,971 INFO [SEQ] Epoch 05  val_MAE=11.1479\n",
      "2025-11-23 11:05:40,910 INFO [SEQ] Epoch 06  val_MAE=10.8651\n",
      "2025-11-23 11:05:41,656 INFO [SEQ] Epoch 07  val_MAE=11.1396\n",
      "2025-11-23 11:05:42,367 INFO [SEQ] Epoch 08  val_MAE=11.0339\n",
      "2025-11-23 11:05:43,111 INFO [SEQ] Epoch 09  val_MAE=10.8853\n",
      "2025-11-23 11:05:43,827 INFO [SEQ] Epoch 10  val_MAE=11.4166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:43,843] Trial 7 finished with value: 10.865086804847328 and parameters: {'seq_len': 68, 'hidden': 39, 'layers': 2, 'lr': 0.00298711916695537, 'batch_size': 16, 'model_type': 'gru'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:44,528 INFO [SEQ] Epoch 00  val_MAE=52.6991\n",
      "2025-11-23 11:05:44,931 INFO [SEQ] Epoch 01  val_MAE=49.9557\n",
      "2025-11-23 11:05:45,300 INFO [SEQ] Epoch 02  val_MAE=48.5856\n",
      "2025-11-23 11:05:45,718 INFO [SEQ] Epoch 03  val_MAE=47.4246\n",
      "2025-11-23 11:05:46,141 INFO [SEQ] Epoch 04  val_MAE=46.3722\n",
      "2025-11-23 11:05:46,549 INFO [SEQ] Epoch 05  val_MAE=45.3949\n",
      "2025-11-23 11:05:46,973 INFO [SEQ] Epoch 06  val_MAE=43.9540\n",
      "2025-11-23 11:05:47,372 INFO [SEQ] Epoch 07  val_MAE=42.6720\n",
      "2025-11-23 11:05:47,762 INFO [SEQ] Epoch 08  val_MAE=41.4727\n",
      "2025-11-23 11:05:48,393 INFO [SEQ] Epoch 09  val_MAE=40.3647\n",
      "2025-11-23 11:05:48,812 INFO [SEQ] Epoch 10  val_MAE=39.3279\n",
      "2025-11-23 11:05:49,246 INFO [SEQ] Epoch 11  val_MAE=38.3677\n",
      "2025-11-23 11:05:49,743 INFO [SEQ] Epoch 12  val_MAE=37.3812\n",
      "2025-11-23 11:05:50,197 INFO [SEQ] Epoch 13  val_MAE=36.3850\n",
      "2025-11-23 11:05:50,638 INFO [SEQ] Epoch 14  val_MAE=35.4736\n",
      "2025-11-23 11:05:51,114 INFO [SEQ] Epoch 15  val_MAE=34.5403\n",
      "2025-11-23 11:05:51,625 INFO [SEQ] Epoch 16  val_MAE=33.6337\n",
      "2025-11-23 11:05:52,122 INFO [SEQ] Epoch 17  val_MAE=32.8047\n",
      "2025-11-23 11:05:52,557 INFO [SEQ] Epoch 18  val_MAE=31.9802\n",
      "2025-11-23 11:05:53,043 INFO [SEQ] Epoch 19  val_MAE=31.2241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:05:53,059] Trial 8 finished with value: 31.224138616822486 and parameters: {'seq_len': 84, 'hidden': 72, 'layers': 2, 'lr': 0.00018885773728118078, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 1 with value: 7.5971457942536.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:05:54,084 INFO [SEQ] Epoch 00  val_MAE=42.8347\n",
      "2025-11-23 11:05:54,952 INFO [SEQ] Epoch 01  val_MAE=35.4149\n",
      "2025-11-23 11:05:55,831 INFO [SEQ] Epoch 02  val_MAE=24.8006\n",
      "2025-11-23 11:05:56,808 INFO [SEQ] Epoch 03  val_MAE=18.8937\n",
      "2025-11-23 11:05:57,724 INFO [SEQ] Epoch 04  val_MAE=15.6176\n",
      "2025-11-23 11:05:58,581 INFO [SEQ] Epoch 05  val_MAE=12.7205\n",
      "2025-11-23 11:05:59,393 INFO [SEQ] Epoch 06  val_MAE=10.8062\n",
      "2025-11-23 11:06:00,203 INFO [SEQ] Epoch 07  val_MAE=9.7485\n",
      "2025-11-23 11:06:01,147 INFO [SEQ] Epoch 08  val_MAE=9.3422\n",
      "2025-11-23 11:06:01,991 INFO [SEQ] Epoch 09  val_MAE=8.9410\n",
      "2025-11-23 11:06:02,902 INFO [SEQ] Epoch 10  val_MAE=9.0126\n",
      "2025-11-23 11:06:03,714 INFO [SEQ] Epoch 11  val_MAE=8.9639\n",
      "2025-11-23 11:06:04,788 INFO [SEQ] Epoch 12  val_MAE=9.2733\n",
      "2025-11-23 11:06:05,636 INFO [SEQ] Epoch 13  val_MAE=8.7052\n",
      "2025-11-23 11:06:06,470 INFO [SEQ] Epoch 14  val_MAE=8.9027\n",
      "2025-11-23 11:06:07,227 INFO [SEQ] Epoch 15  val_MAE=9.3366\n",
      "2025-11-23 11:06:07,916 INFO [SEQ] Epoch 16  val_MAE=9.1309\n",
      "2025-11-23 11:06:08,653 INFO [SEQ] Epoch 17  val_MAE=9.8103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:06:08,671] Trial 9 finished with value: 8.705241174684407 and parameters: {'seq_len': 80, 'hidden': 96, 'layers': 2, 'lr': 0.000799369631687782, 'batch_size': 16, 'model_type': 'gru'}. Best is trial 1 with value: 7.5971457942536.\n",
      "Best inner params: {'seq_len': 96, 'hidden': 110, 'layers': 2, 'lr': 0.0013631998017238842, 'batch_size': 32, 'model_type': 'gru'}\n",
      "Train windows: (2735, 96, 107)  Val windows: (2424, 96, 107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:06:09,456 INFO [SEQ] Epoch 00  val_MAE=37.1244\n",
      "2025-11-23 11:06:09,880 INFO [SEQ] Epoch 01  val_MAE=30.5213\n",
      "2025-11-23 11:06:10,323 INFO [SEQ] Epoch 02  val_MAE=22.7786\n",
      "2025-11-23 11:06:10,882 INFO [SEQ] Epoch 03  val_MAE=16.8419\n",
      "2025-11-23 11:06:11,402 INFO [SEQ] Epoch 04  val_MAE=13.5719\n",
      "2025-11-23 11:06:11,860 INFO [SEQ] Epoch 05  val_MAE=11.3550\n",
      "2025-11-23 11:06:12,336 INFO [SEQ] Epoch 06  val_MAE=9.6908\n",
      "2025-11-23 11:06:12,814 INFO [SEQ] Epoch 07  val_MAE=8.9137\n",
      "2025-11-23 11:06:13,336 INFO [SEQ] Epoch 08  val_MAE=7.9031\n",
      "2025-11-23 11:06:13,738 INFO [SEQ] Epoch 09  val_MAE=7.4179\n",
      "2025-11-23 11:06:14,134 INFO [SEQ] Epoch 10  val_MAE=7.4920\n",
      "2025-11-23 11:06:14,657 INFO [SEQ] Epoch 11  val_MAE=7.5717\n",
      "2025-11-23 11:06:15,161 INFO [SEQ] Epoch 12  val_MAE=7.4176\n",
      "2025-11-23 11:06:15,622 INFO [SEQ] Epoch 13  val_MAE=7.9952\n",
      "2025-11-23 11:06:16,082 INFO [SEQ] Epoch 14  val_MAE=7.5790\n",
      "2025-11-23 11:06:16,466 INFO [SEQ] Epoch 15  val_MAE=7.8636\n",
      "2025-11-23 11:06:17,080 INFO [SEQ] Epoch 16  val_MAE=7.7411\n",
      "2025-11-23 11:06:17,493 INFO [SEQ] Epoch 17  val_MAE=7.9024\n",
      "[I 2025-11-23 11:06:17,639] A new study created in memory with name: no-name-425e4f02-51f7-4db0-af74-41e28b927006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 METRICS: {'MAE': 7.437922954559326, 'RMSE': 11.00126259233404, 'R2': 0.8949770927429199}\n",
      "\n",
      "==============================\n",
      " OUTER FOLD 2/3\n",
      "==============================\n",
      "Train units: 50  Val units: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5692ba0328194fa1928368efadaa795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:06:18,347 INFO [SEQ] Epoch 00  val_MAE=72.0096\n",
      "2025-11-23 11:06:18,852 INFO [SEQ] Epoch 01  val_MAE=66.4233\n",
      "2025-11-23 11:06:19,318 INFO [SEQ] Epoch 02  val_MAE=63.3775\n",
      "2025-11-23 11:06:19,742 INFO [SEQ] Epoch 03  val_MAE=60.5985\n",
      "2025-11-23 11:06:20,141 INFO [SEQ] Epoch 04  val_MAE=58.0456\n",
      "2025-11-23 11:06:20,602 INFO [SEQ] Epoch 05  val_MAE=55.7764\n",
      "2025-11-23 11:06:21,045 INFO [SEQ] Epoch 06  val_MAE=53.5750\n",
      "2025-11-23 11:06:21,476 INFO [SEQ] Epoch 07  val_MAE=51.5616\n",
      "2025-11-23 11:06:21,912 INFO [SEQ] Epoch 08  val_MAE=49.5394\n",
      "2025-11-23 11:06:22,359 INFO [SEQ] Epoch 09  val_MAE=47.8245\n",
      "2025-11-23 11:06:22,812 INFO [SEQ] Epoch 10  val_MAE=45.6783\n",
      "2025-11-23 11:06:23,308 INFO [SEQ] Epoch 11  val_MAE=44.2382\n",
      "2025-11-23 11:06:23,748 INFO [SEQ] Epoch 12  val_MAE=42.5816\n",
      "2025-11-23 11:06:24,254 INFO [SEQ] Epoch 13  val_MAE=41.2038\n",
      "2025-11-23 11:06:24,674 INFO [SEQ] Epoch 14  val_MAE=39.8025\n",
      "2025-11-23 11:06:25,252 INFO [SEQ] Epoch 15  val_MAE=38.3963\n",
      "2025-11-23 11:06:25,823 INFO [SEQ] Epoch 16  val_MAE=37.1295\n",
      "2025-11-23 11:06:26,337 INFO [SEQ] Epoch 17  val_MAE=35.9848\n",
      "2025-11-23 11:06:26,881 INFO [SEQ] Epoch 18  val_MAE=34.8000\n",
      "2025-11-23 11:06:27,493 INFO [SEQ] Epoch 19  val_MAE=33.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:06:27,517] Trial 0 finished with value: 33.714992626658024 and parameters: {'seq_len': 77, 'hidden': 54, 'layers': 1, 'lr': 0.0005579477056594108, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 0 with value: 33.714992626658024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:06:28,362 INFO [SEQ] Epoch 00  val_MAE=60.2022\n",
      "2025-11-23 11:06:28,861 INFO [SEQ] Epoch 01  val_MAE=53.1418\n",
      "2025-11-23 11:06:29,306 INFO [SEQ] Epoch 02  val_MAE=47.9442\n",
      "2025-11-23 11:06:29,770 INFO [SEQ] Epoch 03  val_MAE=38.4222\n",
      "2025-11-23 11:06:30,326 INFO [SEQ] Epoch 04  val_MAE=33.9630\n",
      "2025-11-23 11:06:31,019 INFO [SEQ] Epoch 05  val_MAE=29.8660\n",
      "2025-11-23 11:06:31,634 INFO [SEQ] Epoch 06  val_MAE=27.6359\n",
      "2025-11-23 11:06:32,117 INFO [SEQ] Epoch 07  val_MAE=25.6039\n",
      "2025-11-23 11:06:32,595 INFO [SEQ] Epoch 08  val_MAE=25.2084\n",
      "2025-11-23 11:06:33,079 INFO [SEQ] Epoch 09  val_MAE=24.0998\n",
      "2025-11-23 11:06:33,507 INFO [SEQ] Epoch 10  val_MAE=23.6269\n",
      "2025-11-23 11:06:33,930 INFO [SEQ] Epoch 11  val_MAE=23.5465\n",
      "2025-11-23 11:06:34,353 INFO [SEQ] Epoch 12  val_MAE=23.4614\n",
      "2025-11-23 11:06:34,903 INFO [SEQ] Epoch 13  val_MAE=22.9749\n",
      "2025-11-23 11:06:35,336 INFO [SEQ] Epoch 14  val_MAE=22.8492\n",
      "2025-11-23 11:06:35,764 INFO [SEQ] Epoch 15  val_MAE=23.1883\n",
      "2025-11-23 11:06:36,200 INFO [SEQ] Epoch 16  val_MAE=22.4244\n",
      "2025-11-23 11:06:36,626 INFO [SEQ] Epoch 17  val_MAE=22.0382\n",
      "2025-11-23 11:06:37,094 INFO [SEQ] Epoch 18  val_MAE=22.9675\n",
      "2025-11-23 11:06:37,535 INFO [SEQ] Epoch 19  val_MAE=22.4678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:06:37,560] Trial 1 finished with value: 22.03823642253876 and parameters: {'seq_len': 83, 'hidden': 36, 'layers': 2, 'lr': 0.0037689659000820007, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 1 with value: 22.03823642253876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:06:38,596 INFO [SEQ] Epoch 00  val_MAE=78.4705\n",
      "2025-11-23 11:06:39,439 INFO [SEQ] Epoch 01  val_MAE=75.5563\n",
      "2025-11-23 11:06:40,264 INFO [SEQ] Epoch 02  val_MAE=73.1309\n",
      "2025-11-23 11:06:41,059 INFO [SEQ] Epoch 03  val_MAE=70.4721\n",
      "2025-11-23 11:06:41,907 INFO [SEQ] Epoch 04  val_MAE=67.9090\n",
      "2025-11-23 11:06:42,794 INFO [SEQ] Epoch 05  val_MAE=65.5559\n",
      "2025-11-23 11:06:43,919 INFO [SEQ] Epoch 06  val_MAE=63.4646\n",
      "2025-11-23 11:06:45,024 INFO [SEQ] Epoch 07  val_MAE=61.3109\n",
      "2025-11-23 11:06:46,423 INFO [SEQ] Epoch 08  val_MAE=59.3290\n",
      "2025-11-23 11:06:47,422 INFO [SEQ] Epoch 09  val_MAE=57.2040\n",
      "2025-11-23 11:06:48,384 INFO [SEQ] Epoch 10  val_MAE=55.3176\n",
      "2025-11-23 11:06:49,331 INFO [SEQ] Epoch 11  val_MAE=53.6349\n",
      "2025-11-23 11:06:50,361 INFO [SEQ] Epoch 12  val_MAE=51.7932\n",
      "2025-11-23 11:06:51,403 INFO [SEQ] Epoch 13  val_MAE=50.2305\n",
      "2025-11-23 11:06:52,581 INFO [SEQ] Epoch 14  val_MAE=48.6210\n",
      "2025-11-23 11:06:53,436 INFO [SEQ] Epoch 15  val_MAE=47.1359\n",
      "2025-11-23 11:06:54,340 INFO [SEQ] Epoch 16  val_MAE=45.6058\n",
      "2025-11-23 11:06:55,208 INFO [SEQ] Epoch 17  val_MAE=44.0805\n",
      "2025-11-23 11:06:56,131 INFO [SEQ] Epoch 18  val_MAE=42.8283\n",
      "2025-11-23 11:06:57,046 INFO [SEQ] Epoch 19  val_MAE=41.3444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:06:57,068] Trial 2 finished with value: 41.34436807671531 and parameters: {'seq_len': 55, 'hidden': 114, 'layers': 2, 'lr': 0.00010777560178518667, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 1 with value: 22.03823642253876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:06:58,031 INFO [SEQ] Epoch 00  val_MAE=60.8100\n",
      "2025-11-23 11:06:58,766 INFO [SEQ] Epoch 01  val_MAE=44.8476\n",
      "2025-11-23 11:06:59,519 INFO [SEQ] Epoch 02  val_MAE=35.4701\n",
      "2025-11-23 11:07:00,302 INFO [SEQ] Epoch 03  val_MAE=29.5665\n",
      "2025-11-23 11:07:01,099 INFO [SEQ] Epoch 04  val_MAE=26.7888\n",
      "2025-11-23 11:07:01,936 INFO [SEQ] Epoch 05  val_MAE=24.9785\n",
      "2025-11-23 11:07:02,745 INFO [SEQ] Epoch 06  val_MAE=24.7258\n",
      "2025-11-23 11:07:03,570 INFO [SEQ] Epoch 07  val_MAE=23.9724\n",
      "2025-11-23 11:07:04,402 INFO [SEQ] Epoch 08  val_MAE=24.0437\n",
      "2025-11-23 11:07:05,215 INFO [SEQ] Epoch 09  val_MAE=23.6248\n",
      "2025-11-23 11:07:06,044 INFO [SEQ] Epoch 10  val_MAE=24.1185\n",
      "2025-11-23 11:07:06,890 INFO [SEQ] Epoch 11  val_MAE=24.7359\n",
      "2025-11-23 11:07:07,724 INFO [SEQ] Epoch 12  val_MAE=24.3301\n",
      "2025-11-23 11:07:08,708 INFO [SEQ] Epoch 13  val_MAE=24.4939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:07:08,741] Trial 3 finished with value: 23.62475204070409 and parameters: {'seq_len': 58, 'hidden': 76, 'layers': 1, 'lr': 0.0014298435361441038, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 1 with value: 22.03823642253876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:07:09,518 INFO [SEQ] Epoch 00  val_MAE=81.7929\n",
      "2025-11-23 11:07:10,047 INFO [SEQ] Epoch 01  val_MAE=77.1918\n",
      "2025-11-23 11:07:10,598 INFO [SEQ] Epoch 02  val_MAE=74.1847\n",
      "2025-11-23 11:07:11,131 INFO [SEQ] Epoch 03  val_MAE=71.3797\n",
      "2025-11-23 11:07:11,711 INFO [SEQ] Epoch 04  val_MAE=68.8671\n",
      "2025-11-23 11:07:12,260 INFO [SEQ] Epoch 05  val_MAE=66.5938\n",
      "2025-11-23 11:07:12,836 INFO [SEQ] Epoch 06  val_MAE=64.2660\n",
      "2025-11-23 11:07:13,426 INFO [SEQ] Epoch 07  val_MAE=62.1653\n",
      "2025-11-23 11:07:13,995 INFO [SEQ] Epoch 08  val_MAE=60.1184\n",
      "2025-11-23 11:07:14,566 INFO [SEQ] Epoch 09  val_MAE=58.2302\n",
      "2025-11-23 11:07:15,103 INFO [SEQ] Epoch 10  val_MAE=56.4833\n",
      "2025-11-23 11:07:15,692 INFO [SEQ] Epoch 11  val_MAE=54.5029\n",
      "2025-11-23 11:07:16,254 INFO [SEQ] Epoch 12  val_MAE=52.9629\n",
      "2025-11-23 11:07:16,834 INFO [SEQ] Epoch 13  val_MAE=51.3401\n",
      "2025-11-23 11:07:17,420 INFO [SEQ] Epoch 14  val_MAE=49.4813\n",
      "2025-11-23 11:07:17,954 INFO [SEQ] Epoch 15  val_MAE=48.0882\n",
      "2025-11-23 11:07:18,521 INFO [SEQ] Epoch 16  val_MAE=46.5109\n",
      "2025-11-23 11:07:19,102 INFO [SEQ] Epoch 17  val_MAE=45.0276\n",
      "2025-11-23 11:07:19,740 INFO [SEQ] Epoch 18  val_MAE=43.8003\n",
      "2025-11-23 11:07:20,319 INFO [SEQ] Epoch 19  val_MAE=42.5447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:07:20,370] Trial 4 finished with value: 42.54471618031699 and parameters: {'seq_len': 51, 'hidden': 68, 'layers': 1, 'lr': 0.0003553431972117803, 'batch_size': 64, 'model_type': 'gru'}. Best is trial 1 with value: 22.03823642253876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:07:21,228 INFO [SEQ] Epoch 00  val_MAE=32.1023\n",
      "2025-11-23 11:07:21,706 INFO [SEQ] Epoch 01  val_MAE=23.3741\n",
      "2025-11-23 11:07:22,233 INFO [SEQ] Epoch 02  val_MAE=19.3078\n",
      "2025-11-23 11:07:22,762 INFO [SEQ] Epoch 03  val_MAE=19.7519\n",
      "2025-11-23 11:07:23,308 INFO [SEQ] Epoch 04  val_MAE=19.7572\n",
      "2025-11-23 11:07:23,862 INFO [SEQ] Epoch 05  val_MAE=18.8600\n",
      "2025-11-23 11:07:24,403 INFO [SEQ] Epoch 06  val_MAE=19.7307\n",
      "2025-11-23 11:07:24,986 INFO [SEQ] Epoch 07  val_MAE=19.2755\n",
      "2025-11-23 11:07:25,539 INFO [SEQ] Epoch 08  val_MAE=18.9873\n",
      "2025-11-23 11:07:26,178 INFO [SEQ] Epoch 09  val_MAE=18.5578\n",
      "2025-11-23 11:07:26,751 INFO [SEQ] Epoch 10  val_MAE=19.8094\n",
      "2025-11-23 11:07:27,384 INFO [SEQ] Epoch 11  val_MAE=19.9313\n",
      "2025-11-23 11:07:27,940 INFO [SEQ] Epoch 12  val_MAE=19.1091\n",
      "2025-11-23 11:07:28,547 INFO [SEQ] Epoch 13  val_MAE=19.6025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:07:28,599] Trial 5 finished with value: 18.557767937212816 and parameters: {'seq_len': 108, 'hidden': 115, 'layers': 1, 'lr': 0.002862459049213856, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 5 with value: 18.557767937212816.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:07:29,671 INFO [SEQ] Epoch 00  val_MAE=77.1772\n",
      "2025-11-23 11:07:30,542 INFO [SEQ] Epoch 01  val_MAE=70.1701\n",
      "2025-11-23 11:07:31,501 INFO [SEQ] Epoch 02  val_MAE=64.3962\n",
      "2025-11-23 11:07:32,452 INFO [SEQ] Epoch 03  val_MAE=59.4450\n",
      "2025-11-23 11:07:33,445 INFO [SEQ] Epoch 04  val_MAE=54.5527\n",
      "2025-11-23 11:07:34,335 INFO [SEQ] Epoch 05  val_MAE=50.6231\n",
      "2025-11-23 11:07:35,214 INFO [SEQ] Epoch 06  val_MAE=46.6765\n",
      "2025-11-23 11:07:36,159 INFO [SEQ] Epoch 07  val_MAE=43.3576\n",
      "2025-11-23 11:07:37,029 INFO [SEQ] Epoch 08  val_MAE=40.4405\n",
      "2025-11-23 11:07:37,868 INFO [SEQ] Epoch 09  val_MAE=37.6756\n",
      "2025-11-23 11:07:38,719 INFO [SEQ] Epoch 10  val_MAE=35.3897\n",
      "2025-11-23 11:07:39,626 INFO [SEQ] Epoch 11  val_MAE=33.3759\n",
      "2025-11-23 11:07:40,480 INFO [SEQ] Epoch 12  val_MAE=32.0473\n",
      "2025-11-23 11:07:41,304 INFO [SEQ] Epoch 13  val_MAE=30.3977\n",
      "2025-11-23 11:07:42,208 INFO [SEQ] Epoch 14  val_MAE=29.2010\n",
      "2025-11-23 11:07:43,182 INFO [SEQ] Epoch 15  val_MAE=28.4159\n",
      "2025-11-23 11:07:44,216 INFO [SEQ] Epoch 16  val_MAE=27.5827\n",
      "2025-11-23 11:07:45,225 INFO [SEQ] Epoch 17  val_MAE=26.8815\n",
      "2025-11-23 11:07:46,211 INFO [SEQ] Epoch 18  val_MAE=26.0321\n",
      "2025-11-23 11:07:47,175 INFO [SEQ] Epoch 19  val_MAE=25.3886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:07:47,212] Trial 6 finished with value: 25.388641927185958 and parameters: {'seq_len': 49, 'hidden': 79, 'layers': 1, 'lr': 0.0003793419605681494, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 5 with value: 18.557767937212816.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:07:48,367 INFO [SEQ] Epoch 00  val_MAE=58.7712\n",
      "2025-11-23 11:07:49,229 INFO [SEQ] Epoch 01  val_MAE=43.0559\n",
      "2025-11-23 11:07:50,120 INFO [SEQ] Epoch 02  val_MAE=33.2689\n",
      "2025-11-23 11:07:50,942 INFO [SEQ] Epoch 03  val_MAE=27.8481\n",
      "2025-11-23 11:07:51,729 INFO [SEQ] Epoch 04  val_MAE=26.2440\n",
      "2025-11-23 11:07:52,500 INFO [SEQ] Epoch 05  val_MAE=25.9734\n",
      "2025-11-23 11:07:53,275 INFO [SEQ] Epoch 06  val_MAE=24.9662\n",
      "2025-11-23 11:07:54,068 INFO [SEQ] Epoch 07  val_MAE=22.9759\n",
      "2025-11-23 11:07:54,839 INFO [SEQ] Epoch 08  val_MAE=23.1119\n",
      "2025-11-23 11:07:55,625 INFO [SEQ] Epoch 09  val_MAE=24.0579\n",
      "2025-11-23 11:07:56,408 INFO [SEQ] Epoch 10  val_MAE=23.4977\n",
      "2025-11-23 11:07:57,221 INFO [SEQ] Epoch 11  val_MAE=23.3482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:07:57,267] Trial 7 finished with value: 22.975898991643856 and parameters: {'seq_len': 67, 'hidden': 70, 'layers': 2, 'lr': 0.001679022861454024, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 5 with value: 18.557767937212816.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:07:58,100 INFO [SEQ] Epoch 00  val_MAE=54.4880\n",
      "2025-11-23 11:07:58,609 INFO [SEQ] Epoch 01  val_MAE=51.5194\n",
      "2025-11-23 11:07:59,216 INFO [SEQ] Epoch 02  val_MAE=49.2028\n",
      "2025-11-23 11:07:59,769 INFO [SEQ] Epoch 03  val_MAE=47.2931\n",
      "2025-11-23 11:08:00,420 INFO [SEQ] Epoch 04  val_MAE=45.6906\n",
      "2025-11-23 11:08:01,125 INFO [SEQ] Epoch 05  val_MAE=44.2763\n",
      "2025-11-23 11:08:01,797 INFO [SEQ] Epoch 06  val_MAE=41.1098\n",
      "2025-11-23 11:08:02,360 INFO [SEQ] Epoch 07  val_MAE=38.6982\n",
      "2025-11-23 11:08:02,929 INFO [SEQ] Epoch 08  val_MAE=36.2889\n",
      "2025-11-23 11:08:03,497 INFO [SEQ] Epoch 09  val_MAE=34.4395\n",
      "2025-11-23 11:08:04,040 INFO [SEQ] Epoch 10  val_MAE=32.7505\n",
      "2025-11-23 11:08:04,590 INFO [SEQ] Epoch 11  val_MAE=31.2883\n",
      "2025-11-23 11:08:05,168 INFO [SEQ] Epoch 12  val_MAE=30.4243\n",
      "2025-11-23 11:08:05,719 INFO [SEQ] Epoch 13  val_MAE=29.4493\n",
      "2025-11-23 11:08:06,241 INFO [SEQ] Epoch 14  val_MAE=28.5334\n",
      "2025-11-23 11:08:06,923 INFO [SEQ] Epoch 15  val_MAE=27.6351\n",
      "2025-11-23 11:08:07,571 INFO [SEQ] Epoch 16  val_MAE=26.5166\n",
      "2025-11-23 11:08:08,225 INFO [SEQ] Epoch 17  val_MAE=25.6366\n",
      "2025-11-23 11:08:08,839 INFO [SEQ] Epoch 18  val_MAE=24.6937\n",
      "2025-11-23 11:08:09,553 INFO [SEQ] Epoch 19  val_MAE=24.1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:08:09,600] Trial 8 finished with value: 24.164627157353067 and parameters: {'seq_len': 117, 'hidden': 45, 'layers': 2, 'lr': 0.0005770488792010813, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 5 with value: 18.557767937212816.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:08:10,921 INFO [SEQ] Epoch 00  val_MAE=47.3137\n",
      "2025-11-23 11:08:11,887 INFO [SEQ] Epoch 01  val_MAE=38.8546\n",
      "2025-11-23 11:08:12,891 INFO [SEQ] Epoch 02  val_MAE=32.4539\n",
      "2025-11-23 11:08:13,895 INFO [SEQ] Epoch 03  val_MAE=27.5284\n",
      "2025-11-23 11:08:15,041 INFO [SEQ] Epoch 04  val_MAE=24.0701\n",
      "2025-11-23 11:08:16,312 INFO [SEQ] Epoch 05  val_MAE=21.8984\n",
      "2025-11-23 11:08:17,537 INFO [SEQ] Epoch 06  val_MAE=20.0417\n",
      "2025-11-23 11:08:18,618 INFO [SEQ] Epoch 07  val_MAE=19.1601\n",
      "2025-11-23 11:08:19,643 INFO [SEQ] Epoch 08  val_MAE=18.0205\n",
      "2025-11-23 11:08:20,606 INFO [SEQ] Epoch 09  val_MAE=17.8202\n",
      "2025-11-23 11:08:21,624 INFO [SEQ] Epoch 10  val_MAE=17.7791\n",
      "2025-11-23 11:08:22,757 INFO [SEQ] Epoch 11  val_MAE=17.7177\n",
      "2025-11-23 11:08:23,895 INFO [SEQ] Epoch 12  val_MAE=17.2122\n",
      "2025-11-23 11:08:25,118 INFO [SEQ] Epoch 13  val_MAE=17.2917\n",
      "2025-11-23 11:08:26,465 INFO [SEQ] Epoch 14  val_MAE=16.3925\n",
      "2025-11-23 11:08:27,516 INFO [SEQ] Epoch 15  val_MAE=16.3333\n",
      "2025-11-23 11:08:28,611 INFO [SEQ] Epoch 16  val_MAE=15.7765\n",
      "2025-11-23 11:08:29,730 INFO [SEQ] Epoch 17  val_MAE=15.8902\n",
      "2025-11-23 11:08:30,813 INFO [SEQ] Epoch 18  val_MAE=16.5952\n",
      "2025-11-23 11:08:31,895 INFO [SEQ] Epoch 19  val_MAE=15.8013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:08:31,941] Trial 9 finished with value: 15.776484062145283 and parameters: {'seq_len': 113, 'hidden': 49, 'layers': 1, 'lr': 0.0010586001963975513, 'batch_size': 16, 'model_type': 'lstm'}. Best is trial 9 with value: 15.776484062145283.\n",
      "Best inner params: {'seq_len': 113, 'hidden': 49, 'layers': 1, 'lr': 0.0010586001963975513, 'batch_size': 16, 'model_type': 'lstm'}\n",
      "Train windows: (4309, 113, 107)  Val windows: (2450, 113, 107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:08:33,310 INFO [SEQ] Epoch 00  val_MAE=46.8945\n",
      "2025-11-23 11:08:34,376 INFO [SEQ] Epoch 01  val_MAE=37.9125\n",
      "2025-11-23 11:08:35,429 INFO [SEQ] Epoch 02  val_MAE=31.6992\n",
      "2025-11-23 11:08:36,464 INFO [SEQ] Epoch 03  val_MAE=27.3605\n",
      "2025-11-23 11:08:37,465 INFO [SEQ] Epoch 04  val_MAE=24.7236\n",
      "2025-11-23 11:08:38,459 INFO [SEQ] Epoch 05  val_MAE=22.4707\n",
      "2025-11-23 11:08:39,467 INFO [SEQ] Epoch 06  val_MAE=20.6489\n",
      "2025-11-23 11:08:40,533 INFO [SEQ] Epoch 07  val_MAE=19.1425\n",
      "2025-11-23 11:08:41,583 INFO [SEQ] Epoch 08  val_MAE=17.9748\n",
      "2025-11-23 11:08:42,642 INFO [SEQ] Epoch 09  val_MAE=18.3659\n",
      "2025-11-23 11:08:43,714 INFO [SEQ] Epoch 10  val_MAE=17.4246\n",
      "2025-11-23 11:08:44,781 INFO [SEQ] Epoch 11  val_MAE=17.2037\n",
      "2025-11-23 11:08:45,891 INFO [SEQ] Epoch 12  val_MAE=16.6159\n",
      "2025-11-23 11:08:46,984 INFO [SEQ] Epoch 13  val_MAE=16.5370\n",
      "2025-11-23 11:08:48,057 INFO [SEQ] Epoch 14  val_MAE=16.5841\n",
      "2025-11-23 11:08:49,174 INFO [SEQ] Epoch 15  val_MAE=16.7540\n",
      "2025-11-23 11:08:50,210 INFO [SEQ] Epoch 16  val_MAE=16.9404\n",
      "2025-11-23 11:08:51,236 INFO [SEQ] Epoch 17  val_MAE=16.7046\n",
      "2025-11-23 11:08:52,261 INFO [SEQ] Epoch 18  val_MAE=17.2323\n",
      "[I 2025-11-23 11:08:52,527] A new study created in memory with name: no-name-8ec04c6f-be4c-41a5-bbfa-ebea69e389d5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2 METRICS: {'MAE': 16.621173858642578, 'RMSE': 30.084636064749688, 'R2': 0.6446547508239746}\n",
      "\n",
      "==============================\n",
      " OUTER FOLD 3/3\n",
      "==============================\n",
      "Train units: 75  Val units: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9fb5d8b73e4456a14e35171410048f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:08:53,841 INFO [SEQ] Epoch 00  val_MAE=41.4038\n",
      "2025-11-23 11:08:54,331 INFO [SEQ] Epoch 01  val_MAE=41.7049\n",
      "2025-11-23 11:08:54,839 INFO [SEQ] Epoch 02  val_MAE=20.3036\n",
      "2025-11-23 11:08:55,342 INFO [SEQ] Epoch 03  val_MAE=17.3035\n",
      "2025-11-23 11:08:55,854 INFO [SEQ] Epoch 04  val_MAE=15.8812\n",
      "2025-11-23 11:08:56,353 INFO [SEQ] Epoch 05  val_MAE=15.5100\n",
      "2025-11-23 11:08:56,827 INFO [SEQ] Epoch 06  val_MAE=13.9050\n",
      "2025-11-23 11:08:57,357 INFO [SEQ] Epoch 07  val_MAE=13.7196\n",
      "2025-11-23 11:08:57,868 INFO [SEQ] Epoch 08  val_MAE=13.9159\n",
      "2025-11-23 11:08:58,366 INFO [SEQ] Epoch 09  val_MAE=15.1027\n",
      "2025-11-23 11:08:58,864 INFO [SEQ] Epoch 10  val_MAE=13.7089\n",
      "2025-11-23 11:08:59,402 INFO [SEQ] Epoch 11  val_MAE=13.7723\n",
      "2025-11-23 11:08:59,981 INFO [SEQ] Epoch 12  val_MAE=16.0100\n",
      "2025-11-23 11:09:00,561 INFO [SEQ] Epoch 13  val_MAE=13.9260\n",
      "2025-11-23 11:09:01,112 INFO [SEQ] Epoch 14  val_MAE=15.3490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:09:01,148] Trial 0 finished with value: 13.708879609440649 and parameters: {'seq_len': 110, 'hidden': 105, 'layers': 2, 'lr': 0.007882845761349068, 'batch_size': 64, 'model_type': 'gru'}. Best is trial 0 with value: 13.708879609440649.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:09:04,017 INFO [SEQ] Epoch 00  val_MAE=54.0538\n",
      "2025-11-23 11:09:06,200 INFO [SEQ] Epoch 01  val_MAE=41.1554\n",
      "2025-11-23 11:09:08,303 INFO [SEQ] Epoch 02  val_MAE=32.1097\n",
      "2025-11-23 11:09:10,356 INFO [SEQ] Epoch 03  val_MAE=26.9246\n",
      "2025-11-23 11:09:12,402 INFO [SEQ] Epoch 04  val_MAE=23.8179\n",
      "2025-11-23 11:09:14,414 INFO [SEQ] Epoch 05  val_MAE=21.5425\n",
      "2025-11-23 11:09:16,444 INFO [SEQ] Epoch 06  val_MAE=20.5330\n",
      "2025-11-23 11:09:18,329 INFO [SEQ] Epoch 07  val_MAE=19.0418\n",
      "2025-11-23 11:09:20,587 INFO [SEQ] Epoch 08  val_MAE=19.0144\n",
      "2025-11-23 11:09:22,793 INFO [SEQ] Epoch 09  val_MAE=19.1914\n",
      "2025-11-23 11:09:24,958 INFO [SEQ] Epoch 10  val_MAE=19.0153\n",
      "2025-11-23 11:09:27,110 INFO [SEQ] Epoch 11  val_MAE=18.6748\n",
      "2025-11-23 11:09:29,381 INFO [SEQ] Epoch 12  val_MAE=18.8206\n",
      "2025-11-23 11:09:31,209 INFO [SEQ] Epoch 13  val_MAE=19.0988\n",
      "2025-11-23 11:09:32,954 INFO [SEQ] Epoch 14  val_MAE=19.0356\n",
      "2025-11-23 11:09:34,659 INFO [SEQ] Epoch 15  val_MAE=19.1913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:09:34,692] Trial 1 finished with value: 18.674838058326554 and parameters: {'seq_len': 88, 'hidden': 40, 'layers': 2, 'lr': 0.0010103287914332072, 'batch_size': 16, 'model_type': 'gru'}. Best is trial 0 with value: 13.708879609440649.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:09:35,737 INFO [SEQ] Epoch 00  val_MAE=56.6409\n",
      "2025-11-23 11:09:36,604 INFO [SEQ] Epoch 01  val_MAE=40.6775\n",
      "2025-11-23 11:09:37,350 INFO [SEQ] Epoch 02  val_MAE=29.1153\n",
      "2025-11-23 11:09:38,004 INFO [SEQ] Epoch 03  val_MAE=23.7223\n",
      "2025-11-23 11:09:38,563 INFO [SEQ] Epoch 04  val_MAE=21.4650\n",
      "2025-11-23 11:09:39,220 INFO [SEQ] Epoch 05  val_MAE=19.2553\n",
      "2025-11-23 11:09:39,959 INFO [SEQ] Epoch 06  val_MAE=17.9148\n",
      "2025-11-23 11:09:40,759 INFO [SEQ] Epoch 07  val_MAE=19.3580\n",
      "2025-11-23 11:09:41,555 INFO [SEQ] Epoch 08  val_MAE=18.3918\n",
      "2025-11-23 11:09:42,400 INFO [SEQ] Epoch 09  val_MAE=17.0478\n",
      "2025-11-23 11:09:43,135 INFO [SEQ] Epoch 10  val_MAE=18.3744\n",
      "2025-11-23 11:09:43,874 INFO [SEQ] Epoch 11  val_MAE=17.5358\n",
      "2025-11-23 11:09:44,668 INFO [SEQ] Epoch 12  val_MAE=17.2151\n",
      "2025-11-23 11:09:45,469 INFO [SEQ] Epoch 13  val_MAE=16.6901\n",
      "2025-11-23 11:09:46,303 INFO [SEQ] Epoch 14  val_MAE=17.5665\n",
      "2025-11-23 11:09:47,062 INFO [SEQ] Epoch 15  val_MAE=17.3312\n",
      "2025-11-23 11:09:47,763 INFO [SEQ] Epoch 16  val_MAE=17.9278\n",
      "2025-11-23 11:09:48,499 INFO [SEQ] Epoch 17  val_MAE=17.6580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:09:48,533] Trial 2 finished with value: 16.69009660419665 and parameters: {'seq_len': 75, 'hidden': 80, 'layers': 2, 'lr': 0.002590917812063434, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 0 with value: 13.708879609440649.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:09:49,635 INFO [SEQ] Epoch 00  val_MAE=27.7553\n",
      "2025-11-23 11:09:50,461 INFO [SEQ] Epoch 01  val_MAE=19.6003\n",
      "2025-11-23 11:09:51,220 INFO [SEQ] Epoch 02  val_MAE=17.1317\n",
      "2025-11-23 11:09:51,984 INFO [SEQ] Epoch 03  val_MAE=14.9467\n",
      "2025-11-23 11:09:52,774 INFO [SEQ] Epoch 04  val_MAE=13.7999\n",
      "2025-11-23 11:09:53,541 INFO [SEQ] Epoch 05  val_MAE=13.7294\n",
      "2025-11-23 11:09:54,383 INFO [SEQ] Epoch 06  val_MAE=12.8784\n",
      "2025-11-23 11:09:55,132 INFO [SEQ] Epoch 07  val_MAE=12.1338\n",
      "2025-11-23 11:09:55,923 INFO [SEQ] Epoch 08  val_MAE=12.6890\n",
      "2025-11-23 11:09:56,749 INFO [SEQ] Epoch 09  val_MAE=13.3904\n",
      "2025-11-23 11:09:57,578 INFO [SEQ] Epoch 10  val_MAE=11.9004\n",
      "2025-11-23 11:09:58,342 INFO [SEQ] Epoch 11  val_MAE=12.5144\n",
      "2025-11-23 11:09:59,282 INFO [SEQ] Epoch 12  val_MAE=12.0707\n",
      "2025-11-23 11:10:00,278 INFO [SEQ] Epoch 13  val_MAE=10.9967\n",
      "2025-11-23 11:10:01,151 INFO [SEQ] Epoch 14  val_MAE=13.7643\n",
      "2025-11-23 11:10:02,141 INFO [SEQ] Epoch 15  val_MAE=11.1064\n",
      "2025-11-23 11:10:03,030 INFO [SEQ] Epoch 16  val_MAE=11.3670\n",
      "2025-11-23 11:10:03,889 INFO [SEQ] Epoch 17  val_MAE=10.8285\n",
      "2025-11-23 11:10:04,750 INFO [SEQ] Epoch 18  val_MAE=10.6057\n",
      "2025-11-23 11:10:05,663 INFO [SEQ] Epoch 19  val_MAE=12.5752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:10:05,700] Trial 3 finished with value: 10.60570379857267 and parameters: {'seq_len': 107, 'hidden': 108, 'layers': 1, 'lr': 0.0030698427779806132, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:10:07,166 INFO [SEQ] Epoch 00  val_MAE=55.3936\n",
      "2025-11-23 11:10:08,128 INFO [SEQ] Epoch 01  val_MAE=42.9187\n",
      "2025-11-23 11:10:09,151 INFO [SEQ] Epoch 02  val_MAE=33.9583\n",
      "2025-11-23 11:10:10,244 INFO [SEQ] Epoch 03  val_MAE=28.0471\n",
      "2025-11-23 11:10:11,235 INFO [SEQ] Epoch 04  val_MAE=23.9831\n",
      "2025-11-23 11:10:12,200 INFO [SEQ] Epoch 05  val_MAE=21.3638\n",
      "2025-11-23 11:10:13,163 INFO [SEQ] Epoch 06  val_MAE=19.4682\n",
      "2025-11-23 11:10:14,115 INFO [SEQ] Epoch 07  val_MAE=18.5127\n",
      "2025-11-23 11:10:15,119 INFO [SEQ] Epoch 08  val_MAE=17.8725\n",
      "2025-11-23 11:10:16,173 INFO [SEQ] Epoch 09  val_MAE=16.8733\n",
      "2025-11-23 11:10:17,252 INFO [SEQ] Epoch 10  val_MAE=16.4990\n",
      "2025-11-23 11:10:18,337 INFO [SEQ] Epoch 11  val_MAE=15.9046\n",
      "2025-11-23 11:10:19,463 INFO [SEQ] Epoch 12  val_MAE=15.8532\n",
      "2025-11-23 11:10:20,576 INFO [SEQ] Epoch 13  val_MAE=15.8595\n",
      "2025-11-23 11:10:21,654 INFO [SEQ] Epoch 14  val_MAE=16.2230\n",
      "2025-11-23 11:10:22,692 INFO [SEQ] Epoch 15  val_MAE=16.3804\n",
      "2025-11-23 11:10:23,704 INFO [SEQ] Epoch 16  val_MAE=15.6435\n",
      "2025-11-23 11:10:24,662 INFO [SEQ] Epoch 17  val_MAE=15.0427\n",
      "2025-11-23 11:10:25,661 INFO [SEQ] Epoch 18  val_MAE=15.8073\n",
      "2025-11-23 11:10:26,655 INFO [SEQ] Epoch 19  val_MAE=15.6322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:10:26,703] Trial 4 finished with value: 15.042698900310361 and parameters: {'seq_len': 95, 'hidden': 76, 'layers': 2, 'lr': 0.0009486657803992307, 'batch_size': 32, 'model_type': 'lstm'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:10:29,223 INFO [SEQ] Epoch 00  val_MAE=23.6764\n",
      "2025-11-23 11:10:31,384 INFO [SEQ] Epoch 01  val_MAE=20.2981\n",
      "2025-11-23 11:10:33,590 INFO [SEQ] Epoch 02  val_MAE=19.3953\n",
      "2025-11-23 11:10:35,774 INFO [SEQ] Epoch 03  val_MAE=21.6863\n",
      "2025-11-23 11:10:38,021 INFO [SEQ] Epoch 04  val_MAE=18.9988\n",
      "2025-11-23 11:10:40,259 INFO [SEQ] Epoch 05  val_MAE=18.6391\n",
      "2025-11-23 11:10:42,472 INFO [SEQ] Epoch 06  val_MAE=18.1702\n",
      "2025-11-23 11:10:44,700 INFO [SEQ] Epoch 07  val_MAE=19.1898\n",
      "2025-11-23 11:10:46,895 INFO [SEQ] Epoch 08  val_MAE=18.8266\n",
      "2025-11-23 11:10:48,988 INFO [SEQ] Epoch 09  val_MAE=17.8260\n",
      "2025-11-23 11:10:51,125 INFO [SEQ] Epoch 10  val_MAE=19.9049\n",
      "2025-11-23 11:10:53,379 INFO [SEQ] Epoch 11  val_MAE=20.0333\n",
      "2025-11-23 11:10:55,516 INFO [SEQ] Epoch 12  val_MAE=18.1439\n",
      "2025-11-23 11:10:57,698 INFO [SEQ] Epoch 13  val_MAE=19.4511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:10:57,732] Trial 5 finished with value: 17.826012342330444 and parameters: {'seq_len': 61, 'hidden': 95, 'layers': 2, 'lr': 0.0040411997706326815, 'batch_size': 16, 'model_type': 'gru'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:10:58,710 INFO [SEQ] Epoch 00  val_MAE=66.6261\n",
      "2025-11-23 11:10:59,230 INFO [SEQ] Epoch 01  val_MAE=61.7958\n",
      "2025-11-23 11:10:59,724 INFO [SEQ] Epoch 02  val_MAE=59.0577\n",
      "2025-11-23 11:11:00,228 INFO [SEQ] Epoch 03  val_MAE=56.5956\n",
      "2025-11-23 11:11:00,790 INFO [SEQ] Epoch 04  val_MAE=54.4594\n",
      "2025-11-23 11:11:01,296 INFO [SEQ] Epoch 05  val_MAE=52.3360\n",
      "2025-11-23 11:11:01,839 INFO [SEQ] Epoch 06  val_MAE=50.3878\n",
      "2025-11-23 11:11:02,379 INFO [SEQ] Epoch 07  val_MAE=48.6267\n",
      "2025-11-23 11:11:02,923 INFO [SEQ] Epoch 08  val_MAE=46.9060\n",
      "2025-11-23 11:11:03,456 INFO [SEQ] Epoch 09  val_MAE=45.2268\n",
      "2025-11-23 11:11:03,998 INFO [SEQ] Epoch 10  val_MAE=43.7556\n",
      "2025-11-23 11:11:04,642 INFO [SEQ] Epoch 11  val_MAE=42.3023\n",
      "2025-11-23 11:11:05,283 INFO [SEQ] Epoch 12  val_MAE=40.8449\n",
      "2025-11-23 11:11:05,859 INFO [SEQ] Epoch 13  val_MAE=39.6805\n",
      "2025-11-23 11:11:06,414 INFO [SEQ] Epoch 14  val_MAE=38.2644\n",
      "2025-11-23 11:11:06,982 INFO [SEQ] Epoch 15  val_MAE=37.0124\n",
      "2025-11-23 11:11:07,520 INFO [SEQ] Epoch 16  val_MAE=35.9638\n",
      "2025-11-23 11:11:08,033 INFO [SEQ] Epoch 17  val_MAE=34.6995\n",
      "2025-11-23 11:11:08,622 INFO [SEQ] Epoch 18  val_MAE=33.6888\n",
      "2025-11-23 11:11:09,155 INFO [SEQ] Epoch 19  val_MAE=32.7697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:11:09,195] Trial 6 finished with value: 32.76965533693632 and parameters: {'seq_len': 99, 'hidden': 107, 'layers': 1, 'lr': 0.00019235288824998988, 'batch_size': 64, 'model_type': 'lstm'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:11:11,719 INFO [SEQ] Epoch 00  val_MAE=27.5496\n",
      "2025-11-23 11:11:14,181 INFO [SEQ] Epoch 01  val_MAE=20.7852\n",
      "2025-11-23 11:11:16,536 INFO [SEQ] Epoch 02  val_MAE=21.3547\n",
      "2025-11-23 11:11:18,581 INFO [SEQ] Epoch 03  val_MAE=20.5416\n",
      "2025-11-23 11:11:20,856 INFO [SEQ] Epoch 04  val_MAE=21.5792\n",
      "2025-11-23 11:11:23,684 INFO [SEQ] Epoch 05  val_MAE=21.5135\n",
      "2025-11-23 11:11:26,319 INFO [SEQ] Epoch 06  val_MAE=21.4016\n",
      "2025-11-23 11:11:28,913 INFO [SEQ] Epoch 07  val_MAE=25.6757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:11:28,945] Trial 7 finished with value: 20.54162232066593 and parameters: {'seq_len': 45, 'hidden': 80, 'layers': 1, 'lr': 0.007030828893449769, 'batch_size': 16, 'model_type': 'lstm'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:11:31,865 INFO [SEQ] Epoch 00  val_MAE=77.8206\n",
      "2025-11-23 11:11:33,849 INFO [SEQ] Epoch 01  val_MAE=72.9692\n",
      "2025-11-23 11:11:35,793 INFO [SEQ] Epoch 02  val_MAE=68.9167\n",
      "2025-11-23 11:11:37,471 INFO [SEQ] Epoch 03  val_MAE=65.2877\n",
      "2025-11-23 11:11:39,409 INFO [SEQ] Epoch 04  val_MAE=61.7944\n",
      "2025-11-23 11:11:41,479 INFO [SEQ] Epoch 05  val_MAE=58.3931\n",
      "2025-11-23 11:11:43,771 INFO [SEQ] Epoch 06  val_MAE=55.3140\n",
      "2025-11-23 11:11:46,085 INFO [SEQ] Epoch 07  val_MAE=52.3929\n",
      "2025-11-23 11:11:48,140 INFO [SEQ] Epoch 08  val_MAE=49.5071\n",
      "2025-11-23 11:11:49,998 INFO [SEQ] Epoch 09  val_MAE=46.7791\n",
      "2025-11-23 11:11:51,971 INFO [SEQ] Epoch 10  val_MAE=44.2887\n",
      "2025-11-23 11:11:54,362 INFO [SEQ] Epoch 11  val_MAE=41.8809\n",
      "2025-11-23 11:11:56,433 INFO [SEQ] Epoch 12  val_MAE=39.7653\n",
      "2025-11-23 11:11:58,577 INFO [SEQ] Epoch 13  val_MAE=37.7256\n",
      "2025-11-23 11:12:00,725 INFO [SEQ] Epoch 14  val_MAE=35.7698\n",
      "2025-11-23 11:12:03,288 INFO [SEQ] Epoch 15  val_MAE=33.9958\n",
      "2025-11-23 11:12:05,697 INFO [SEQ] Epoch 16  val_MAE=32.4034\n",
      "2025-11-23 11:12:08,084 INFO [SEQ] Epoch 17  val_MAE=30.9460\n",
      "2025-11-23 11:12:10,264 INFO [SEQ] Epoch 18  val_MAE=29.6889\n",
      "2025-11-23 11:12:12,580 INFO [SEQ] Epoch 19  val_MAE=28.5572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:12:12,620] Trial 8 finished with value: 28.557238303774124 and parameters: {'seq_len': 66, 'hidden': 39, 'layers': 1, 'lr': 0.00017997044101444114, 'batch_size': 16, 'model_type': 'lstm'}. Best is trial 3 with value: 10.60570379857267.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:12:14,042 INFO [SEQ] Epoch 00  val_MAE=41.0988\n",
      "2025-11-23 11:12:15,093 INFO [SEQ] Epoch 01  val_MAE=27.3748\n",
      "2025-11-23 11:12:16,080 INFO [SEQ] Epoch 02  val_MAE=21.0441\n",
      "2025-11-23 11:12:16,971 INFO [SEQ] Epoch 03  val_MAE=18.4877\n",
      "2025-11-23 11:12:17,901 INFO [SEQ] Epoch 04  val_MAE=17.4932\n",
      "2025-11-23 11:12:18,865 INFO [SEQ] Epoch 05  val_MAE=16.4507\n",
      "2025-11-23 11:12:19,784 INFO [SEQ] Epoch 06  val_MAE=18.1745\n",
      "2025-11-23 11:12:20,764 INFO [SEQ] Epoch 07  val_MAE=16.7064\n",
      "2025-11-23 11:12:21,947 INFO [SEQ] Epoch 08  val_MAE=15.8572\n",
      "2025-11-23 11:12:22,980 INFO [SEQ] Epoch 09  val_MAE=14.5108\n",
      "2025-11-23 11:12:24,063 INFO [SEQ] Epoch 10  val_MAE=14.6344\n",
      "2025-11-23 11:12:25,182 INFO [SEQ] Epoch 11  val_MAE=15.3155\n",
      "2025-11-23 11:12:26,235 INFO [SEQ] Epoch 12  val_MAE=15.1199\n",
      "2025-11-23 11:12:27,217 INFO [SEQ] Epoch 13  val_MAE=13.9629\n",
      "2025-11-23 11:12:28,201 INFO [SEQ] Epoch 14  val_MAE=15.1280\n",
      "2025-11-23 11:12:29,163 INFO [SEQ] Epoch 15  val_MAE=14.3415\n",
      "2025-11-23 11:12:30,273 INFO [SEQ] Epoch 16  val_MAE=15.0912\n",
      "2025-11-23 11:12:31,282 INFO [SEQ] Epoch 17  val_MAE=14.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 11:12:31,325] Trial 9 finished with value: 13.96290086180556 and parameters: {'seq_len': 90, 'hidden': 123, 'layers': 1, 'lr': 0.0012259228316582405, 'batch_size': 32, 'model_type': 'gru'}. Best is trial 3 with value: 10.60570379857267.\n",
      "Best inner params: {'seq_len': 107, 'hidden': 108, 'layers': 1, 'lr': 0.0030698427779806132, 'batch_size': 32, 'model_type': 'lstm'}\n",
      "Train windows: (7209, 107, 107)  Val windows: (2822, 107, 107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:12:32,683 INFO [SEQ] Epoch 00  val_MAE=28.2923\n",
      "2025-11-23 11:12:33,474 INFO [SEQ] Epoch 01  val_MAE=19.4247\n",
      "2025-11-23 11:12:34,339 INFO [SEQ] Epoch 02  val_MAE=16.2611\n",
      "2025-11-23 11:12:35,185 INFO [SEQ] Epoch 03  val_MAE=15.1007\n",
      "2025-11-23 11:12:35,936 INFO [SEQ] Epoch 04  val_MAE=14.1597\n",
      "2025-11-23 11:12:36,792 INFO [SEQ] Epoch 05  val_MAE=14.6914\n",
      "2025-11-23 11:12:37,586 INFO [SEQ] Epoch 06  val_MAE=14.2662\n",
      "2025-11-23 11:12:38,404 INFO [SEQ] Epoch 07  val_MAE=13.3075\n",
      "2025-11-23 11:12:39,184 INFO [SEQ] Epoch 08  val_MAE=14.2080\n",
      "2025-11-23 11:12:39,986 INFO [SEQ] Epoch 09  val_MAE=18.7420\n",
      "2025-11-23 11:12:40,874 INFO [SEQ] Epoch 10  val_MAE=16.4655\n",
      "2025-11-23 11:12:41,684 INFO [SEQ] Epoch 11  val_MAE=15.6809\n",
      "2025-11-23 11:12:42,527 INFO [SEQ] Epoch 12  val_MAE=15.2432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 3 METRICS: {'MAE': 13.404685974121094, 'RMSE': 22.837573175255645, 'R2': 0.8074919581413269}\n",
      "\n",
      "==============================\n",
      " FINAL Nested CV Results\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.437923</td>\n",
       "      <td>11.001263</td>\n",
       "      <td>0.894977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.621174</td>\n",
       "      <td>30.084636</td>\n",
       "      <td>0.644655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.404686</td>\n",
       "      <td>22.837573</td>\n",
       "      <td>0.807492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE       RMSE        R2\n",
       "0   7.437923  11.001263  0.894977\n",
       "1  16.621174  30.084636  0.644655\n",
       "2  13.404686  22.837573  0.807492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: MAE     12.487928\n",
      "RMSE    21.307824\n",
      "R2       0.782375\n",
      "dtype: float64\n",
      "Std: MAE     4.659760\n",
      "RMSE    9.633218\n",
      "R2      0.127037\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import optuna\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ------------------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------------------\n",
    "OUTER_FOLDS = 3\n",
    "INNER_TRIALS = 10\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# ------------------------------------------\n",
    "# Helper: inner objective for Optuna\n",
    "# ------------------------------------------\n",
    "def inner_objective(trial, train_df, val_df, sequence_features):\n",
    "\n",
    "    seq_len  = trial.suggest_int(\"seq_len\", 40, 120)\n",
    "    hidden   = trial.suggest_int(\"hidden\", 32, 128)\n",
    "    layers   = trial.suggest_int(\"layers\", 1, 2)\n",
    "    lr       = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    batch_sz = trial.suggest_categorical(\"batch_size\", [16,32,64])\n",
    "\n",
    "    # --- build windows ---\n",
    "    Xtr, ytr, _ = make_windows(train_df, sequence_features, seq_len=seq_len)\n",
    "    Xva, yva, _ = make_windows(val_df,  sequence_features, seq_len=seq_len)\n",
    "\n",
    "    if len(Xtr) == 0 or len(Xva) == 0:\n",
    "        return float(\"inf\")\n",
    "\n",
    "    train_loader = DataLoader(SequenceDataset(Xtr, ytr), batch_size=batch_sz, shuffle=True)\n",
    "    val_loader   = DataLoader(SequenceDataset(Xva, yva), batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    # Try both LSTM and GRU inside nested CV.\n",
    "    model_type = trial.suggest_categorical(\"model_type\", [\"lstm\", \"gru\"])\n",
    "\n",
    "    n_features = len(sequence_features)\n",
    "\n",
    "    if model_type == \"lstm\":\n",
    "        model = LSTMRegressor(n_features, hidden, layers)\n",
    "    else:\n",
    "        model = GRURegressor(n_features, hidden, layers)\n",
    "\n",
    "    model, best_mae = train_sequence_model(\n",
    "        model, train_loader, val_loader,\n",
    "        lr=lr, epochs=20, patience=4, device=DEVICE\n",
    "    )\n",
    "\n",
    "    return best_mae\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# OUTER NESTED CV LOOP\n",
    "# -----------------------------------------------------\n",
    "units = train_df[\"unit\"].unique()\n",
    "outer_tscv = TimeSeriesSplit(n_splits=OUTER_FOLDS)\n",
    "\n",
    "outer_results = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(outer_tscv.split(units)):\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" OUTER FOLD {fold+1}/{OUTER_FOLDS}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    train_units = units[tr_idx]\n",
    "    val_units   = units[va_idx]\n",
    "\n",
    "    train_units_df = train_df[train_df[\"unit\"].isin(train_units)].copy()\n",
    "    val_units_df   = train_df[train_df[\"unit\"].isin(val_units)].copy()\n",
    "\n",
    "    print(\"Train units:\", len(train_units), \" Val units:\", len(val_units))\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # INNER OPTUNA\n",
    "    # ------------------------------------------\n",
    "    def objective(trial):\n",
    "        return inner_objective(trial, train_units_df, val_units_df, sequence_features)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=INNER_TRIALS, show_progress_bar=True)\n",
    "\n",
    "    print(\"Best inner params:\", study.best_params)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    seq_len     = best_params[\"seq_len\"]\n",
    "    hidden      = best_params[\"hidden\"]\n",
    "    layers      = best_params[\"layers\"]\n",
    "    lr          = best_params[\"lr\"]\n",
    "    batch_sz    = best_params[\"batch_size\"]\n",
    "    model_type  = best_params[\"model_type\"]\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Retrain best model on outer-train\n",
    "    # ------------------------------------------\n",
    "    Xtr, ytr, _ = make_windows(train_units_df, sequence_features, seq_len=seq_len)\n",
    "    Xva, yva, _ = make_windows(val_units_df,   sequence_features, seq_len=seq_len)\n",
    "\n",
    "    print(\"Train windows:\", Xtr.shape, \" Val windows:\", Xva.shape)\n",
    "\n",
    "    train_loader = DataLoader(SequenceDataset(Xtr, ytr), batch_size=batch_sz, shuffle=True)\n",
    "    val_loader   = DataLoader(SequenceDataset(Xva, yva), batch_size=batch_sz, shuffle=False)\n",
    "\n",
    "    n_features = len(sequence_features)\n",
    "\n",
    "    if model_type == \"lstm\":\n",
    "        model = LSTMRegressor(n_features, hidden, layers)\n",
    "    else:\n",
    "        model = GRURegressor(n_features, hidden, layers)\n",
    "\n",
    "    model, _ = train_sequence_model(\n",
    "        model, train_loader, val_loader,\n",
    "        lr=lr, epochs=25, patience=5, device=DEVICE\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Evaluate outer fold\n",
    "    # ------------------------------------------\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in val_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            preds.extend(model(xb).cpu().numpy())\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    metrics = regression_metrics(yva, preds)\n",
    "\n",
    "    print(f\"FOLD {fold+1} METRICS:\", metrics)\n",
    "    outer_results.append(metrics)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# FINAL AGGREGATED RESULTS\n",
    "# -----------------------------------------------------\n",
    "outer_df = pd.DataFrame(outer_results)\n",
    "print(\"\\n==============================\")\n",
    "print(\" FINAL Nested CV Results\")\n",
    "print(\"==============================\")\n",
    "display(outer_df)\n",
    "print(\"Mean:\", outer_df.mean())\n",
    "print(\"Std:\", outer_df.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7783596a-d500-48e2-acb8-f3f0ddb113db",
   "metadata": {},
   "source": [
    "#### Final RUL Model Selection for the Agent (LSTM)\n",
    "\n",
    "In previous experiments, we observed that:\n",
    "\n",
    "Simple train/validation splits produced unrealistically strong results (MAE  56).\n",
    "\n",
    "After running Sequence Nested Cross-Validation (LSTM + GRU), we obtained more reliable and unbiased estimates:\n",
    "\n",
    "| Fold | MAE   | RMSE  | R2   |\n",
    "| ---- | ----- | ----- | ---- |\n",
    "| 0    | ~7.4  | ~11.0 | 0.89 |\n",
    "| 1    | ~16.6 | ~30.0 | 0.64 |\n",
    "| 2    | ~13.4 | ~22.8 | 0.80 |\n",
    "\n",
    "The mean performance of the sequence model family is:\n",
    "\n",
    "MAE  12.5\n",
    "\n",
    "RMSE  21.3\n",
    "\n",
    "R  0.78\n",
    "\n",
    "These values are realistic and consistent with published CMAPSS RUL benchmarks, unlike the overly optimistic single-split results.\n",
    "\n",
    "Final proposed model:\n",
    "\n",
    "Model type: GRU\n",
    "\n",
    "seq_len: 96\n",
    "\n",
    "hidden_size: 110\n",
    "\n",
    "num_layers: 2\n",
    "\n",
    "lr: 0.001363\n",
    "\n",
    "batch_size: 32\n",
    "\n",
    "This model showed:\n",
    "\n",
    "Most stable learning\n",
    "\n",
    "Lowest MAE\n",
    "\n",
    "No divergence\n",
    "\n",
    "Seq_len suitable for CMAPSS\n",
    "\n",
    "Suitable feature dimension space (75 engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d55bc7e-d745-4653-a9c5-0e69e93147c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using final GRU hyperparameters: {'seq_len': 96, 'hidden': 110, 'layers': 2, 'lr': 0.001363, 'batch_size': 32}\n",
      "Using 107 sequence features.\n",
      "Train rows: (18525, 428) Val rows: (2106, 428)\n",
      "Final training windows: (9025, 96, 107) Val windows: (0, 96, 107)\n",
      "Training on: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 12:12:16,970 INFO [SEQ] Epoch 00  val_MAE=nan\n",
      "2025-11-23 12:12:17,792 INFO [SEQ] Epoch 01  val_MAE=nan\n",
      "2025-11-23 12:12:18,656 INFO [SEQ] Epoch 02  val_MAE=nan\n",
      "2025-11-23 12:12:19,658 INFO [SEQ] Epoch 03  val_MAE=nan\n",
      "2025-11-23 12:12:20,638 INFO [SEQ] Epoch 04  val_MAE=nan\n",
      "2025-11-23 12:12:21,627 INFO [SEQ] Epoch 05  val_MAE=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation MAE: inf\n",
      "Saved final GRU model and metadata to: artifacts\\final_model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from agentic_pm.modeling.model_selection import make_windows, SequenceDataset, train_sequence_model\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Load final processed dataset\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"data/processed/CMAPSS/train_FD001_final.csv\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Best hyperparameters (Fold 1 winner)\n",
    "# ----------------------------\n",
    "SEQ_LEN    = 96\n",
    "HIDDEN     = 110\n",
    "LAYERS     = 2\n",
    "LR         = 0.001363\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS     = 40\n",
    "PATIENCE   = 6\n",
    "\n",
    "print(\"Using final GRU hyperparameters:\", {\n",
    "    \"seq_len\": SEQ_LEN,\n",
    "    \"hidden\": HIDDEN,\n",
    "    \"layers\": LAYERS,\n",
    "    \"lr\": LR,\n",
    "    \"batch_size\": BATCH_SIZE\n",
    "})\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Features to use (sequence features)\n",
    "# ----------------------------\n",
    "assert \"sequence_features\" in globals(), \" You must define sequence_features before running this cell\"\n",
    "\n",
    "print(f\"Using {len(sequence_features)} sequence features.\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Create holdout validation (Last 10% for each unit)\n",
    "# ----------------------------\n",
    "def per_unit_holdout_df(df, val_frac=0.10):\n",
    "    train_rows = []\n",
    "    val_rows = []\n",
    "\n",
    "    for u, g in df.groupby(\"unit\"):\n",
    "        cutoff = int(len(g) * (1 - val_frac))\n",
    "        train_rows.append(g.iloc[:cutoff])\n",
    "        val_rows.append(g.iloc[cutoff:])\n",
    "\n",
    "    return pd.concat(train_rows), pd.concat(val_rows)\n",
    "\n",
    "train_df, val_df = per_unit_holdout_df(df, val_frac=0.10)\n",
    "\n",
    "print(\"Train rows:\", train_df.shape, \"Val rows:\", val_df.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Create final windows\n",
    "# ----------------------------\n",
    "Xtr, ytr, _ = make_windows(train_df, sequence_features, seq_len=SEQ_LEN)\n",
    "Xva, yva, _ = make_windows(val_df, sequence_features, seq_len=SEQ_LEN)\n",
    "\n",
    "print(\"Final training windows:\", Xtr.shape, \"Val windows:\", Xva.shape)\n",
    "\n",
    "train_loader = DataLoader(SequenceDataset(Xtr, ytr), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(SequenceDataset(Xva, yva), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Define GRU model\n",
    "# ----------------------------\n",
    "class GRURegressor(nn.Module):\n",
    "    def __init__(self, n_features, hidden_size=64, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=n_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, h_n = self.gru(x)\n",
    "        last = h_n[-1]\n",
    "        return self.fc(last).squeeze(1)\n",
    "\n",
    "# instantiate model\n",
    "model = GRURegressor(\n",
    "    n_features=len(sequence_features),\n",
    "    hidden_size=HIDDEN,\n",
    "    num_layers=LAYERS,\n",
    "    dropout=0.10\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Training on:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Train final model\n",
    "# ----------------------------\n",
    "model, best_val = train_sequence_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    lr=LR,\n",
    "    epochs=EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Final validation MAE:\", best_val)\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Save model + metadata\n",
    "# ----------------------------\n",
    "SAVE_DIR = Path(\"artifacts/final_model\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), SAVE_DIR / \"gru_final_weights.pth\")\n",
    "\n",
    "metadata = {\n",
    "    \"model_type\": \"GRU\",\n",
    "    \"seq_len\": SEQ_LEN,\n",
    "    \"hidden\": HIDDEN,\n",
    "    \"layers\": LAYERS,\n",
    "    \"dropout\": 0.10,\n",
    "    \"lr\": LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"features\": sequence_features\n",
    "}\n",
    "\n",
    "joblib.dump(metadata, SAVE_DIR / \"gru_final_metadata.pkl\")\n",
    "\n",
    "print(\"Saved final GRU model and metadata to:\", SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb413a0a-bcf9-4c22-a329-1147ac85015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final GRU Config: {'seq_len': 96, 'hidden': 110, 'layers': 1, 'lr': 0.0015, 'batch_size': 32}\n",
      "Device: cuda\n",
      "\n",
      "========================================\n",
      "Training FINAL GRU model on FD002\n",
      "========================================\n",
      "Loaded: (53759, 429)\n",
      "FD002 - Using 107 sequence features\n",
      "Train rows: (48268, 429) | Val rows: (5491, 429)\n",
      "Windows: (23568, 96, 107) (0, 96, 107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 12:16:58,915 INFO [SEQ] Epoch 00  val_MAE=nan\n",
      "2025-11-23 12:17:01,063 INFO [SEQ] Epoch 01  val_MAE=nan\n",
      "2025-11-23 12:17:03,209 INFO [SEQ] Epoch 02  val_MAE=nan\n",
      "2025-11-23 12:17:05,359 INFO [SEQ] Epoch 03  val_MAE=nan\n",
      "2025-11-23 12:17:07,673 INFO [SEQ] Epoch 04  val_MAE=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD002 final MAE: inf\n",
      " Saved model for FD002  artifacts\\final_models\\FD002\n",
      "\n",
      "========================================\n",
      "Training FINAL GRU model on FD003\n",
      "========================================\n",
      "Loaded: (24720, 428)\n",
      "FD003 - Using 107 sequence features\n",
      "Train rows: (22198, 428) | Val rows: (2522, 428)\n",
      "Windows: (12698, 96, 107) (0, 96, 107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 12:17:11,296 INFO [SEQ] Epoch 00  val_MAE=nan\n",
      "2025-11-23 12:17:12,428 INFO [SEQ] Epoch 01  val_MAE=nan\n",
      "2025-11-23 12:17:13,516 INFO [SEQ] Epoch 02  val_MAE=nan\n",
      "2025-11-23 12:17:14,593 INFO [SEQ] Epoch 03  val_MAE=nan\n",
      "2025-11-23 12:17:15,689 INFO [SEQ] Epoch 04  val_MAE=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD003 final MAE: inf\n",
      " Saved model for FD003  artifacts\\final_models\\FD003\n",
      "\n",
      "========================================\n",
      "Training FINAL GRU model on FD004\n",
      "========================================\n",
      "Loaded: (61249, 429)\n",
      "FD004 - Using 107 sequence features\n",
      "Train rows: (55013, 429) | Val rows: (6236, 429)\n",
      "Windows: (31358, 96, 107) (0, 96, 107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 12:17:24,849 INFO [SEQ] Epoch 00  val_MAE=nan\n",
      "2025-11-23 12:17:28,039 INFO [SEQ] Epoch 01  val_MAE=nan\n",
      "2025-11-23 12:17:31,097 INFO [SEQ] Epoch 02  val_MAE=nan\n",
      "2025-11-23 12:17:34,311 INFO [SEQ] Epoch 03  val_MAE=nan\n",
      "2025-11-23 12:17:37,209 INFO [SEQ] Epoch 04  val_MAE=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD004 final MAE: inf\n",
      " Saved model for FD004  artifacts\\final_models\\FD004\n",
      "\n",
      " All subsets trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from agentic_pm.modeling.model_selection import make_windows, SequenceDataset, train_sequence_model\n",
    "\n",
    "# ============================================================\n",
    "# 0) FINAL LIGHTWEIGHT GRU CONFIG (shared across all subsets)\n",
    "# ============================================================\n",
    "SEQ_LEN = 96\n",
    "HIDDEN = 110\n",
    "LAYERS = 1\n",
    "LR = 0.0015\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "PATIENCE = 5\n",
    "DROPOUT = 0.10\n",
    "\n",
    "print(\"Final GRU Config:\", {\n",
    "    \"seq_len\": SEQ_LEN,\n",
    "    \"hidden\": HIDDEN,\n",
    "    \"layers\": LAYERS,\n",
    "    \"lr\": LR,\n",
    "    \"batch_size\": BATCH_SIZE\n",
    "})\n",
    "\n",
    "# ============================================================\n",
    "# 1) Function  rebuild sequence features per subset\n",
    "# ============================================================\n",
    "import re\n",
    "\n",
    "keep_patterns = [\n",
    "    r'^sensor_\\d+$',\n",
    "    r'^sensor_\\d+_rm_5$',\n",
    "    r'^sensor_\\d+_rm_15$',\n",
    "    r'^sensor_\\d+_rm_60$',\n",
    "    r'^sensor_\\d+_rstd_5$',\n",
    "    r'^health_index$',\n",
    "    r'^anom_score$'\n",
    "]\n",
    "\n",
    "def match_any(col):\n",
    "    return any(re.match(p, col) for p in keep_patterns)\n",
    "\n",
    "def rebuild_sequence_features(df):\n",
    "    feats = [c for c in df.columns if match_any(c)]\n",
    "    # fallback if too few\n",
    "    if len(feats) < 10:\n",
    "        feats = [c for c in df.columns if \"sensor_\" in c][:30]\n",
    "    return feats\n",
    "\n",
    "# ============================================================\n",
    "# 2) per-unit holdout splitter\n",
    "# ============================================================\n",
    "def per_unit_holdout_df(df, val_frac=0.10):\n",
    "    train_rows, val_rows = [], []\n",
    "    for u, g in df.groupby(\"unit\"):\n",
    "        cutoff = int(len(g) * (1 - val_frac))\n",
    "        train_rows.append(g.iloc[:cutoff])\n",
    "        val_rows.append(g.iloc[cutoff:])\n",
    "    return pd.concat(train_rows), pd.concat(val_rows)\n",
    "\n",
    "# ============================================================\n",
    "# 3) Define GRU model\n",
    "# ============================================================\n",
    "import torch.nn as nn\n",
    "\n",
    "class GRURegressor(nn.Module):\n",
    "    def __init__(self, n_features, hidden_size=64, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=n_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, h_n = self.gru(x)\n",
    "        return self.fc(h_n[-1]).squeeze(1)\n",
    "\n",
    "# ============================================================\n",
    "# 4) MAIN LOOP FOR FD002FD004\n",
    "# ============================================================\n",
    "SUBSETS = [\"FD002\", \"FD003\", \"FD004\"]\n",
    "BASE_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SAVE_ROOT = Path(\"artifacts/final_models\")\n",
    "SAVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    print(\"\\n========================================\")\n",
    "    print(f\"Training FINAL GRU model on {subset}\")\n",
    "    print(\"========================================\")\n",
    "\n",
    "    # ---------------------- Load data ----------------------\n",
    "    train_path = BASE_DIR / f\"train_{subset}_final.csv\"\n",
    "    if not train_path.exists():\n",
    "        print(f\" Missing: {train_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(train_path)\n",
    "    print(\"Loaded:\", df.shape)\n",
    "\n",
    "    # ------------------ Build Sequence Features -------------\n",
    "    sequence_features = rebuild_sequence_features(df)\n",
    "    print(f\"{subset} - Using {len(sequence_features)} sequence features\")\n",
    "\n",
    "    # ------------------ Train/Val split ---------------------\n",
    "    train_df, val_df = per_unit_holdout_df(df, val_frac=0.10)\n",
    "    print(\"Train rows:\", train_df.shape, \"| Val rows:\", val_df.shape)\n",
    "\n",
    "    # ------------------ Create Windows ----------------------\n",
    "    Xtr, ytr, _ = make_windows(train_df, sequence_features, seq_len=SEQ_LEN)\n",
    "    Xva, yva, _ = make_windows(val_df, sequence_features, seq_len=SEQ_LEN)\n",
    "    print(\"Windows:\", Xtr.shape, Xva.shape)\n",
    "\n",
    "    train_loader = DataLoader(SequenceDataset(Xtr, ytr), batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = DataLoader(SequenceDataset(Xva, yva), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # ------------------ Init GRU Model ----------------------\n",
    "    model = GRURegressor(\n",
    "        n_features=len(sequence_features),\n",
    "        hidden_size=HIDDEN,\n",
    "        num_layers=LAYERS,\n",
    "        dropout=DROPOUT\n",
    "    ).to(device)\n",
    "\n",
    "    # ------------------ Train ----------------------\n",
    "    model, best_val = train_sequence_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        lr=LR,\n",
    "        epochs=EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    print(f\"{subset} final MAE:\", best_val)\n",
    "\n",
    "    # ------------------ Save Model ----------------------\n",
    "    SAVE_DIR = SAVE_ROOT / subset\n",
    "    SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    torch.save(model.state_dict(), SAVE_DIR / \"gru_final_weights.pth\")\n",
    "\n",
    "    metadata = {\n",
    "        \"subset\": subset,\n",
    "        \"model_type\": \"GRU\",\n",
    "        \"seq_len\": SEQ_LEN,\n",
    "        \"hidden\": HIDDEN,\n",
    "        \"layers\": LAYERS,\n",
    "        \"dropout\": DROPOUT,\n",
    "        \"lr\": LR,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"features\": sequence_features\n",
    "    }\n",
    "    joblib.dump(metadata, SAVE_DIR / \"gru_final_metadata.pkl\")\n",
    "\n",
    "    print(f\" Saved model for {subset} \", SAVE_DIR)\n",
    "\n",
    "print(\"\\n All subsets trained and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "170e7d99-7b08-4fe3-bb86-1703836cffdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata:\n",
      "{'model_type': 'GRU', 'seq_len': 96, 'hidden': 110, 'layers': 2, 'dropout': 0.1, 'lr': 0.001363, 'batch_size': 32, 'features': ['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15', 'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19', 'sensor_20', 'sensor_21', 'sensor_1_rm_5', 'sensor_1_rstd_5', 'sensor_2_rm_5', 'sensor_2_rstd_5', 'sensor_3_rm_5', 'sensor_3_rstd_5', 'sensor_4_rm_5', 'sensor_4_rstd_5', 'sensor_5_rm_5', 'sensor_5_rstd_5', 'sensor_6_rm_5', 'sensor_6_rstd_5', 'sensor_7_rm_5', 'sensor_7_rstd_5', 'sensor_8_rm_5', 'sensor_8_rstd_5', 'sensor_9_rm_5', 'sensor_9_rstd_5', 'sensor_10_rm_5', 'sensor_10_rstd_5', 'sensor_11_rm_5', 'sensor_11_rstd_5', 'sensor_12_rm_5', 'sensor_12_rstd_5', 'sensor_13_rm_5', 'sensor_13_rstd_5', 'sensor_14_rm_5', 'sensor_14_rstd_5', 'sensor_15_rm_5', 'sensor_15_rstd_5', 'sensor_16_rm_5', 'sensor_16_rstd_5', 'sensor_17_rm_5', 'sensor_17_rstd_5', 'sensor_18_rm_5', 'sensor_18_rstd_5', 'sensor_19_rm_5', 'sensor_19_rstd_5', 'sensor_20_rm_5', 'sensor_20_rstd_5', 'sensor_21_rm_5', 'sensor_21_rstd_5', 'sensor_1_rm_15', 'sensor_2_rm_15', 'sensor_3_rm_15', 'sensor_4_rm_15', 'sensor_5_rm_15', 'sensor_6_rm_15', 'sensor_7_rm_15', 'sensor_8_rm_15', 'sensor_9_rm_15', 'sensor_10_rm_15', 'sensor_11_rm_15', 'sensor_12_rm_15', 'sensor_13_rm_15', 'sensor_14_rm_15', 'sensor_15_rm_15', 'sensor_16_rm_15', 'sensor_17_rm_15', 'sensor_18_rm_15', 'sensor_19_rm_15', 'sensor_20_rm_15', 'sensor_21_rm_15', 'sensor_1_rm_60', 'sensor_2_rm_60', 'sensor_3_rm_60', 'sensor_4_rm_60', 'sensor_5_rm_60', 'sensor_6_rm_60', 'sensor_7_rm_60', 'sensor_8_rm_60', 'sensor_9_rm_60', 'sensor_10_rm_60', 'sensor_11_rm_60', 'sensor_12_rm_60', 'sensor_13_rm_60', 'sensor_14_rm_60', 'sensor_15_rm_60', 'sensor_16_rm_60', 'sensor_17_rm_60', 'sensor_18_rm_60', 'sensor_19_rm_60', 'sensor_20_rm_60', 'sensor_21_rm_60', 'anom_score', 'health_index']}\n",
      "Model loaded on: cuda\n",
      "Test shape: (13096, 428)\n",
      "Selected unit 3 with 126 rows (valid for seq_len=96)\n",
      "Windows shape: (31, 96, 107)\n",
      "Predictions: (31,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from agentic_pm.modeling.model_selection import make_windows, SequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --------------------------------------------\n",
    "# Config\n",
    "# --------------------------------------------\n",
    "SUBSET = \"FD001\"   # FD001 / FD002 / FD003 / FD004\n",
    "\n",
    "DATA_DIR = Path(\"data/processed/CMAPSS\")\n",
    "MODEL_DIR = Path(f\"artifacts/final_models/{SUBSET}\")\n",
    "\n",
    "SEQ_LEN = 96\n",
    "\n",
    "# --------------------------------------------\n",
    "# Load final trained model + metadata\n",
    "# --------------------------------------------\n",
    "import joblib\n",
    "meta = joblib.load(MODEL_DIR / \"gru_final_metadata.pkl\")\n",
    "sequence_features = meta[\"features\"]\n",
    "hidden = meta[\"hidden\"]\n",
    "layers = meta[\"layers\"]\n",
    "dropout = meta[\"dropout\"]\n",
    "\n",
    "print(\"Loaded metadata:\")\n",
    "print(meta)\n",
    "\n",
    "# --------------------------------------------\n",
    "# GRU Recreate\n",
    "# --------------------------------------------\n",
    "import torch.nn as nn\n",
    "\n",
    "class GRURegressor(nn.Module):\n",
    "    def __init__(self, n_features, hidden_size, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=n_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, h = self.gru(x)\n",
    "        return self.fc(h[-1]).squeeze(1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GRURegressor(\n",
    "    n_features=len(sequence_features),\n",
    "    hidden_size=hidden,\n",
    "    num_layers=layers,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_DIR / \"gru_final_weights.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded on:\", device)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Load TEST dataset\n",
    "# --------------------------------------------\n",
    "test_path = DATA_DIR / f\"test_{SUBSET}_final.csv\"\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Auto-pick a test unit with >= seq_len rows\n",
    "# --------------------------------------------\n",
    "valid_units = []\n",
    "\n",
    "for u, g in test_df.groupby(\"unit\"):\n",
    "    if len(g) >= SEQ_LEN:\n",
    "        valid_units.append(u)\n",
    "\n",
    "if len(valid_units) == 0:\n",
    "    raise ValueError(f\"No test units have >= {SEQ_LEN} rows. Cannot build windows.\")\n",
    "\n",
    "unit_to_plot = valid_units[0]  # pick first valid one\n",
    "unit_df = test_df[test_df[\"unit\"] == unit_to_plot].copy()\n",
    "\n",
    "print(f\"Selected unit {unit_to_plot} with {len(unit_df)} rows (valid for seq_len={SEQ_LEN})\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Make windows\n",
    "# --------------------------------------------\n",
    "X_test, y_test, _ = make_windows(unit_df, sequence_features, seq_len=SEQ_LEN)\n",
    "\n",
    "print(\"Windows shape:\", X_test.shape)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    SequenceDataset(X_test, y_test),\n",
    "    batch_size=256,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Predict\n",
    "# --------------------------------------------\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for xb, _ in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds.append(model(xb).cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "\n",
    "print(\"Predictions:\", preds.shape)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Plot\n",
    "# --------------------------------------------\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(y_test, label=\"True RUL\", linewidth=2)\n",
    "plt.plot(preds, label=\"Predicted RUL\", alpha=0.8)\n",
    "plt.title(f\"RUL Curve  {SUBSET}  Unit {unit_to_plot}\")\n",
    "plt.xlabel(\"Window index\")\n",
    "plt.ylabel(\"RUL\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f091c7-be4d-42fc-a9d6-b69f3b6e7b47",
   "metadata": {},
   "source": [
    "#### Final Model Selection Rationale\n",
    "Why the GRU (seq_len=96, hidden=110, layers=2) is the final choice\n",
    "1. Best Balance of Accuracy + Stability\n",
    "\n",
    "- Outperforms LSTM and TCN in nested CV.\n",
    "\n",
    "- More stable than TCN (which showed high variance).\n",
    "\n",
    "- Beats all tree-based models by a wide margin.\n",
    "\n",
    "2. Computational Efficiency\n",
    "\n",
    "- GRU has fewer parameters than LSTM (2 gates vs 3).\n",
    "\n",
    "- Faster inference  suitable for on-device edge scenarios.\n",
    "\n",
    "- Fits easily on CPU/GPU in real-time loops.\n",
    "\n",
    "3. Robust to Sensor Noise & Drift\n",
    "\n",
    "- Longer sequence length (96 cycles) allows smoother estimation of degradation slope.\n",
    "\n",
    "- Hidden size 110 + 2 recurrent layers captures multi-timescale degradation patterns.\n",
    "\n",
    "- Regularization via dropout + nested CV prevents overfitting.\n",
    "\n",
    "4. Excellent Latency / Footprint Tradeoff\n",
    "\n",
    "- < 4M parameters\n",
    "\n",
    "- < 2 ms inference per window on CPU\n",
    "\n",
    "- Scalable to FD002/3/4 without architecture change\n",
    "\n",
    "5. Interpretability Enhancements\n",
    "\n",
    "- Integrated anomaly score + health index help inspect model behavior.\n",
    "\n",
    "- Smooth degradation curves  easy to visualize and reason about.\n",
    "\n",
    "6. Deployment-Ready\n",
    "\n",
    "- Model + metadata saved in unified schema.\n",
    "\n",
    "- Inference wrapper prepared for use with the agent (LLM + diagnostics).\n",
    "\n",
    "- Runs fully on laptop hardware  meets project constraints.\n",
    "\n",
    "#### Final Conclusion\n",
    "\n",
    "The GRU model with seq_len=96, hidden_dim=110, layers=2 provides the best combination of:\n",
    "\n",
    "- strong predictive accuracy\n",
    "\n",
    "- robustness across conditions\n",
    "\n",
    "- computational efficiency\n",
    "\n",
    "- stability under nested CV\n",
    "\n",
    "- suitability for edge deployment\n",
    "\n",
    "- seamless integration with the agentic RUL reasoning pipeline\n",
    "\n",
    "Therefore, it is selected as the final model for FD001FD004 RUL prediction and is used as the inference engine in the local agent system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2af5ca-9a41-4447-8f0f-f93d5f34ec86",
   "metadata": {},
   "source": [
    "## 3.4 Agent Design & Local LLM Integration\n",
    "This section builds a local agent that:\n",
    "- creates a small realistic corpus (synthetic),\n",
    "- embeds documents using `sentence-transformers`,\n",
    "- indexes with FAISS (fallback to scikit-learn NN),\n",
    "- exposes tools: retriever, model-runner, deterministic diagnostic checker, simple what-if simulator,\n",
    "- composes a structured prompt and calls a local LLM (llama-cpp-python preferred).\n",
    "\n",
    "Before running: install required libs if not present:\n",
    "\n",
    "`pip install sentence-transformers faiss-cpu chromadb llama-cpp-python==0.1.50` (adjust versions to your env).\n",
    "\n",
    "1) Build a synthetic maintenance corpus\n",
    "2) Embed + FAISS index\n",
    "3) Load index + retriever\n",
    "4) Load your GRU sequence model (FD001)\n",
    "5) Agent orchestration\n",
    "6) Final agent test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71137250-9d12-4a44-b2f3-8ece8ca308af",
   "metadata": {},
   "source": [
    "### 3.4.1 Create a Synthetic Maintenance Corpus\n",
    "\n",
    "We build a realistic maintenance corpus for the RAG agent.\n",
    "Content includes:\n",
    "\n",
    "- OEM manuals\n",
    "\n",
    "- Failure modes\n",
    "\n",
    "- Maintenance logs\n",
    "\n",
    "- Inspection notes\n",
    "\n",
    "- Troubleshooting bulletins\n",
    "\n",
    "- Best-practice procedures\n",
    "\n",
    "Each document gets:\n",
    "\n",
    "- doc_id\n",
    "\n",
    "- title\n",
    "\n",
    "- source\n",
    "\n",
    "- text (13 paragraphs)\n",
    "\n",
    "We save:\n",
    "\n",
    "- corpus_passages.pkl\n",
    "\n",
    "- corpus_meta.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291dd0c7-25b8-4286-9fd2-66f60ba4dfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 40 corpus documents.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "CORPUS_DIR = Path(\"data/corpus\")\n",
    "CORPUS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "docs = []\n",
    "\n",
    "TITLES = [\n",
    "    \"Compressor Overheat Troubleshooting\",\n",
    "    \"Turbine Blade Fatigue Guidelines\",\n",
    "    \"Bearing Wear Inspection Procedure\",\n",
    "    \"Sensor Fault Isolation Manual\",\n",
    "    \"Vibration Anomaly Diagnostic Bulletin\",\n",
    "    \"Oil System Contamination Report\",\n",
    "    \"Combustion Chamber Temperature Limits\",\n",
    "    \"Preventive Maintenance Checklist\",\n",
    "    \"Startup Failure Case Log\",\n",
    "    \"Pressure System Leak Root Cause Analysis\"\n",
    "]\n",
    "\n",
    "SOURCES = [\"OEM Manual\", \"Field Log\", \"Service Bulletin\", \"Inspection Report\"]\n",
    "\n",
    "PARAGRAPHS = [\n",
    "    \"Excessive compressor temperature is commonly caused by restricted airflow, fouled blades, or abnormal bearing friction. Operators must verify inlet guide vane position and inspect thermal sensors for drift.\",\n",
    "    \"Fatigue cracking on turbine blades typically appears after extended high-load operation or thermal cycling. Non-destructive testing is recommended every 200 cycles.\",\n",
    "    \"Abnormal vibration levels above threshold indicate early-stage bearing degradation. Review lubrication consistency and check for shaft misalignment.\",\n",
    "    \"Sensor drift or intermittent dropout may result from wiring harness fatigue or high-heat exposure. Check continuity and recalibrate if necessary.\",\n",
    "    \"Oil contamination may originate from filter degradation, coolant leakage, or extended service intervals. Analyze particles to determine the contaminant source.\",\n",
    "    \"Pressure loss in pneumatic systems is often linked to seal wear or microfractures in piping. Conduct a dye-penetrant test to confirm root cause.\"\n",
    "]\n",
    "\n",
    "# Build ~40 synthetic documents\n",
    "pid = 0\n",
    "for i in range(40):\n",
    "    title = random.choice(TITLES)\n",
    "    source = random.choice(SOURCES)\n",
    "    text = \" \".join(random.sample(PARAGRAPHs := PARAGRAPHS, k=2))\n",
    "\n",
    "    docs.append({\n",
    "        \"pid\": pid,\n",
    "        \"doc_id\": f\"DOC-{1000+pid}\",\n",
    "        \"title\": title,\n",
    "        \"source\": source,\n",
    "        \"text\": text\n",
    "    })\n",
    "    pid += 1\n",
    "\n",
    "# Save\n",
    "passages = [d[\"text\"] for d in docs]\n",
    "meta = {d[\"pid\"]: d for d in docs}\n",
    "\n",
    "pickle.dump(passages, open(CORPUS_DIR / \"corpus_passages.pkl\", \"wb\"))\n",
    "pickle.dump(meta,      open(CORPUS_DIR / \"corpus_meta.pkl\", \"wb\"))\n",
    "\n",
    "print(f\"Saved {len(passages)} corpus documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640a4db-82a9-4e43-982a-c46f66e00cc3",
   "metadata": {},
   "source": [
    "### 3.4.2 Build Embeddings + FAISS Index\n",
    "\n",
    "We use sentence-transformers to encode all passages and create a FAISS index.\n",
    "We save:\n",
    "\n",
    "- faiss.index\n",
    "\n",
    "- emb_model_name.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf6be5a-329e-476e-a1c2-41a19d014b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built and saved.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "CORPUS_DIR = Path(\"data/corpus\")\n",
    "passages = pickle.load(open(CORPUS_DIR / \"corpus_passages.pkl\", \"rb\"))\n",
    "meta = pickle.load(open(CORPUS_DIR / \"corpus_meta.pkl\", \"rb\"))\n",
    "\n",
    "emb_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = emb_model.encode(passages, convert_to_numpy=True).astype(\"float32\")\n",
    "\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)   # cosine-like similarity after normalization\n",
    "\n",
    "# normalize embeddings\n",
    "emb_norm = embeddings / (np.linalg.norm(embeddings, axis=1, keepdims=True) + 1e-9)\n",
    "index.add(emb_norm)\n",
    "\n",
    "faiss.write_index(index, str(CORPUS_DIR / \"faiss.index\"))\n",
    "open(CORPUS_DIR / \"emb_model_name.txt\", \"w\").write(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"FAISS index built and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d451ac8-0b03-4aab-bcb9-8e532119fcb5",
   "metadata": {},
   "source": [
    "### 3.4.3 Load Embeddings, FAISS & Build Retriever\n",
    "\n",
    "This cell loads all components and defines a reliable retrieve() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3d263b-9fb2-4d3e-b9db-d4b2957852d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded emb_model, meta, passages, and index.\n",
      "Retriever ready.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "CORPUS_DIR = Path(\"data/corpus\")\n",
    "\n",
    "passages = pickle.load(open(CORPUS_DIR / \"corpus_passages.pkl\", \"rb\"))\n",
    "meta      = pickle.load(open(CORPUS_DIR / \"corpus_meta.pkl\", \"rb\"))\n",
    "index     = faiss.read_index(str(CORPUS_DIR / \"faiss.index\"))\n",
    "\n",
    "model_name = open(CORPUS_DIR / \"emb_model_name.txt\").read().strip()\n",
    "emb_model = SentenceTransformer(model_name)\n",
    "\n",
    "print(\"Loaded emb_model, meta, passages, and index.\")\n",
    "\n",
    "def retrieve(query, top_k=5):\n",
    "    qemb = emb_model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    qemb = qemb / (np.linalg.norm(qemb) + 1e-9)\n",
    "\n",
    "    scores, ids = index.search(qemb, top_k)\n",
    "    scores, ids = scores[0], ids[0]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for pid, sc in zip(ids, scores):\n",
    "        pid = int(pid)\n",
    "        key = pid if pid in meta else str(pid)\n",
    "        if key not in meta:\n",
    "            continue\n",
    "        md = meta[key]\n",
    "        results.append({\n",
    "            \"pid\": pid,\n",
    "            \"doc_id\": md[\"doc_id\"],\n",
    "            \"title\": md[\"title\"],\n",
    "            \"source\": md[\"source\"],\n",
    "            \"text\": md[\"text\"],\n",
    "            \"score\": float(sc)\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"Retriever ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9263b280-aaf0-4943-ac0d-3de00adc5439",
   "metadata": {},
   "source": [
    "### 3.4.4 Tool: Load Trained Sequence Model\n",
    "\n",
    "We load:\n",
    "\n",
    "- FD001 GRU model metadata (gru_final_metadata.pkl)\n",
    "\n",
    "- model weights (gru_final_weights.pth)\n",
    "\n",
    "- rebuild GRU architecture\n",
    "\n",
    "- put model in .eval() mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82fbead0-95a8-40c6-93ca-23a654d1abdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GRU model.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "# ---------------------------\n",
    "# GRU architecture\n",
    "# ---------------------------\n",
    "class GRURegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_dim, hidden_dim, num_layers=num_layers,\n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out).squeeze(1)\n",
    "\n",
    "# ---------------------------\n",
    "# Load meta + weights\n",
    "# ---------------------------\n",
    "subset = \"FD001\"\n",
    "ART = Path(f\"artifacts/final_models/{subset}\")\n",
    "meta_path = ART / \"gru_final_metadata.pkl\"\n",
    "weights_path = ART / \"gru_final_weights.pth\"\n",
    "\n",
    "meta = pickle.load(open(meta_path, \"rb\"))\n",
    "input_dim = len(meta[\"features\"])\n",
    "\n",
    "model = GRURegressor(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=meta[\"hidden\"],\n",
    "    num_layers=meta[\"layers\"],\n",
    "    dropout=meta[\"dropout\"]\n",
    ")\n",
    "state = torch.load(weights_path, map_location=\"cpu\")\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "print(\"Loaded GRU model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfeac0f-d3bc-4b1b-802a-b48971e1af7e",
   "metadata": {},
   "source": [
    "### 3.4.5 Tool: Define Model Runner & Diagnostics\n",
    "\n",
    "This includes:\n",
    "\n",
    "- converting recent sensor window into tensor\n",
    "\n",
    "- running GRU\n",
    "\n",
    "- basic rule-based diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c06bd117-656d-49ac-922d-da4f7b8b10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_sequence_model(model, meta, recent_df):\n",
    "    feats = meta[\"features\"]\n",
    "    if len(recent_df) < meta[\"seq_len\"]:\n",
    "        raise ValueError(\"Not enough timesteps for the required sequence length.\")\n",
    "\n",
    "    arr = recent_df[feats].tail(meta[\"seq_len\"]).values.astype(\"float32\")\n",
    "    x = torch.tensor(arr).unsqueeze(0)  # (1, T, F)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x).cpu().numpy()[0]\n",
    "\n",
    "    return {\"pred_rul\": float(pred)}\n",
    "\n",
    "def diagnostic_checker(df):\n",
    "    out = {}\n",
    "    if \"health_index\" in df.columns:\n",
    "        out[\"health_issue\"] = (df[\"health_index\"].iloc[-1] < 0.3)\n",
    "    if \"anom_score\" in df.columns:\n",
    "        out[\"anomaly_spike\"] = (df[\"anom_score\"].tail(10).mean() > 0.2)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae8505-b8db-4ff9-a197-adeeeed0f2fe",
   "metadata": {},
   "source": [
    "### 3.4.6 Tool: Simulator\n",
    "\n",
    "A simple \"what-if\" preventive maintenance scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d28ef29-7806-406e-a5fe-6420e4e602cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator_apply_preventive(df, action=\"replace\"):\n",
    "    if action == \"replace\":\n",
    "        return {\"expected_rul_gain\": 40.0, \"action\": action}\n",
    "    return {\"expected_rul_gain\": 0.0, \"action\": action}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c04f7-7766-491a-9e64-bf42f16d3ddd",
   "metadata": {},
   "source": [
    "### 3.4.7 Prompt Builder + LLM Call\n",
    "\n",
    "We generate a structured prompt and call your local GGUF model via llama-cpp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa679e8-7390-4de5-92ad-b78b32b80d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "def build_prompt(asset_id, summary, retrieved, model_out, diag, sim):\n",
    "    prompt = f\"\"\"\n",
    "You are a maintenance diagnostic agent.\n",
    "\n",
    "ASSET: {asset_id}\n",
    "\n",
    "FACTS:\n",
    "- Last cycle: {summary['last_cycle']}\n",
    "- Health index: {summary.get('health_index_last')}\n",
    "- Recent anomaly mean: {summary.get('anom_mean_last5')}\n",
    "\n",
    "MODEL OUTPUT:\n",
    "- Predicted RUL: {model_out['pred_rul']:.2f}\n",
    "\n",
    "DIAGNOSTICS:\n",
    "{diag}\n",
    "\n",
    "SIMULATION:\n",
    "{sim}\n",
    "\n",
    "RETRIEVED DOCUMENTS:\n",
    "\"\"\"\n",
    "    for r in retrieved:\n",
    "        prompt += f\"\\n[Doc {r['doc_id']}] {r['title']} ({r['source']}): {r['text'][:180]}...\"\n",
    "\n",
    "    prompt += \"\"\"\n",
    "TASK:\n",
    "Provide one-sentence recommendation and 34 bullet points of justification.\n",
    "Reference documents explicitly using [Doc ID].\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# --- GLOBAL SINGLETON ---\n",
    "LLM_SINGLETON = None\n",
    "\n",
    "def load_llm_once(model_path):\n",
    "    global LLM_SINGLETON\n",
    "    if LLM_SINGLETON is None:\n",
    "        print(\"Loading LLM model once...\")\n",
    "        LLM_SINGLETON = Llama(\n",
    "            model_path=model_path,\n",
    "            n_ctx=2048,\n",
    "            n_threads=6,\n",
    "            n_gpu_layers=0,\n",
    "            use_mmap=False,\n",
    "            use_mlock=False\n",
    "        )\n",
    "    return LLM_SINGLETON\n",
    "\n",
    "\n",
    "def call_local_llm(prompt, model_path, temperature=0.1):\n",
    "    llm = load_llm_once(model_path)\n",
    "\n",
    "    out = llm(\n",
    "        prompt,\n",
    "        max_tokens=256,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return out[\"choices\"][0][\"text\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7740625-8c19-43e3-b5c6-378140e05fad",
   "metadata": {},
   "source": [
    "### 3.4.8 Agent Orchestrator\n",
    "\n",
    "Ties everything together:\n",
    "\n",
    "- retrieval\n",
    "\n",
    "- GRU inference\n",
    "\n",
    "- diagnostics\n",
    "\n",
    "- simulation\n",
    "\n",
    "- LLM synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e565bbbe-aad1-418d-9213-897af62effec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_recommend(asset_id, recent_df, model, meta, llm_model_path, query_hint=None):\n",
    "    # summary\n",
    "    summary = {\n",
    "        \"last_cycle\": int(recent_df[\"cycle\"].iloc[-1]),\n",
    "        \"health_index_last\": float(recent_df.get(\"health_index\", pd.Series([0])).iloc[-1]),\n",
    "        \"anom_mean_last5\": float(recent_df.get(\"anom_score\", pd.Series([0])).tail(5).mean())\n",
    "    }\n",
    "\n",
    "    # retrieve\n",
    "    q = query_hint or f\"maintenance issues for asset {asset_id}\"\n",
    "    retrieved = retrieve(q, top_k=4)\n",
    "\n",
    "    # model\n",
    "    model_out = run_sequence_model(model, meta, recent_df)\n",
    "\n",
    "    # diagnostics\n",
    "    diag = diagnostic_checker(recent_df)\n",
    "\n",
    "    # simulation\n",
    "    sim = simulator_apply_preventive(recent_df)\n",
    "\n",
    "    # prompt\n",
    "    prompt = build_prompt(asset_id, summary, retrieved, model_out, diag, sim)\n",
    "\n",
    "    llm_resp = call_local_llm(prompt, llm_model_path)\n",
    "\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"retrieved\": retrieved,\n",
    "        \"model_out\": model_out,\n",
    "        \"diagnostics\": diag,\n",
    "        \"simulation\": sim,\n",
    "        \"prompt\": prompt,\n",
    "        \"llm_response\": llm_resp\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68700695-b40e-4bdd-9109-e0e8a3409654",
   "metadata": {},
   "source": [
    "### 3.4.9 Test the Agent\n",
    "\n",
    "We test on:\n",
    "\n",
    "- FD001\n",
    "\n",
    "- unit = 1\n",
    "\n",
    "- last 120 cycles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e63101-6bdf-4791-8bbb-67917e2e7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loaded: (20631, 428)\n",
      "recent_window_df shape: (116, 428)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>unit</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_13_norm_unit</th>\n",
       "      <th>sensor_14_norm_unit</th>\n",
       "      <th>sensor_15_norm_unit</th>\n",
       "      <th>sensor_16_norm_unit</th>\n",
       "      <th>sensor_17_norm_unit</th>\n",
       "      <th>sensor_18_norm_unit</th>\n",
       "      <th>sensor_19_norm_unit</th>\n",
       "      <th>sensor_20_norm_unit</th>\n",
       "      <th>sensor_21_norm_unit</th>\n",
       "      <th>health_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1.009880</td>\n",
       "      <td>1.356910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.261846</td>\n",
       "      <td>-0.688814</td>\n",
       "      <td>-0.884827</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508715</td>\n",
       "      <td>1.560476</td>\n",
       "      <td>0.705686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.223972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931115</td>\n",
       "      <td>-0.025943</td>\n",
       "      <td>-0.325917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1.832827</td>\n",
       "      <td>0.674444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.381753</td>\n",
       "      <td>-1.592418</td>\n",
       "      <td>-0.537064</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517216</td>\n",
       "      <td>1.386585</td>\n",
       "      <td>-1.683168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265307</td>\n",
       "      <td>0.660771</td>\n",
       "      <td>-1.208373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>1.009880</td>\n",
       "      <td>-0.690488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.121775</td>\n",
       "      <td>-1.315139</td>\n",
       "      <td>-0.555952</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132492</td>\n",
       "      <td>1.579941</td>\n",
       "      <td>-0.584360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386363</td>\n",
       "      <td>0.320213</td>\n",
       "      <td>-0.752288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.087383</td>\n",
       "      <td>-1.372953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.481745</td>\n",
       "      <td>0.234363</td>\n",
       "      <td>-1.705902</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252232</td>\n",
       "      <td>1.483912</td>\n",
       "      <td>-0.250504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325835</td>\n",
       "      <td>0.779267</td>\n",
       "      <td>-0.880752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.818892</td>\n",
       "      <td>-1.372953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098125</td>\n",
       "      <td>-0.930210</td>\n",
       "      <td>-0.765943</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.893440</td>\n",
       "      <td>0.732549</td>\n",
       "      <td>-0.211608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.400501</td>\n",
       "      <td>0.888432</td>\n",
       "      <td>-0.981980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cycle  unit  op_setting_1  op_setting_2  op_setting_3  sensor_1  sensor_2  \\\n",
       "76     77     1      1.009880      1.356910           0.0       0.0 -0.261846   \n",
       "77     78     1      1.832827      0.674444           0.0       0.0 -1.381753   \n",
       "78     79     1      1.009880     -0.690488           0.0       0.0 -1.121775   \n",
       "79     80     1     -0.087383     -1.372953           0.0       0.0 -1.481745   \n",
       "80     81     1     -0.818892     -1.372953           0.0       0.0  0.098125   \n",
       "\n",
       "    sensor_3  sensor_4      sensor_5  ...  sensor_13_norm_unit  \\\n",
       "76 -0.688814 -0.884827 -5.329071e-15  ...            -0.508715   \n",
       "77 -1.592418 -0.537064 -5.329071e-15  ...             0.517216   \n",
       "78 -1.315139 -0.555952 -5.329071e-15  ...             0.132492   \n",
       "79  0.234363 -1.705902 -5.329071e-15  ...            -0.252232   \n",
       "80 -0.930210 -0.765943 -5.329071e-15  ...            -0.893440   \n",
       "\n",
       "    sensor_14_norm_unit  sensor_15_norm_unit  sensor_16_norm_unit  \\\n",
       "76             1.560476             0.705686                  0.0   \n",
       "77             1.386585            -1.683168                  0.0   \n",
       "78             1.579941            -0.584360                  0.0   \n",
       "79             1.483912            -0.250504                  0.0   \n",
       "80             0.732549            -0.211608                  0.0   \n",
       "\n",
       "    sensor_17_norm_unit  sensor_18_norm_unit  sensor_19_norm_unit  \\\n",
       "76            -0.223972                  0.0                  0.0   \n",
       "77            -0.833752                  0.0                  0.0   \n",
       "78             0.385808                  0.0                  0.0   \n",
       "79            -0.833752                  0.0                  0.0   \n",
       "80            -0.833752                  0.0                  0.0   \n",
       "\n",
       "    sensor_20_norm_unit  sensor_21_norm_unit  health_index  \n",
       "76             0.931115            -0.025943     -0.325917  \n",
       "77             0.265307             0.660771     -1.208373  \n",
       "78             0.386363             0.320213     -0.752288  \n",
       "79             0.325835             0.779267     -0.880752  \n",
       "80            -0.400501             0.888432     -0.981980  \n",
       "\n",
       "[5 rows x 428 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load processed FD001 dataset (needed for building recent_window_df)\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    r\"C:\\myProjects\\Agentic-Predictive-Maintenance\\data\\processed\\CMAPSS\\train_FD001_final.csv\"\n",
    ")\n",
    "\n",
    "print(\"Train loaded:\", train_df.shape)\n",
    "\n",
    "# Select asset / build window\n",
    "asset_id = 1\n",
    "window_T = meta[\"seq_len\"] + 20   # ensures enough timesteps\n",
    "\n",
    "recent_window_df = train_df[train_df[\"unit\"] == asset_id].tail(window_T)\n",
    "\n",
    "print(\"recent_window_df shape:\", recent_window_df.shape)\n",
    "display(recent_window_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa29360-de64-4b6d-b2b5-51a8c620a5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from C:\\myProjects\\Agentic-Predictive-Maintenance\\models\\mistral-7b-instruct-v0.2.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLM model once...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   164.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '1000000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n",
      "\n",
      "llama_print_timings:        load time =   55347.26 ms\n",
      "llama_print_timings:      sample time =      33.00 ms /   169 runs   (    0.20 ms per token,  5121.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   55347.15 ms /   191 tokens (  289.78 ms per token,     3.45 tokens per second)\n",
      "llama_print_timings:        eval time =  107821.95 ms /   168 runs   (  641.80 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =  163625.19 ms /   359 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECOMMENDATION:\n",
      "Based on the current health index, predicted RUL, and diagnostic results, it is recommended to replace Asset 1 after the next cycle (approximately 15 cycles from now).\n",
      "\n",
      "JUSTIFICATION:\n",
      "- The asset's health index [Doc ID: Health Index] is below the acceptable threshold of 0.5, indicating a higher risk for failure.\n",
      "- The predicted RUL [Doc ID: Model Output] suggests that the asset will likely fail within the next few cycles.\n",
      "- No anomaly spikes were detected in the recent data [Doc ID: Diagnostics], which further supports the recommendation for replacement.\n",
      "- Replacing the asset proactively will minimize potential downtime and reduce the risk of unexpected failures, ensuring business continuity.\n"
     ]
    }
   ],
   "source": [
    "llm_model_path = r\"C:\\myProjects\\Agentic-Predictive-Maintenance\\models\\mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n",
    "\n",
    "asset_id = 1\n",
    "window_T = meta[\"seq_len\"] + 20\n",
    "recent_window_df = train_df[train_df[\"unit\"] == asset_id].tail(window_T)\n",
    "\n",
    "out = agent_recommend(asset_id, recent_window_df, model, meta, llm_model_path)\n",
    "print(out[\"llm_response\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99148e9-4c74-4247-b25d-b16ccb599a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
