{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902a7186-2e68-403e-9622-84053bfbafc8",
   "metadata": {},
   "source": [
    "# Agentic Predictive Maintenance for Insured Assets\n",
    "---\n",
    "**Objective:** Develop an agentic predictive maintenance solution using time-series sensor data.\n",
    "\n",
    "**Core Components:**\n",
    "* **Data:** Time-series sensor data, policy data, and maintenance logs/manuals.\n",
    "* **Model:** Time-aware model selection (forecasting/classification) and hyperparameter tuning.\n",
    "* **Agent:** An AI agent combining deterministic checks, RAG (retrieval from manuals), and LLM reasoning to provide explainable maintenance recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1ec4a0-3ffc-43b3-b998-f243d9d1b38e",
   "metadata": {},
   "source": [
    "## Batch Processing: Full Pipeline for All Datasets (FD001-FD004)\n",
    "\n",
    "This cell executes the complete **Data Engineering Pipeline** for all four CMAPSS subsets.\n",
    "It orchestrates the modules we created earlier (`data_ingest`, `time_cleaning`, `feature_tools`, `scaling`).\n",
    "\n",
    "**Pipeline Logic per Dataset:**\n",
    "1.  **Ingest:** Loads raw text files, computes RUL, saves intermediate CSVs.\n",
    "2.  **Clean:** Aligns cycles, fills missing values (imputation), and caps outliers.\n",
    "3.  **Feature Engineering:** Generates temporal features (rolling mean/std, lag, trends) and anomaly indicators on the *physical* (unscaled) values.\n",
    "4.  **Scaling:**\n",
    "    * **FD001 & FD003:** Uses `Global Standardization` (single scaler).\n",
    "    * **FD002 & FD004:** Uses `Conditional Standardization` (clusters data by operating conditions first, then scales per cluster) to handle complex regimes.\n",
    "5.  **Save:** exports the final, model-ready data to `data/processed/CMAPSS/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea67e712-d29a-4150-85b0-70a5f5b9acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¢ Starting Batch Processing for All Subsets...\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD001\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD001 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD001\\train_FD001_raw.csv, data\\intermediate\\CMAPSS\\FD001\\test_FD001_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Global Standardization\n",
      "[scaling] Saved global scaler: artifacts\\scalers\\FD001_global_scaler.pkl\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD001 in 796.00 seconds.\n",
      "   Saved shape: Train (20631, 428), Test (13096, 428)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD002\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD002 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD002\\train_FD002_raw.csv, data\\intermediate\\CMAPSS\\FD002\\test_FD002_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Conditional Standardization (Clustering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.02310017 -0.02310017 -0.02310017 ... -0.02310017 -0.02310017\n",
      " -0.02310017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0326773 -0.0326773 -0.0326773 ... -0.0326773 -0.0326773 -0.0326773]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.06121538 -0.06121538 -0.06121538 ... -0.06121538 -0.06121538\n",
      " -0.06121538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03906578 -0.03906578 -0.03906578 ... -0.03906578 -0.03906578\n",
      " -0.03906578]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00872905 -0.00872905 -0.00872905 ... -0.00872905 -0.00872905\n",
      " -0.00872905]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.02310017 -0.02310017 -0.02310017 ... -0.02310017 -0.02310017\n",
      " -0.02310017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0326773 -0.0326773 -0.0326773 ... -0.0326773 -0.0326773 -0.0326773]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.06121538 -0.06121538 -0.06121538 ... -0.06121538 -0.06121538\n",
      " -0.06121538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03906578 -0.03906578 -0.03906578 ... -0.03906578 -0.03906578\n",
      " -0.03906578]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00872905 -0.00872905 -0.00872905 ... -0.00872905 -0.00872905\n",
      " -0.00872905]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scaling] Saved 6 cluster scalers and unit->cluster map for FD002\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD002 in 2404.56 seconds.\n",
      "   Saved shape: Train (53759, 429), Test (33991, 429)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD003\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD003 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD003\\train_FD003_raw.csv, data\\intermediate\\CMAPSS\\FD003\\test_FD003_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Global Standardization\n",
      "[scaling] Saved global scaler: artifacts\\scalers\\FD003_global_scaler.pkl\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD003 in 1117.04 seconds.\n",
      "   Saved shape: Train (24720, 428), Test (16596, 428)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD004\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD004 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD004\\train_FD004_raw.csv, data\\intermediate\\CMAPSS\\FD004\\test_FD004_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Conditional Standardization (Clustering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01730062 -0.01730062 -0.01730062 ... -0.01730062 -0.01730062\n",
      " -0.01730062]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.09715425 -0.09715425 -0.09715425 ... -0.09715425 -0.09715425\n",
      " -0.09715425]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03119965 -0.03119965 -0.03119965 ... -0.03119965 -0.03119965\n",
      " -0.03119965]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0561403 -0.0561403 -0.0561403 ... -0.0561403 -0.0561403 -0.0561403]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03772701 -0.03772701 -0.03772701 ... -0.03772701 -0.03772701\n",
      " -0.03772701]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0967612 -0.0967612 -0.0967612 ... -0.0967612 -0.0967612 -0.0967612]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01730062 -0.01730062 -0.01730062 ... -0.01730062 -0.01730062\n",
      " -0.01730062]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.09715425 -0.09715425 -0.09715425 ... -0.09715425 -0.09715425\n",
      " -0.09715425]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03119965 -0.03119965 -0.03119965 ... -0.03119965 -0.03119965\n",
      " -0.03119965]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0561403 -0.0561403 -0.0561403 ... -0.0561403 -0.0561403 -0.0561403]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03772701 -0.03772701 -0.03772701 ... -0.03772701 -0.03772701\n",
      " -0.03772701]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0967612 -0.0967612 -0.0967612 ... -0.0967612 -0.0967612 -0.0967612]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01140124 -0.01140124 -0.01140124 ... -0.01140124 -0.01140124\n",
      " -0.01140124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01140124 -0.01140124 -0.01140124 ... -0.01140124 -0.01140124\n",
      " -0.01140124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scaling] Saved 6 cluster scalers and unit->cluster map for FD004\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD004 in 2634.24 seconds.\n",
      "   Saved shape: Train (61249, 429), Test (41214, 429)\n",
      "\n",
      "ðŸŽ‰ðŸŽ‰ ALL DATASETS PROCESSED SUCCESSFULLY! ðŸŽ‰ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# --- 1. Suppress Warnings ---\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# 1. Import Your Modules\n",
    "from agentic_pm import data_ingest, time_cleaning, feature_tools, scaling\n",
    "\n",
    "# --- CONFIG ---\n",
    "SUBSETS = [\"FD001\", \"FD002\", \"FD003\", \"FD004\"]\n",
    "\n",
    "RAW_DIR = Path(\"data/raw/CMAPSS\")\n",
    "INTERMEDIATE_DIR = Path(\"data/intermediate/CMAPSS\")\n",
    "PROCESSED_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SCALER_DIR = Path(\"artifacts/scalers\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SCALER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def run_full_pipeline(subset_name):\n",
    "    \"\"\"\n",
    "    Runs the End-to-End Pipeline for a single subset:\n",
    "    Ingest -> Clean -> Feature Eng -> Scale -> Save\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"ðŸš€ Processing Subset: {subset_name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 1: INGEST (Load Raw & Compute RUL)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"1ï¸âƒ£ Ingesting data...\")\n",
    "    data_ingest.process_subset(subset_name, raw_base=RAW_DIR, out_base=INTERMEDIATE_DIR)\n",
    "    \n",
    "    # Load intermediate raw data\n",
    "    train_df = pd.read_csv(INTERMEDIATE_DIR / subset_name / f\"train_{subset_name}_raw.csv\")\n",
    "    test_df  = pd.read_csv(INTERMEDIATE_DIR / subset_name / f\"test_{subset_name}_raw.csv\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 2: CLEANING\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\")\n",
    "    train_df = time_cleaning.align_cycles(train_df)\n",
    "    train_df = time_cleaning.impute_missing(train_df)\n",
    "    train_df = time_cleaning.cap_outliers(train_df)\n",
    "\n",
    "    test_df = time_cleaning.align_cycles(test_df)\n",
    "    test_df = time_cleaning.impute_missing(test_df)\n",
    "    test_df = time_cleaning.cap_outliers(test_df)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 3: FEATURE ENGINEERING (On Physical Values)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"3ï¸âƒ£ Engineering Features...\")\n",
    "    # Train\n",
    "    train_df = feature_tools.create_temporal_features(train_df)\n",
    "    train_df = feature_tools.create_anomaly_indicators(train_df)\n",
    "    train_df = feature_tools.compute_health_index(train_df)\n",
    "    \n",
    "    # Test\n",
    "    test_df = feature_tools.create_temporal_features(test_df)\n",
    "    test_df = feature_tools.create_anomaly_indicators(test_df)\n",
    "    test_df = feature_tools.compute_health_index(test_df)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 4: SCALING (Prepare for ML Model)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"4ï¸âƒ£ Scaling features...\")\n",
    "    \n",
    "    # Identify feature columns (exclude metadata)\n",
    "    # We exclude 'unit', 'cycle', 'RUL', 'gap_flag' and the raw 'op_settings' if we want\n",
    "    # Usually we KEEP op_settings as features, but we scale them.\n",
    "    cols_to_exclude = ['unit', 'cycle', 'RUL', 'gap_flag', 'anom_score'] \n",
    "    # Note: 'anom_score' is 0-1 flag based, usually doesn't need scaling, but can be scaled.\n",
    "    # Let's include everything else.\n",
    "    feature_cols = [c for c in train_df.columns if c not in cols_to_exclude]\n",
    "\n",
    "    # Logic: FD001/FD003 -> Global Scaling\n",
    "    #        FD002/FD004 -> Conditional Scaling (due to multiple operating conditions)\n",
    "    if subset_name in [\"FD001\", \"FD003\"]:\n",
    "        print(f\"   -> Using Global Standardization\")\n",
    "        train_scaled, test_scaled, _ = scaling.global_standardize(\n",
    "            train_df, test_df, feature_cols, subset_name=subset_name\n",
    "        )\n",
    "    else:\n",
    "        print(f\"   -> Using Conditional Standardization (Clustering)\")\n",
    "        op_cols = [\"op_setting_1\", \"op_setting_2\", \"op_setting_3\"]\n",
    "        train_scaled, test_scaled, _, _ = scaling.conditional_standardize(\n",
    "            train_df, test_df, feature_cols, op_cols, subset_name=subset_name\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 5: SAVE FINAL DATA\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"5ï¸âƒ£ Saving final processed data...\")\n",
    "    final_train_path = PROCESSED_DIR / f\"train_{subset_name}_final.csv\"\n",
    "    final_test_path = PROCESSED_DIR / f\"test_{subset_name}_final.csv\"\n",
    "    \n",
    "    train_scaled.to_csv(final_train_path, index=False)\n",
    "    test_scaled.to_csv(final_test_path, index=False)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"âœ… Done with {subset_name} in {elapsed:.2f} seconds.\")\n",
    "    print(f\"   Saved shape: Train {train_scaled.shape}, Test {test_scaled.shape}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION LOOP\n",
    "# ==========================================\n",
    "print(\"ðŸ“¢ Starting Batch Processing for All Subsets...\")\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    try:\n",
    "        run_full_pipeline(subset)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ FAILED on {subset}: {e}\")\n",
    "        # Uncomment 'raise' if you want to stop the whole notebook on error\n",
    "        # raise e \n",
    "\n",
    "print(\"\\nðŸŽ‰ðŸŽ‰ ALL DATASETS PROCESSED SUCCESSFULLY! ðŸŽ‰ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d633a83-bb02-4e11-b372-c328302bde24",
   "metadata": {},
   "source": [
    "### Labeling & Problem Framing\n",
    "\n",
    "#### 1. Task Definition\n",
    "For this project, we explicitly define the prediction task as:\n",
    "\n",
    "- **(B) Remaining Useful Life (RUL) Regression**  \n",
    "  The model predicts the number of cycles remaining before the asset reaches end-of-life (failure threshold).  \n",
    "  Alternative tasks (A: time-to-failure regression, C: binary/multi-class maintenance classification) were considered but not selected for this iteration.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Assumptions\n",
    "- Each *cycle* in the CMAPSS dataset represents a consistent time step (uniform sampling frequency).  \n",
    "- The degradation process is monotonic toward failure within each unitâ€™s operational trajectory.  \n",
    "- Units in the training set run until failure; units in the test set are truncated before failure.  \n",
    "- Sensor measurements are assumed to be correctly calibrated and synchronized.  \n",
    "- No maintenance occurs during each unitâ€™s recorded run unless explicitly annotated.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Sampling Frequency\n",
    "- **Sampling interval:** One record per engine per cycle (i.e., *per-cycle sampling*).  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Label Generation Rules\n",
    "\n",
    "##### **Training Data**\n",
    "- Each unit runs until failure; therefore:\n",
    "  \n",
    "  \\[\n",
    "  RUL_{train}(unit, t) = \\text{max\\_cycle(unit)} - t\n",
    "  \\]\n",
    "\n",
    "##### **Test Data**\n",
    "- Test trajectories end before failure. Ground-truth final RUL values are provided separately.\n",
    "  \n",
    "  \\[\n",
    "  RUL_{test}(unit, t) = RUL_{given}(unit) + (\\text{final\\_cycle(unit)} - t)\n",
    "  \\]\n",
    "\n",
    "##### **Optional Enhancements**\n",
    "- Clip large RUL values (e.g., max 130 cycles) to stabilize model training.  \n",
    "- Apply transformations (e.g., `log1p(RUL)`) when using models sensitive to scale.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Example Asset Timelines (Annotated)\n",
    "\n",
    "Below we illustrate two example trajectories:\n",
    "\n",
    "1. **Training unit (full run):**\n",
    "   - Starts healthy, degrades over time, ends in a failure event.  \n",
    "   - RUL decreases linearly with respect to cycle index until reaching zero at the final cycle.\n",
    "\n",
    "2. **Test unit (truncated run):**\n",
    "   - Sequence ends before failure.  \n",
    "   - Final RUL label is assigned by combining the provided RUL file with the time remaining from the last observed cycle.\n",
    "\n",
    "These annotated timelines help verify label correctness, confirm continuity, and validate assumptions about degradation behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4811fd-658d-4687-9e9c-0cf1f84bd25a",
   "metadata": {},
   "source": [
    "# ðŸ“ Project Status Checkpoint: Data Pipeline & Feature Engineering\n",
    "\n",
    "At this stage, we have successfully implemented the **Data Engineering** and **Tool Definition** layers of our Agentic Predictive Maintenance system. Instead of raw processing within the notebook, we have modularized our code into the `agentic_pm` package for reproducibility and scalability.\n",
    "\n",
    "### Summary of Accomplishments:\n",
    "\n",
    "#### 1. Data Ingestion & Cleaning (Layer 1)\n",
    "We processed the raw CMAPSS datasets (FD001-FD004) through a rigorous cleaning pipeline:\n",
    "* **Ingestion:** Loaded raw text files and computed the **Remaining Useful Life (RUL)** target.\n",
    "* **Alignment:** Used `align_cycles` to create a continuous time index for each asset, handling missing timestamps.\n",
    "* **Imputation:** Filled sensor gaps using linear interpolation (`impute_missing`).\n",
    "* **Noise Reduction:** Applied a rolling Z-score filter (`cap_outliers`) to smooth extreme sensor spikes while retaining the signal.\n",
    "\n",
    "#### 2. Feature Engineering (Layer 2)\n",
    "We generated advanced features on the *cleaned physical values* (before normalization) to capture temporal dynamics:\n",
    "* **Temporal Features:** Rolling Means & Standard Deviations (window sizes 5, 15, 60), Exponential Moving Averages (EMA), and Lag features.\n",
    "* **Anomaly Indicators:** Computed Z-scores and change-point detection flags to highlight abnormal sensor behavior.\n",
    "* **Health Index:** Created a composite score combining weighted sensor values to represent overall asset health.\n",
    "\n",
    "#### 3. Agent Tools (Layer 3)\n",
    "We implemented deterministic tools that our AI Agent will call later:\n",
    "* **`diagnostic_checker`:** A rule-based tool that checks specific physical thresholds (e.g., *Temperature > 800Â°C*) to flag immediate risks.\n",
    "* **`maintenance_simulator`:** A \"what-if\" tool to simulate the impact of preventive maintenance on failure probability.\n",
    "\n",
    "#### 4. Scaling & Normalization (Layer 4)\n",
    "To prepare the data for Machine Learning models, we applied dataset-specific scaling:\n",
    "* **Global Standardization:** Applied to **FD001 & FD003** (single operating condition).\n",
    "* **Conditional Standardization:** Applied to **FD002 & FD004** (multiple operating conditions), using KMeans clustering to normalize data within specific operating regimes.\n",
    "\n",
    "---\n",
    "**âœ… Current State:** Cleaned, feature-engineered, and normalized datasets are saved in `data/processed/CMAPSS/`.\n",
    "**ðŸ‘‰ Next Step:** We will now proceed to **Step 3: Model Selection**, where we will train and evaluate models (XGBoost, etc.) using time-aware validation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111447f4-09ec-4058-b602-b7ca1d494e08",
   "metadata": {},
   "source": [
    "## 3. Model Selection, Hyperparameter Tuning & Evaluation\n",
    "\n",
    "CMAPSS Predictive Maintenance â€” Full Modeling Pipeline\n",
    "\n",
    "Tabular + Sequence Models + Anomaly Detection + Comparison\n",
    "\n",
    "This notebook uses the final processed datasets created by the preprocessing pipeline:\n",
    "   data/processed/CMAPSS/train_FD00X_final.csv\n",
    "   data/processed/CMAPSS/test_FD00X_final.csv\n",
    "\n",
    "It evaluates:\n",
    "- Classical tabular models (RandomForest, ElasticNet, LightGBM)\n",
    "- Sequence models (LSTM, GRU, Mini-TCN)\n",
    "- Anomaly model (IsolationForest) and using its score as a feature\n",
    "- Comparison table summarizing metrics\n",
    "\n",
    "### 3.1 Import & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "12648b07-24ad-4a12-a0b5-c34f5504d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready. Torch: True LightGBM: True Optuna: True\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# modeling utilities we created\n",
    "from agentic_pm.modeling import model_selection as ms\n",
    "\n",
    "# optional libs - we'll check availability\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "except Exception:\n",
    "    optuna = None\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "except Exception:\n",
    "    torch = None\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import joblib\n",
    "\n",
    "print(\"Environment ready. Torch:\", bool(torch), \"LightGBM:\", bool(lgb), \"Optuna:\", bool(optuna))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40bc9c0-667c-4458-b995-47d914200573",
   "metadata": {},
   "source": [
    "### 3.2 Load Final Datasets\n",
    "Choose subset (FD001..FD004) and load the final train/test CSVs produced by your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d3d14d73-e549-4276-9309-b3821c56a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files:\n",
      " - data\\processed\\CMAPSS\\train_FD001_final.csv (20631, 428)\n",
      " - data\\processed\\CMAPSS\\test_FD001_final.csv (13096, 428)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>unit</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_13_norm_unit</th>\n",
       "      <th>sensor_14_norm_unit</th>\n",
       "      <th>sensor_15_norm_unit</th>\n",
       "      <th>sensor_16_norm_unit</th>\n",
       "      <th>sensor_17_norm_unit</th>\n",
       "      <th>sensor_18_norm_unit</th>\n",
       "      <th>sensor_19_norm_unit</th>\n",
       "      <th>sensor_20_norm_unit</th>\n",
       "      <th>sensor_21_norm_unit</th>\n",
       "      <th>health_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.315980</td>\n",
       "      <td>-1.372953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.721725</td>\n",
       "      <td>-0.134255</td>\n",
       "      <td>-0.925936</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278164</td>\n",
       "      <td>1.997798</td>\n",
       "      <td>-0.380157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.354811</td>\n",
       "      <td>1.317629</td>\n",
       "      <td>-0.534520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872722</td>\n",
       "      <td>-1.031720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.061780</td>\n",
       "      <td>0.211528</td>\n",
       "      <td>-0.643726</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636957</td>\n",
       "      <td>1.072544</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991643</td>\n",
       "      <td>1.360548</td>\n",
       "      <td>-0.438211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.961874</td>\n",
       "      <td>1.015677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-0.413166</td>\n",
       "      <td>-0.525953</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.149922</td>\n",
       "      <td>1.298342</td>\n",
       "      <td>-0.435259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.053313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689003</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>-0.618248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324090</td>\n",
       "      <td>-0.008022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-1.261314</td>\n",
       "      <td>-0.784831</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508715</td>\n",
       "      <td>1.376204</td>\n",
       "      <td>-2.042955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265307</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>-0.765705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.864611</td>\n",
       "      <td>-0.690488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621816</td>\n",
       "      <td>-1.251528</td>\n",
       "      <td>-0.301518</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021681</td>\n",
       "      <td>1.372310</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.223972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386363</td>\n",
       "      <td>1.181405</td>\n",
       "      <td>-0.317219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cycle  unit  op_setting_1  op_setting_2  op_setting_3  sensor_1  sensor_2  \\\n",
       "0      1     1     -0.315980     -1.372953           0.0       0.0 -1.721725   \n",
       "1      2     1      0.872722     -1.031720           0.0       0.0 -1.061780   \n",
       "2      3     1     -1.961874      1.015677           0.0       0.0 -0.661813   \n",
       "3      4     1      0.324090     -0.008022           0.0       0.0 -0.661813   \n",
       "4      5     1     -0.864611     -0.690488           0.0       0.0 -0.621816   \n",
       "\n",
       "   sensor_3  sensor_4      sensor_5  ...  sensor_13_norm_unit  \\\n",
       "0 -0.134255 -0.925936 -5.329071e-15  ...            -1.278164   \n",
       "1  0.211528 -0.643726 -5.329071e-15  ...            -0.636957   \n",
       "2 -0.413166 -0.525953 -5.329071e-15  ...            -1.149922   \n",
       "3 -1.261314 -0.784831 -5.329071e-15  ...            -0.508715   \n",
       "4 -1.251528 -0.301518 -5.329071e-15  ...            -1.021681   \n",
       "\n",
       "   sensor_14_norm_unit  sensor_15_norm_unit  sensor_16_norm_unit  \\\n",
       "0             1.997798            -0.380157                  0.0   \n",
       "1             1.072544             0.018526                  0.0   \n",
       "2             1.298342            -0.435259                  0.0   \n",
       "3             1.376204            -2.042955                  0.0   \n",
       "4             1.372310            -0.059266                  0.0   \n",
       "\n",
       "   sensor_17_norm_unit  sensor_18_norm_unit  sensor_19_norm_unit  \\\n",
       "0            -0.833752                  0.0                  0.0   \n",
       "1            -0.833752                  0.0                  0.0   \n",
       "2            -2.053313                  0.0                  0.0   \n",
       "3            -0.833752                  0.0                  0.0   \n",
       "4            -0.223972                  0.0                  0.0   \n",
       "\n",
       "   sensor_20_norm_unit  sensor_21_norm_unit  health_index  \n",
       "0             1.354811             1.317629     -0.534520  \n",
       "1             0.991643             1.360548     -0.438211  \n",
       "2             0.689003             0.619718     -0.618248  \n",
       "3             0.265307             0.896829     -0.765705  \n",
       "4             0.386363             1.181405     -0.317219  \n",
       "\n",
       "[5 rows x 428 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SUBSET = \"FD001\"   # change if you want FD002/FD003/FD004\n",
    "\n",
    "train_path = DATA_DIR / f\"train_{SUBSET}_final.csv\"\n",
    "test_path  = DATA_DIR / f\"test_{SUBSET}_final.csv\"\n",
    "\n",
    "assert train_path.exists(), f\"Train file missing: {train_path}\"\n",
    "assert test_path.exists(),  f\"Test file missing: {test_path}\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Loaded files:\")\n",
    "print(\" -\", train_path, train_df.shape)\n",
    "print(\" -\", test_path, test_df.shape)\n",
    "display(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532787d-1ab6-4966-aad0-8292de4df389",
   "metadata": {},
   "source": [
    "### 3.3 Basic sanity checks\n",
    "Check RUL, missing values, and columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6c783d5d-68cc-4622-b47c-65145f2e5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUL range (train): 0 361\n",
      "Nulls per column (train):\n",
      "sensor_21_lag_6    600\n",
      "sensor_20_lag_6    600\n",
      "sensor_19_lag_6    600\n",
      "sensor_18_lag_6    600\n",
      "sensor_17_lag_6    600\n",
      "sensor_16_lag_6    600\n",
      "sensor_15_lag_6    600\n",
      "sensor_14_lag_6    600\n",
      "sensor_13_lag_6    600\n",
      "sensor_12_lag_6    600\n",
      "dtype: int64\n",
      "Total columns: 428\n",
      "Sample columns: ['cycle', 'unit', 'op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15', 'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19', 'sensor_20', 'sensor_21', 'RUL', 'sensor_1_rm_5', 'sensor_1_rstd_5', 'sensor_1_slope_5']\n"
     ]
    }
   ],
   "source": [
    "# sanity\n",
    "print(\"RUL range (train):\", train_df[\"RUL\"].min(), train_df[\"RUL\"].max())\n",
    "print(\"Nulls per column (train):\")\n",
    "print(train_df.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# list of columns\n",
    "cols = train_df.columns.tolist()\n",
    "print(\"Total columns:\", len(cols))\n",
    "print(\"Sample columns:\", cols[:30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30c882-a0f5-44c3-8dbe-45ed6238ece7",
   "metadata": {},
   "source": [
    "### 3.4 Feature Selection\n",
    "We have too many features. We need feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fddf6210-5ef1-42d9-bdbc-d1196b70cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning feature space...\n",
      "Removing lag columns: 63 columns removed\n",
      "NaN fix complete:\n",
      "cycle           0\n",
      "unit            0\n",
      "op_setting_1    0\n",
      "op_setting_2    0\n",
      "op_setting_3    0\n",
      "dtype: int64\n",
      " Tabular features selected: 125\n",
      "Sequence features selected: 29\n",
      "Examples (tabular): ['anom_score', 'health_index', 'op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_10_slope_15', 'sensor_11_rm_15', 'sensor_11_rm_60', 'sensor_11_slope_15', 'sensor_11_slope_5']\n",
      "Examples (sequence): ['anom_score', 'health_index', 'sensor_11_rm_15', 'sensor_11_rm_60', 'sensor_13', 'sensor_13_rm_5', 'sensor_13_rstd_5', 'sensor_14_rm_15', 'sensor_14_rm_5', 'sensor_15_rm_5']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5) Feature Cleanup & Selection (Tabular + Sequence)\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Cleaning feature space...\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Drop all lag columns (lag features cause NaN at sequence start)\n",
    "# ------------------------------------------------------------\n",
    "lag_cols = [c for c in train_df.columns if \"_lag_\" in c]\n",
    "print(f\"Removing lag columns: {len(lag_cols)} columns removed\")\n",
    "train_df = train_df.drop(columns=lag_cols)\n",
    "test_df  = test_df.drop(columns=lag_cols)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Fix NaN values (per-unit backfill â†’ forward fill)\n",
    "# ------------------------------------------------------------\n",
    "def fix_nans(df):\n",
    "    return (df.groupby(\"unit\")\n",
    "              .apply(lambda g: g.bfill().ffill())\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "train_df = fix_nans(train_df)\n",
    "test_df  = fix_nans(test_df)\n",
    "\n",
    "print(\"NaN fix complete:\")\n",
    "print(train_df.isna().sum().sort_values(ascending=False).head(5))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Construct tabular feature list\n",
    "# ------------------------------------------------------------\n",
    "META_EXCLUDE = {\"unit\", \"cycle\", \"RUL\", \"gap_flag\"}\n",
    "\n",
    "all_features = [c for c in train_df.columns if c not in META_EXCLUDE]\n",
    "\n",
    "# Variance filtering: keep top-k highest variance features\n",
    "k = 120\n",
    "variances = train_df[all_features].var().sort_values(ascending=False)\n",
    "topk = list(variances.index[:k])\n",
    "\n",
    "# Always keep key domain indicators\n",
    "domain_keep = [\n",
    "    \"health_index\",\n",
    "    \"anom_score\",\n",
    "    \"op_setting_1\",\n",
    "    \"op_setting_2\",\n",
    "    \"op_setting_3\"\n",
    "]\n",
    "domain_keep = [c for c in domain_keep if c in train_df.columns]\n",
    "\n",
    "tabular_features = sorted(set(topk + domain_keep))\n",
    "\n",
    "print(f\" Tabular features selected: {len(tabular_features)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Build sequence features (reduced set for LSTM/TCN efficiency)\n",
    "# ------------------------------------------------------------\n",
    "keep_patterns = [\n",
    "    r'^sensor_\\d+$',        # raw sensor values\n",
    "    r'^sensor_\\d+_rm_5$',   # short rolling means\n",
    "    r'^sensor_\\d+_rm_15$',\n",
    "    r'^sensor_\\d+_rm_60$',\n",
    "    r'^sensor_\\d+_rstd_5$', # short rolling std\n",
    "    r'^health_index$',      # degradation signal\n",
    "    r'^anom_score$'         # anomaly indicator\n",
    "]\n",
    "\n",
    "def match_any(col):\n",
    "    return any(re.match(p, col) for p in keep_patterns)\n",
    "\n",
    "sequence_features = [c for c in tabular_features if match_any(c)]\n",
    "\n",
    "# fallback if pattern too restrictive\n",
    "if len(sequence_features) < 12:\n",
    "    sequence_features = tabular_features[:40]\n",
    "\n",
    "print(f\"Sequence features selected: {len(sequence_features)}\")\n",
    "\n",
    "# Show samples\n",
    "print(\"Examples (tabular):\", tabular_features[:10])\n",
    "print(\"Examples (sequence):\", sequence_features[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91582f00-25ad-4ce3-8dd7-1a3a6e04bb27",
   "metadata": {},
   "source": [
    "### 3.5 Train/Validation Split (per-unit holdout)\n",
    "Use per-unit holdout (last portion of cycles per unit) to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3213aca3-57af-41a9-b62a-db7f4af78614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 14398 Val rows: 6233\n"
     ]
    }
   ],
   "source": [
    "# Get row indices for per-unit holdout\n",
    "train_idx, val_idx = ms.per_unit_holdout(train_df, holdout_frac=0.3)\n",
    "print(\"Train rows:\", len(train_idx), \"Val rows:\", len(val_idx))\n",
    "\n",
    "# Prepare arrays for tabular models\n",
    "X = train_df[tabular_features].values\n",
    "y = train_df[\"RUL\"].values\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_val   = X[val_idx]\n",
    "y_train = y[train_idx]\n",
    "y_val   = y[val_idx]\n",
    "\n",
    "# Standardize features for sklearn models (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25499f5-13bf-491e-ad61-c8678c7f305c",
   "metadata": {},
   "source": [
    "### 3.6 Baselines (Persistence & Moving-average linear map)\n",
    "Evaluate leakage-free baselines to anchor model expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "37d17d5b-de55-442f-ab7c-e4c298faa763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence baseline (shifted) metrics: {'MAE': 0.9839563613027434, 'RMSE': 0.9919457451407024, 'R2': 0.9977172069450396}\n",
      "Moving-average baseline metrics: {'MAE': 108.3474749721799, 'RMSE': 110.31866168564305, 'R2': -27.23505734065863}\n"
     ]
    }
   ],
   "source": [
    "# Baseline: persistence (shifted)\n",
    "y_val_persist = ms.baseline_persistence_shift(train_df.iloc[val_idx])  # make sure method accepts dataframe slice\n",
    "# The baseline impl may expect full df aligned; use ms.baseline_persistence_shift on the val slice\n",
    "# We need y_true for validation rows:\n",
    "y_true = y[val_idx]\n",
    "\n",
    "# For moving-average baseline: fit on train_df and predict on validation portion of train_df (or test later)\n",
    "# Here demonstrate using same split: compute on rows corresponding to val_idx (they are rows in train_df)\n",
    "ma_preds = ms.baseline_ma_linear_map(train_df.iloc[train_idx], train_df.iloc[val_idx], sensor_col=\"sensor_1\", window=10)\n",
    "\n",
    "# Evaluate\n",
    "try:\n",
    "    metrics_persist = ms.regression_metrics(y_true, y_val_persist)\n",
    "except Exception:\n",
    "    # fallback compute on simple approach (if shapes mismatch)\n",
    "    metrics_persist = {\"MAE\": float(\"nan\"), \"RMSE\": float(\"nan\"), \"R2\": float(\"nan\")}\n",
    "\n",
    "metrics_ma = ms.regression_metrics(y_true, ma_preds)\n",
    "\n",
    "print(\"Persistence baseline (shifted) metrics:\", metrics_persist)\n",
    "print(\"Moving-average baseline metrics:\", metrics_ma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7d964b-7d29-470e-a98d-adbec1b8b66f",
   "metadata": {},
   "source": [
    "### 3.7 Tabular Model\n",
    "#### 3.7.1 Random Forest\n",
    "Train a RandomForest on the standardized tabular features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d6250ca-0efa-410e-b5d6-a1236c4e23d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF metrics: {'MAE': 27.662710956963686, 'RMSE': 31.64981748161584, 'R2': -1.323983950866963}\n",
      "Precision@100 (rf): 0.02\n",
      "Early-warning@7 (rf): 0.0\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\"n_estimators\":200, \"max_depth\":12, \"min_samples_leaf\":2}\n",
    "rf = ms.fit_random_forest(X_train_s, y_train, params=rf_params)\n",
    "y_val_pred_rf = rf.predict(X_val_s)\n",
    "metrics_rf = ms.regression_metrics(y_val, y_val_pred_rf)\n",
    "print(\"RF metrics:\", metrics_rf)\n",
    "print(\"Precision@100 (rf):\", ms.precision_at_k_rul(y_val, y_val_pred_rf, k=100))\n",
    "print(\"Early-warning@7 (rf):\", ms.early_warning_rate(train_df.iloc[val_idx], y_val, y_val_pred_rf, lead=7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca54c92-bc09-4452-842a-0d580f291ddb",
   "metadata": {},
   "source": [
    "#### 3.7.2 ElasticNet\n",
    "Train a regularized linear model (ElasticNet) for benchmarking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d80abf9-3e7f-4e02-ae2e-38607af6e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet metrics: {'MAE': 75.38697489734093, 'RMSE': 101.54092259576085, 'R2': -22.920646601780117}\n",
      "Precision@100 (en): 0.22\n"
     ]
    }
   ],
   "source": [
    "en_params = {\"alpha\": 0.01, \"l1_ratio\": 0.2}\n",
    "en = ms.fit_elasticnet(X_train_s, y_train, params=en_params)\n",
    "y_val_pred_en = en.predict(X_val_s)\n",
    "metrics_en = ms.regression_metrics(y_val, y_val_pred_en)\n",
    "print(\"ElasticNet metrics:\", metrics_en)\n",
    "print(\"Precision@100 (en):\", ms.precision_at_k_rul(y_val, y_val_pred_en, k=100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50518fe6-df5c-480e-8fdf-9e6829086f37",
   "metadata": {},
   "source": [
    "#### 3.7.3 LightGBM (version-safe)\n",
    "Train LightGBM using ms.fit_lightgbm. If LightGBM not installed, skip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "85ae24fe-8142-4a46-8b9a-b68142fcdf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's l1: 22.7097\n",
      "LightGBM metrics: {'MAE': 22.709666182561556, 'RMSE': 27.10636182058728, 'R2': -0.7046419305422893}\n",
      "Precision@100 (lgb): 0.0\n",
      "Early-warning@7 (lgb): 0.0\n"
     ]
    }
   ],
   "source": [
    "if lgb is None:\n",
    "    print(\"LightGBM not installed â€” skipping LGBM.\")\n",
    "else:\n",
    "    lgb_params = {\"objective\":\"regression\", \"metric\":\"mae\", \"learning_rate\":0.05, \"num_leaves\":48, \"verbosity\":-1}\n",
    "    try:\n",
    "        lgb_model, lgb_info = ms.fit_lightgbm(X_train_s, y_train, X_val_s, y_val, params=lgb_params, rounds=1000, early=50)\n",
    "        y_val_pred_lgb = lgb_model.predict(X_val_s)\n",
    "        metrics_lgb = ms.regression_metrics(y_val, y_val_pred_lgb)\n",
    "        print(\"LightGBM metrics:\", metrics_lgb)\n",
    "        print(\"Precision@100 (lgb):\", ms.precision_at_k_rul(y_val, y_val_pred_lgb, k=100))\n",
    "        print(\"Early-warning@7 (lgb):\", ms.early_warning_rate(train_df.iloc[val_idx], y_val, y_val_pred_lgb, lead=7))\n",
    "    except Exception as e:\n",
    "        print(\"LightGBM training error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354ecdf-92df-4332-a83b-28ca332c1817",
   "metadata": {},
   "source": [
    "### 3.8 Anomaly Model: IsolationForest\n",
    "Fit IsolationForest on training features, compute anomaly score for train/val and optionally add as a feature for model retraining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "793b057a-0150-4201-ab7d-fb8ee87746a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly score (train) stats: 0.3509437643130367 0.6964313243918464 0.4067106093380277\n",
      "Anomaly score (val)   stats: 0.3635086542925437 0.6586642447075471 0.49786727881221426\n",
      "RF enriched (with anomaly) metrics: {'MAE': 27.67307100422802, 'RMSE': 31.669657734252304, 'R2': -1.326898525693852}\n"
     ]
    }
   ],
   "source": [
    "iso = IsolationForest(contamination=0.02, random_state=42)\n",
    "iso.fit(X_train_s)\n",
    "train_anom = iso.score_samples(X_train_s)   # higher = less anomalous; we can invert\n",
    "val_anom   = iso.score_samples(X_val_s)\n",
    "\n",
    "# Invert to get anomaly magnitude (higher means more anomalous)\n",
    "train_anom_score = -train_anom\n",
    "val_anom_score = -val_anom\n",
    "\n",
    "print(\"Anomaly score (train) stats:\", np.nanmin(train_anom_score), np.nanmax(train_anom_score), np.nanmean(train_anom_score))\n",
    "print(\"Anomaly score (val)   stats:\", np.nanmin(val_anom_score), np.nanmax(val_anom_score), np.nanmean(val_anom_score))\n",
    "\n",
    "# Optionally attach to features and retrain RF quickly to see impact\n",
    "X_train_enriched = np.hstack([X_train_s, train_anom_score.reshape(-1,1)])\n",
    "X_val_enriched   = np.hstack([X_val_s, val_anom_score.reshape(-1,1)])\n",
    "\n",
    "rf_enriched = ms.fit_random_forest(X_train_enriched, y_train, params=rf_params)\n",
    "y_val_pred_rf_enriched = rf_enriched.predict(X_val_enriched)\n",
    "metrics_rf_enriched = ms.regression_metrics(y_val, y_val_pred_rf_enriched)\n",
    "print(\"RF enriched (with anomaly) metrics:\", metrics_rf_enriched)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc71801-5fdd-4ecd-90a3-d10f2f01c375",
   "metadata": {},
   "source": [
    "### 3.9 Sequence Model\n",
    "#### 3.9.1 Prepare Sliding Windows for Sequence Models\n",
    "Convert train/val row-splits into sliding windows (single-step RUL prediction).\n",
    "- Uses ms.make_windows() and sequence_features defined earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6df86ce4-cf77-4a4a-a624-d5f4077362fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence windows shapes -> Train: (9498, 50, 29) Val: (1393, 50, 29)\n"
     ]
    }
   ],
   "source": [
    "if torch is None:\n",
    "    print(\"PyTorch not available â€” sequence models will be skipped.\")\n",
    "else:\n",
    "    seq_len = 50   # starting point; tune later\n",
    "    stride = 1\n",
    "\n",
    "    # Prepare windows using rows from train_idx and val_idx (these index into train_df)\n",
    "    train_df_tr = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    train_df_va = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    Xtr_seq, ytr_seq, units_tr = ms.make_windows(train_df_tr, sequence_features, seq_len=seq_len, )\n",
    "    Xva_seq, yva_seq, units_va = ms.make_windows(train_df_va, sequence_features, seq_len=seq_len, )\n",
    "\n",
    "    print(\"Sequence windows shapes -> Train:\", Xtr_seq.shape, \"Val:\", Xva_seq.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb0963-a729-4d1f-bb32-597fd65d02ee",
   "metadata": {},
   "source": [
    "#### 3.9.2 Sequence DataLoaders\n",
    "Build DataLoader wrappers for training sequence models (if torch available).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "112ded19-f119-4497-bee4-830e9c7c7b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for sequence training: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch is not None:\n",
    "    batch_size = 32\n",
    "    train_loader_seq = DataLoader(ms.SequenceDataset(Xtr_seq, ytr_seq), batch_size=batch_size, shuffle=True)\n",
    "    val_loader_seq   = DataLoader(ms.SequenceDataset(Xva_seq, yva_seq), batch_size=batch_size, shuffle=False)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Device for sequence training:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394cb38-91c3-40d2-bcde-fa41307715b2",
   "metadata": {},
   "source": [
    "#### 3.9.3 Sequence Model: LSTM\n",
    "Train LSTM (if torch available). This is a small model to be laptop-friendly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "47ad026c-ee2a-4df7-94cf-d414e546ad45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:48,174 INFO [SEQ] Epoch 00  val_MAE=11.8863\n",
      "2025-11-22 14:40:49,028 INFO [SEQ] Epoch 01  val_MAE=11.1619\n",
      "2025-11-22 14:40:49,883 INFO [SEQ] Epoch 02  val_MAE=10.9788\n",
      "2025-11-22 14:40:50,803 INFO [SEQ] Epoch 03  val_MAE=10.8918\n",
      "2025-11-22 14:40:51,712 INFO [SEQ] Epoch 04  val_MAE=10.8904\n",
      "2025-11-22 14:40:52,568 INFO [SEQ] Epoch 05  val_MAE=11.1440\n",
      "2025-11-22 14:40:53,492 INFO [SEQ] Epoch 06  val_MAE=11.4621\n",
      "2025-11-22 14:40:54,372 INFO [SEQ] Epoch 07  val_MAE=11.8052\n",
      "2025-11-22 14:40:55,300 INFO [SEQ] Epoch 08  val_MAE=12.2482\n",
      "2025-11-22 14:40:56,225 INFO [SEQ] Epoch 09  val_MAE=12.6781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM best val MAE: 10.890438702973453\n"
     ]
    }
   ],
   "source": [
    "lstm_val_mae = None\n",
    "if torch is None:\n",
    "    print(\"PyTorch not installed â€” skipping LSTM.\")\n",
    "else:\n",
    "    model_lstm = ms.LSTMRegressor(n_features=len(sequence_features), hidden_size=64, num_layers=1)\n",
    "    model_lstm, lstm_val_mae = ms.train_sequence_model(model_lstm, train_loader_seq, val_loader_seq, lr=1e-4, epochs=25, patience=5, device=device)\n",
    "    print(\"LSTM best val MAE:\", lstm_val_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359b9a76-b39c-43d8-b355-8235b60d55fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
