{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902a7186-2e68-403e-9622-84053bfbafc8",
   "metadata": {},
   "source": [
    "# Agentic Predictive Maintenance for Insured Assets\n",
    "---\n",
    "**Objective:** Develop an agentic predictive maintenance solution using time-series sensor data.\n",
    "\n",
    "**Core Components:**\n",
    "* **Data:** Time-series sensor data, policy data, and maintenance logs/manuals.\n",
    "* **Model:** Time-aware model selection (forecasting/classification) and hyperparameter tuning.\n",
    "* **Agent:** An AI agent combining deterministic checks, RAG (retrieval from manuals), and LLM reasoning to provide explainable maintenance recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1ec4a0-3ffc-43b3-b998-f243d9d1b38e",
   "metadata": {},
   "source": [
    "## Batch Processing: Full Pipeline for All Datasets (FD001-FD004)\n",
    "\n",
    "This cell executes the complete **Data Engineering Pipeline** for all four CMAPSS subsets.\n",
    "It orchestrates the modules we created earlier (`data_ingest`, `time_cleaning`, `feature_tools`, `scaling`).\n",
    "\n",
    "**Pipeline Logic per Dataset:**\n",
    "1.  **Ingest:** Loads raw text files, computes RUL, saves intermediate CSVs.\n",
    "2.  **Clean:** Aligns cycles, fills missing values (imputation), and caps outliers.\n",
    "3.  **Feature Engineering:** Generates temporal features (rolling mean/std, lag, trends) and anomaly indicators on the *physical* (unscaled) values.\n",
    "4.  **Scaling:**\n",
    "    * **FD001 & FD003:** Uses `Global Standardization` (single scaler).\n",
    "    * **FD002 & FD004:** Uses `Conditional Standardization` (clusters data by operating conditions first, then scales per cluster) to handle complex regimes.\n",
    "5.  **Save:** exports the final, model-ready data to `data/processed/CMAPSS/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea67e712-d29a-4150-85b0-70a5f5b9acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¢ Starting Batch Processing for All Subsets...\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD001\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD001 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD001\\train_FD001_raw.csv, data\\intermediate\\CMAPSS\\FD001\\test_FD001_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Global Standardization\n",
      "[scaling] Saved global scaler: artifacts\\scalers\\FD001_global_scaler.pkl\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD001 in 796.00 seconds.\n",
      "   Saved shape: Train (20631, 428), Test (13096, 428)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD002\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD002 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD002\\train_FD002_raw.csv, data\\intermediate\\CMAPSS\\FD002\\test_FD002_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Conditional Standardization (Clustering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.02310017 -0.02310017 -0.02310017 ... -0.02310017 -0.02310017\n",
      " -0.02310017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0326773 -0.0326773 -0.0326773 ... -0.0326773 -0.0326773 -0.0326773]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.06121538 -0.06121538 -0.06121538 ... -0.06121538 -0.06121538\n",
      " -0.06121538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03906578 -0.03906578 -0.03906578 ... -0.03906578 -0.03906578\n",
      " -0.03906578]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00872905 -0.00872905 -0.00872905 ... -0.00872905 -0.00872905\n",
      " -0.00872905]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.02310017 -0.02310017 -0.02310017 ... -0.02310017 -0.02310017\n",
      " -0.02310017]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0326773 -0.0326773 -0.0326773 ... -0.0326773 -0.0326773 -0.0326773]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.06121538 -0.06121538 -0.06121538 ... -0.06121538 -0.06121538\n",
      " -0.06121538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03906578 -0.03906578 -0.03906578 ... -0.03906578 -0.03906578\n",
      " -0.03906578]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00872905 -0.00872905 -0.00872905 ... -0.00872905 -0.00872905\n",
      " -0.00872905]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04280095 -0.04280095 -0.04280095 ... -0.04280095 -0.04280095\n",
      " -0.04280095]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04540246 -0.04540246 -0.04540246 ... -0.04540246 -0.04540246\n",
      " -0.04540246]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.10079344 -0.10079344 -0.10079344 ... -0.10079344 -0.10079344\n",
      " -0.10079344]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00729015 -0.00729015 -0.00729015 ... -0.00729015 -0.00729015\n",
      " -0.00729015]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01598824 -0.01598824 -0.01598824 ... -0.01598824 -0.01598824\n",
      " -0.01598824]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01001554 -0.01001554 -0.01001554 ... -0.01001554 -0.01001554\n",
      " -0.01001554]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scaling] Saved 6 cluster scalers and unit->cluster map for FD002\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD002 in 2404.56 seconds.\n",
      "   Saved shape: Train (53759, 429), Test (33991, 429)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD003\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD003 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD003\\train_FD003_raw.csv, data\\intermediate\\CMAPSS\\FD003\\test_FD003_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Global Standardization\n",
      "[scaling] Saved global scaler: artifacts\\scalers\\FD003_global_scaler.pkl\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD003 in 1117.04 seconds.\n",
      "   Saved shape: Train (24720, 428), Test (16596, 428)\n",
      "\n",
      "========================================\n",
      "ðŸš€ Processing Subset: FD004\n",
      "========================================\n",
      "1ï¸âƒ£ Ingesting data...\n",
      "[data_ingest] Processing FD004 ...\n",
      "[data_ingest] Saved: data\\intermediate\\CMAPSS\\FD004\\train_FD004_raw.csv, data\\intermediate\\CMAPSS\\FD004\\test_FD004_raw.csv\n",
      "2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\n",
      "3ï¸âƒ£ Engineering Features...\n",
      "4ï¸âƒ£ Scaling features...\n",
      "   -> Using Conditional Standardization (Clustering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01730062 -0.01730062 -0.01730062 ... -0.01730062 -0.01730062\n",
      " -0.01730062]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.09715425 -0.09715425 -0.09715425 ... -0.09715425 -0.09715425\n",
      " -0.09715425]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03119965 -0.03119965 -0.03119965 ... -0.03119965 -0.03119965\n",
      " -0.03119965]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0561403 -0.0561403 -0.0561403 ... -0.0561403 -0.0561403 -0.0561403]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03772701 -0.03772701 -0.03772701 ... -0.03772701 -0.03772701\n",
      " -0.03772701]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0967612 -0.0967612 -0.0967612 ... -0.0967612 -0.0967612 -0.0967612]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01223247 -0.01223247 -0.01223247 ... -0.01223247 -0.01223247\n",
      " -0.01223247]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01730062 -0.01730062 -0.01730062 ... -0.01730062 -0.01730062\n",
      " -0.01730062]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.09715425 -0.09715425 -0.09715425 ... -0.09715425 -0.09715425\n",
      " -0.09715425]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03119965 -0.03119965 -0.03119965 ... -0.03119965 -0.03119965\n",
      " -0.03119965]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0561403 -0.0561403 -0.0561403 ... -0.0561403 -0.0561403 -0.0561403]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.03772701 -0.03772701 -0.03772701 ... -0.03772701 -0.03772701\n",
      " -0.03772701]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04240945 -0.04240945 -0.04240945 ... -0.04240945 -0.04240945\n",
      " -0.04240945]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.04414446 -0.04414446 -0.04414446 ... -0.04414446 -0.04414446\n",
      " -0.04414446]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.0967612 -0.0967612 -0.0967612 ... -0.0967612 -0.0967612 -0.0967612]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00864934 -0.00864934 -0.00864934 ... -0.00864934 -0.00864934\n",
      " -0.00864934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01140124 -0.01140124 -0.01140124 ... -0.01140124 -0.01140124\n",
      " -0.01140124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.01140124 -0.01140124 -0.01140124 ... -0.01140124 -0.01140124\n",
      " -0.01140124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_t.loc[mask_tr, feature_cols] = scaler.transform(train_t.loc[mask_tr, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n",
      "C:\\myProjects\\Agentic-Predictive-Maintenance\\agentic_pm\\scaling.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[-0.00892893 -0.00892893 -0.00892893 ... -0.00892893 -0.00892893\n",
      " -0.00892893]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_t.loc[mask_te, feature_cols] = scaler.transform(test_t.loc[mask_te, feature_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scaling] Saved 6 cluster scalers and unit->cluster map for FD004\n",
      "5ï¸âƒ£ Saving final processed data...\n",
      "âœ… Done with FD004 in 2634.24 seconds.\n",
      "   Saved shape: Train (61249, 429), Test (41214, 429)\n",
      "\n",
      "ðŸŽ‰ðŸŽ‰ ALL DATASETS PROCESSED SUCCESSFULLY! ðŸŽ‰ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# --- 1. Suppress Warnings ---\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# 1. Import Your Modules\n",
    "from agentic_pm import data_ingest, time_cleaning, feature_tools, scaling\n",
    "\n",
    "# --- CONFIG ---\n",
    "SUBSETS = [\"FD001\", \"FD002\", \"FD003\", \"FD004\"]\n",
    "\n",
    "RAW_DIR = Path(\"data/raw/CMAPSS\")\n",
    "INTERMEDIATE_DIR = Path(\"data/intermediate/CMAPSS\")\n",
    "PROCESSED_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SCALER_DIR = Path(\"artifacts/scalers\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SCALER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def run_full_pipeline(subset_name):\n",
    "    \"\"\"\n",
    "    Runs the End-to-End Pipeline for a single subset:\n",
    "    Ingest -> Clean -> Feature Eng -> Scale -> Save\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"ðŸš€ Processing Subset: {subset_name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 1: INGEST (Load Raw & Compute RUL)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"1ï¸âƒ£ Ingesting data...\")\n",
    "    data_ingest.process_subset(subset_name, raw_base=RAW_DIR, out_base=INTERMEDIATE_DIR)\n",
    "    \n",
    "    # Load intermediate raw data\n",
    "    train_df = pd.read_csv(INTERMEDIATE_DIR / subset_name / f\"train_{subset_name}_raw.csv\")\n",
    "    test_df  = pd.read_csv(INTERMEDIATE_DIR / subset_name / f\"test_{subset_name}_raw.csv\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 2: CLEANING\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"2ï¸âƒ£ Cleaning data (Align, Impute, Cap Outliers)...\")\n",
    "    train_df = time_cleaning.align_cycles(train_df)\n",
    "    train_df = time_cleaning.impute_missing(train_df)\n",
    "    train_df = time_cleaning.cap_outliers(train_df)\n",
    "\n",
    "    test_df = time_cleaning.align_cycles(test_df)\n",
    "    test_df = time_cleaning.impute_missing(test_df)\n",
    "    test_df = time_cleaning.cap_outliers(test_df)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 3: FEATURE ENGINEERING (On Physical Values)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"3ï¸âƒ£ Engineering Features...\")\n",
    "    # Train\n",
    "    train_df = feature_tools.create_temporal_features(train_df)\n",
    "    train_df = feature_tools.create_anomaly_indicators(train_df)\n",
    "    train_df = feature_tools.compute_health_index(train_df)\n",
    "    \n",
    "    # Test\n",
    "    test_df = feature_tools.create_temporal_features(test_df)\n",
    "    test_df = feature_tools.create_anomaly_indicators(test_df)\n",
    "    test_df = feature_tools.compute_health_index(test_df)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 4: SCALING (Prepare for ML Model)\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"4ï¸âƒ£ Scaling features...\")\n",
    "    \n",
    "    # Identify feature columns (exclude metadata)\n",
    "    # We exclude 'unit', 'cycle', 'RUL', 'gap_flag' and the raw 'op_settings' if we want\n",
    "    # Usually we KEEP op_settings as features, but we scale them.\n",
    "    cols_to_exclude = ['unit', 'cycle', 'RUL', 'gap_flag', 'anom_score'] \n",
    "    # Note: 'anom_score' is 0-1 flag based, usually doesn't need scaling, but can be scaled.\n",
    "    # Let's include everything else.\n",
    "    feature_cols = [c for c in train_df.columns if c not in cols_to_exclude]\n",
    "\n",
    "    # Logic: FD001/FD003 -> Global Scaling\n",
    "    #        FD002/FD004 -> Conditional Scaling (due to multiple operating conditions)\n",
    "    if subset_name in [\"FD001\", \"FD003\"]:\n",
    "        print(f\"   -> Using Global Standardization\")\n",
    "        train_scaled, test_scaled, _ = scaling.global_standardize(\n",
    "            train_df, test_df, feature_cols, subset_name=subset_name\n",
    "        )\n",
    "    else:\n",
    "        print(f\"   -> Using Conditional Standardization (Clustering)\")\n",
    "        op_cols = [\"op_setting_1\", \"op_setting_2\", \"op_setting_3\"]\n",
    "        train_scaled, test_scaled, _, _ = scaling.conditional_standardize(\n",
    "            train_df, test_df, feature_cols, op_cols, subset_name=subset_name\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # STEP 5: SAVE FINAL DATA\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"5ï¸âƒ£ Saving final processed data...\")\n",
    "    final_train_path = PROCESSED_DIR / f\"train_{subset_name}_final.csv\"\n",
    "    final_test_path = PROCESSED_DIR / f\"test_{subset_name}_final.csv\"\n",
    "    \n",
    "    train_scaled.to_csv(final_train_path, index=False)\n",
    "    test_scaled.to_csv(final_test_path, index=False)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"âœ… Done with {subset_name} in {elapsed:.2f} seconds.\")\n",
    "    print(f\"   Saved shape: Train {train_scaled.shape}, Test {test_scaled.shape}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION LOOP\n",
    "# ==========================================\n",
    "print(\"ðŸ“¢ Starting Batch Processing for All Subsets...\")\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    try:\n",
    "        run_full_pipeline(subset)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ FAILED on {subset}: {e}\")\n",
    "        # Uncomment 'raise' if you want to stop the whole notebook on error\n",
    "        # raise e \n",
    "\n",
    "print(\"\\nðŸŽ‰ðŸŽ‰ ALL DATASETS PROCESSED SUCCESSFULLY! ðŸŽ‰ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d633a83-bb02-4e11-b372-c328302bde24",
   "metadata": {},
   "source": [
    "### Labeling & Problem Framing\n",
    "\n",
    "#### 1. Task Definition\n",
    "For this project, we explicitly define the prediction task as:\n",
    "\n",
    "- **(B) Remaining Useful Life (RUL) Regression**  \n",
    "  The model predicts the number of cycles remaining before the asset reaches end-of-life (failure threshold).  \n",
    "  Alternative tasks (A: time-to-failure regression, C: binary/multi-class maintenance classification) were considered but not selected for this iteration.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Assumptions\n",
    "- Each *cycle* in the CMAPSS dataset represents a consistent time step (uniform sampling frequency).  \n",
    "- The degradation process is monotonic toward failure within each unitâ€™s operational trajectory.  \n",
    "- Units in the training set run until failure; units in the test set are truncated before failure.  \n",
    "- Sensor measurements are assumed to be correctly calibrated and synchronized.  \n",
    "- No maintenance occurs during each unitâ€™s recorded run unless explicitly annotated.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Sampling Frequency\n",
    "- **Sampling interval:** One record per engine per cycle (i.e., *per-cycle sampling*).  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Label Generation Rules\n",
    "\n",
    "##### **Training Data**\n",
    "- Each unit runs until failure; therefore:\n",
    "  \n",
    "  \\[\n",
    "  RUL_{train}(unit, t) = \\text{max\\_cycle(unit)} - t\n",
    "  \\]\n",
    "\n",
    "##### **Test Data**\n",
    "- Test trajectories end before failure. Ground-truth final RUL values are provided separately.\n",
    "  \n",
    "  \\[\n",
    "  RUL_{test}(unit, t) = RUL_{given}(unit) + (\\text{final\\_cycle(unit)} - t)\n",
    "  \\]\n",
    "\n",
    "##### **Optional Enhancements**\n",
    "- Clip large RUL values (e.g., max 130 cycles) to stabilize model training.  \n",
    "- Apply transformations (e.g., `log1p(RUL)`) when using models sensitive to scale.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Example Asset Timelines (Annotated)\n",
    "\n",
    "Below we illustrate two example trajectories:\n",
    "\n",
    "1. **Training unit (full run):**\n",
    "   - Starts healthy, degrades over time, ends in a failure event.  \n",
    "   - RUL decreases linearly with respect to cycle index until reaching zero at the final cycle.\n",
    "\n",
    "2. **Test unit (truncated run):**\n",
    "   - Sequence ends before failure.  \n",
    "   - Final RUL label is assigned by combining the provided RUL file with the time remaining from the last observed cycle.\n",
    "\n",
    "These annotated timelines help verify label correctness, confirm continuity, and validate assumptions about degradation behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4811fd-658d-4687-9e9c-0cf1f84bd25a",
   "metadata": {},
   "source": [
    "# ðŸ“ Project Status Checkpoint: Data Pipeline & Feature Engineering\n",
    "\n",
    "At this stage, we have successfully implemented the **Data Engineering** and **Tool Definition** layers of our Agentic Predictive Maintenance system. Instead of raw processing within the notebook, we have modularized our code into the `agentic_pm` package for reproducibility and scalability.\n",
    "\n",
    "### Summary of Accomplishments:\n",
    "\n",
    "#### 1. Data Ingestion & Cleaning (Layer 1)\n",
    "We processed the raw CMAPSS datasets (FD001-FD004) through a rigorous cleaning pipeline:\n",
    "* **Ingestion:** Loaded raw text files and computed the **Remaining Useful Life (RUL)** target.\n",
    "* **Alignment:** Used `align_cycles` to create a continuous time index for each asset, handling missing timestamps.\n",
    "* **Imputation:** Filled sensor gaps using linear interpolation (`impute_missing`).\n",
    "* **Noise Reduction:** Applied a rolling Z-score filter (`cap_outliers`) to smooth extreme sensor spikes while retaining the signal.\n",
    "\n",
    "#### 2. Feature Engineering (Layer 2)\n",
    "We generated advanced features on the *cleaned physical values* (before normalization) to capture temporal dynamics:\n",
    "* **Temporal Features:** Rolling Means & Standard Deviations (window sizes 5, 15, 60), Exponential Moving Averages (EMA), and Lag features.\n",
    "* **Anomaly Indicators:** Computed Z-scores and change-point detection flags to highlight abnormal sensor behavior.\n",
    "* **Health Index:** Created a composite score combining weighted sensor values to represent overall asset health.\n",
    "\n",
    "#### 3. Agent Tools (Layer 3)\n",
    "We implemented deterministic tools that our AI Agent will call later:\n",
    "* **`diagnostic_checker`:** A rule-based tool that checks specific physical thresholds (e.g., *Temperature > 800Â°C*) to flag immediate risks.\n",
    "* **`maintenance_simulator`:** A \"what-if\" tool to simulate the impact of preventive maintenance on failure probability.\n",
    "\n",
    "#### 4. Scaling & Normalization (Layer 4)\n",
    "To prepare the data for Machine Learning models, we applied dataset-specific scaling:\n",
    "* **Global Standardization:** Applied to **FD001 & FD003** (single operating condition).\n",
    "* **Conditional Standardization:** Applied to **FD002 & FD004** (multiple operating conditions), using KMeans clustering to normalize data within specific operating regimes.\n",
    "\n",
    "---\n",
    "**âœ… Current State:** Cleaned, feature-engineered, and normalized datasets are saved in `data/processed/CMAPSS/`.\n",
    "**ðŸ‘‰ Next Step:** We will now proceed to **Step 3: Model Selection**, where we will train and evaluate models (XGBoost, etc.) using time-aware validation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111447f4-09ec-4058-b602-b7ca1d494e08",
   "metadata": {},
   "source": [
    "## 3. Model Selection, Hyperparameter Tuning & Evaluation\n",
    "### 3.1 Import & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12648b07-24ad-4a12-a0b5-c34f5504d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path: True data\\processed\\CMAPSS\\train_FD001_final.csv\n",
      "test_path: True data\\processed\\CMAPSS\\test_FD001_final.csv\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "from agentic_pm.modeling import model_selection as ms\n",
    "\n",
    "DATA_DIR = Path(\"data/processed/CMAPSS\")\n",
    "SUBSET = \"FD001\"\n",
    "train_path = DATA_DIR / f\"train_{SUBSET}_final.csv\"\n",
    "test_path  = DATA_DIR / f\"test_{SUBSET}_final.csv\"\n",
    "\n",
    "print(\"train_path:\", train_path.exists(), train_path)\n",
    "print(\"test_path:\", test_path.exists(), test_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40bc9c0-667c-4458-b995-47d914200573",
   "metadata": {},
   "source": [
    "### 3.2 Load processed data, quick sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3d14d73-e549-4276-9309-b3821c56a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: train (20631, 428) test (13096, 428)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>unit</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_13_norm_unit</th>\n",
       "      <th>sensor_14_norm_unit</th>\n",
       "      <th>sensor_15_norm_unit</th>\n",
       "      <th>sensor_16_norm_unit</th>\n",
       "      <th>sensor_17_norm_unit</th>\n",
       "      <th>sensor_18_norm_unit</th>\n",
       "      <th>sensor_19_norm_unit</th>\n",
       "      <th>sensor_20_norm_unit</th>\n",
       "      <th>sensor_21_norm_unit</th>\n",
       "      <th>health_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.315980</td>\n",
       "      <td>-1.372953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.721725</td>\n",
       "      <td>-0.134255</td>\n",
       "      <td>-0.925936</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278164</td>\n",
       "      <td>1.997798</td>\n",
       "      <td>-0.380157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.354811</td>\n",
       "      <td>1.317629</td>\n",
       "      <td>-0.534520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872722</td>\n",
       "      <td>-1.031720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.061780</td>\n",
       "      <td>0.211528</td>\n",
       "      <td>-0.643726</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636957</td>\n",
       "      <td>1.072544</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991643</td>\n",
       "      <td>1.360548</td>\n",
       "      <td>-0.438211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.961874</td>\n",
       "      <td>1.015677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-0.413166</td>\n",
       "      <td>-0.525953</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.149922</td>\n",
       "      <td>1.298342</td>\n",
       "      <td>-0.435259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.053313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689003</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>-0.618248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324090</td>\n",
       "      <td>-0.008022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-1.261314</td>\n",
       "      <td>-0.784831</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508715</td>\n",
       "      <td>1.376204</td>\n",
       "      <td>-2.042955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265307</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>-0.765705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.864611</td>\n",
       "      <td>-0.690488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621816</td>\n",
       "      <td>-1.251528</td>\n",
       "      <td>-0.301518</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021681</td>\n",
       "      <td>1.372310</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.223972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386363</td>\n",
       "      <td>1.181405</td>\n",
       "      <td>-0.317219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cycle  unit  op_setting_1  op_setting_2  op_setting_3  sensor_1  sensor_2  \\\n",
       "0      1     1     -0.315980     -1.372953           0.0       0.0 -1.721725   \n",
       "1      2     1      0.872722     -1.031720           0.0       0.0 -1.061780   \n",
       "2      3     1     -1.961874      1.015677           0.0       0.0 -0.661813   \n",
       "3      4     1      0.324090     -0.008022           0.0       0.0 -0.661813   \n",
       "4      5     1     -0.864611     -0.690488           0.0       0.0 -0.621816   \n",
       "\n",
       "   sensor_3  sensor_4      sensor_5  ...  sensor_13_norm_unit  \\\n",
       "0 -0.134255 -0.925936 -5.329071e-15  ...            -1.278164   \n",
       "1  0.211528 -0.643726 -5.329071e-15  ...            -0.636957   \n",
       "2 -0.413166 -0.525953 -5.329071e-15  ...            -1.149922   \n",
       "3 -1.261314 -0.784831 -5.329071e-15  ...            -0.508715   \n",
       "4 -1.251528 -0.301518 -5.329071e-15  ...            -1.021681   \n",
       "\n",
       "   sensor_14_norm_unit  sensor_15_norm_unit  sensor_16_norm_unit  \\\n",
       "0             1.997798            -0.380157                  0.0   \n",
       "1             1.072544             0.018526                  0.0   \n",
       "2             1.298342            -0.435259                  0.0   \n",
       "3             1.376204            -2.042955                  0.0   \n",
       "4             1.372310            -0.059266                  0.0   \n",
       "\n",
       "   sensor_17_norm_unit  sensor_18_norm_unit  sensor_19_norm_unit  \\\n",
       "0            -0.833752                  0.0                  0.0   \n",
       "1            -0.833752                  0.0                  0.0   \n",
       "2            -2.053313                  0.0                  0.0   \n",
       "3            -0.833752                  0.0                  0.0   \n",
       "4            -0.223972                  0.0                  0.0   \n",
       "\n",
       "   sensor_20_norm_unit  sensor_21_norm_unit  health_index  \n",
       "0             1.354811             1.317629     -0.534520  \n",
       "1             0.991643             1.360548     -0.438211  \n",
       "2             0.689003             0.619718     -0.618248  \n",
       "3             0.265307             0.896829     -0.765705  \n",
       "4             0.386363             1.181405     -0.317219  \n",
       "\n",
       "[5 rows x 428 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUL min/max train: 0 361\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Shapes: train\", train_df.shape, \"test\", test_df.shape)\n",
    "display(train_df.head())\n",
    "\n",
    "# Quick check that RUL is present and non-negative\n",
    "print(\"RUL min/max train:\", train_df['RUL'].min(), train_df['RUL'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532787d-1ab6-4966-aad0-8292de4df389",
   "metadata": {},
   "source": [
    "### 3.3 Visual Check â€” RUL Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c783d5d-68cc-4622-b47c-65145f2e5a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "train_df[\"RUL\"].hist(bins=50)\n",
    "plt.title(\"RUL Distribution â€” Train\")\n",
    "plt.xlabel(\"RUL\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30c882-a0f5-44c3-8dbe-45ed6238ece7",
   "metadata": {},
   "source": [
    "### 3.4 Fix and run correct baselines (no leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fddf6210-5ef1-42d9-bdbc-d1196b70cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence baseline (shifted) metrics: {'MAE': 0.9923640806353085, 'RMSE': 0.9961747239492219, 'R2': 0.9997147057731792}\n",
      "Moving-average baseline metrics: {'MAE': 54.127533447851036, 'RMSE': 67.79375906542671, 'R2': -0.3212998275171681}\n"
     ]
    }
   ],
   "source": [
    "# Persistence baseline (shifted)\n",
    "y_test = test_df['RUL'].values\n",
    "y_pred_persist = ms.baseline_persistence_shift(test_df)   # corrected baseline\n",
    "metrics_persist = ms.regression_metrics(y_test, y_pred_persist)\n",
    "print(\"Persistence baseline (shifted) metrics:\", metrics_persist)\n",
    "\n",
    "# Moving average baseline: fit on train, predict on test (no leakage)\n",
    "y_pred_ma = ms.baseline_ma_linear_map(train_df, test_df, sensor_col='sensor_1', window=10)\n",
    "metrics_ma = ms.regression_metrics(y_test, y_pred_ma)\n",
    "print(\"Moving-average baseline metrics:\", metrics_ma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91582f00-25ad-4ce3-8dd7-1a3a6e04bb27",
   "metadata": {},
   "source": [
    "### 3.5 Feature selection (reduce dimensions to avoid overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3213aca3-57af-41a9-b62a-db7f4af78614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature cols available: 425\n",
      "Selected feature count: 85\n"
     ]
    }
   ],
   "source": [
    "# Select candidate features (drop metadata)\n",
    "exclude = {'unit','cycle','RUL','gap_flag'}\n",
    "all_feat = [c for c in train_df.columns if c not in exclude]\n",
    "print(\"Total feature cols available:\", len(all_feat))\n",
    "\n",
    "# Simple variance-based filter: keep top-k highest-variance features + keep domain sensors and health_index\n",
    "k = 80\n",
    "var = train_df[all_feat].var().sort_values(ascending=False)\n",
    "topk = list(var.index[:k])\n",
    "# Ensure some domain features present\n",
    "domain = [c for c in ['health_index','anom_score','op_setting_1','op_setting_2','op_setting_3'] if c in train_df.columns]\n",
    "feature_cols = sorted(set(topk + domain))\n",
    "print(\"Selected feature count:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25499f5-13bf-491e-ad61-c8678c7f305c",
   "metadata": {},
   "source": [
    "### 3.6 Build X/y and time-aware per-unit holdout split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37d17d5b-de55-442f-ab7c-e4c298faa763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 18:07:07,575 INFO Per-unit holdout: train rows=14398 val rows=6233 (holdout_frac=0.30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: 14398 val rows: 6233\n"
     ]
    }
   ],
   "source": [
    "X = train_df[feature_cols].values\n",
    "y = train_df['RUL'].values\n",
    "\n",
    "# Per-unit holdout: last 30% cycles per unit for validation (no leakage)\n",
    "train_idx, val_idx = ms.per_unit_holdout(train_df, holdout_frac=0.3)\n",
    "print(\"train rows:\", len(train_idx), \"val rows:\", len(val_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7d964b-7d29-470e-a98d-adbec1b8b66f",
   "metadata": {},
   "source": [
    "### 3.7 Scale features (fit on train only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d6250ca-0efa-410e-b5d6-a1236c4e23d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = X[train_idx]\n",
    "X_val = X[val_idx]\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca54c92-bc09-4452-842a-0d580f291ddb",
   "metadata": {},
   "source": [
    "### 3.8 Train RandomForest (baseline strong) and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d80abf9-3e7f-4e02-ae2e-38607af6e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF metrics: {'MAE': 26.9856491098807, 'RMSE': 30.965902531665254, 'R2': -1.2246320499591055}\n",
      "Precision@100 (rf): 0.04\n",
      "Early-warning@7 (rf): 0.0\n"
     ]
    }
   ],
   "source": [
    "rf = ms.fit_random_forest(X_train_s, y[train_idx], params={\"n_estimators\":200, \"max_depth\":12, \"min_samples_leaf\":2})\n",
    "y_val_pred_rf = rf.predict(X_val_s)\n",
    "metrics_rf = ms.regression_metrics(y[val_idx], y_val_pred_rf)\n",
    "print(\"RF metrics:\", metrics_rf)\n",
    "print(\"Precision@100 (rf):\", ms.precision_at_k_rul(y[val_idx], y_val_pred_rf, k=100))\n",
    "print(\"Early-warning@7 (rf):\", ms.early_warning_rate(train_df.iloc[val_idx], y[val_idx], y_val_pred_rf, lead=7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50518fe6-df5c-480e-8fdf-9e6829086f37",
   "metadata": {},
   "source": [
    "### 3.8 Train LightGBM (simple params) and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85ae24fe-8142-4a46-8b9a-b68142fcdf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[710]\tval's l1: 18.0903\n",
      "LightGBM metrics: {'MAE': 18.090268980715283, 'RMSE': 21.495357423431514, 'R2': -0.07196362008842083}\n",
      "Precision@100 (lgb): 0.07\n",
      "Early-warning@7 (lgb): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Use lightgbm if installed; else skip\n",
    "try:\n",
    "    lgb_model, _ = ms.fit_lightgbm(X_train_s, y[train_idx], X_val_s, y[val_idx],\n",
    "                                   params={\"objective\":\"regression\",\"metric\":\"mae\",\"learning_rate\":0.05,\"num_leaves\":48,\"verbosity\":-1},\n",
    "                                   num_boost_round=1000, early_stopping_rounds=50)\n",
    "    y_val_pred_lgb = lgb_model.predict(X_val_s)\n",
    "    metrics_lgb = ms.regression_metrics(y[val_idx], y_val_pred_lgb)\n",
    "    print(\"LightGBM metrics:\", metrics_lgb)\n",
    "    print(\"Precision@100 (lgb):\", ms.precision_at_k_rul(y[val_idx], y_val_pred_lgb, k=100))\n",
    "    print(\"Early-warning@7 (lgb):\", ms.early_warning_rate(train_df.iloc[val_idx], y[val_idx], y_val_pred_lgb, lead=7))\n",
    "except Exception as e:\n",
    "    print(\"LightGBM not available or failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354ecdf-92df-4332-a83b-28ca332c1817",
   "metadata": {},
   "source": [
    "### 3.9 Plot sample unit true vs predicted (LightGBM if available, else RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "793b057a-0150-4201-ab7d-fb8ee87746a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unit_sample = train_df.iloc[val_idx]['unit'].unique()[0]\n",
    "unit_rows = train_df[(train_df.unit == unit_sample) & (train_df.index.isin(val_idx))]\n",
    "Xu = scaler.transform(unit_rows[feature_cols].values)\n",
    "y_pred_unit = (lgb_model.predict(Xu) if 'lgb_model' in globals() else rf.predict(Xu))\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(unit_rows.cycle.values, unit_rows.RUL.values, label='true RUL')\n",
    "plt.plot(unit_rows.cycle.values, y_pred_unit, label='pred RUL')\n",
    "plt.title(f\"Unit {unit_sample} true vs pred RUL\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc71801-5fdd-4ecd-90a3-d10f2f01c375",
   "metadata": {},
   "source": [
    "### 3.10 Optuna Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6df86ce4-cf77-4a4a-a624-d5f4077362fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:22:38,825] A new study created in memory with name: no-name-0de2c130-fda4-4916-aff3-b8df0c984408\n",
      "2025-11-18 18:22:38,852 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[482]\tval's l1: 53.7217\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 61.0683\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:23:06,431] Trial 0 finished with value: 62.560889265040714 and parameters: {'num_leaves': 78, 'learning_rate': 0.0011079837677329255, 'feature_fraction': 0.8455862555351941, 'bagging_fraction': 0.9738440308993981, 'bagging_freq': 10, 'min_data_in_leaf': 48}. Best is trial 0 with value: 62.560889265040714.\n",
      "2025-11-18 18:23:06,454 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 72.8926\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tval's l1: 53.7196\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tval's l1: 34.5276\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:23:13,425] Trial 1 finished with value: 36.09023473393942 and parameters: {'num_leaves': 180, 'learning_rate': 0.11110274005409185, 'feature_fraction': 0.5780439298664577, 'bagging_fraction': 0.5750918807951539, 'bagging_freq': 8, 'min_data_in_leaf': 27}. Best is trial 1 with value: 36.09023473393942.\n",
      "2025-11-18 18:23:13,443 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[110]\tval's l1: 20.0235\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tval's l1: 52.9516\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tval's l1: 32.0872\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:23:16,804] Trial 2 finished with value: 33.81476188122508 and parameters: {'num_leaves': 56, 'learning_rate': 0.1992042790730921, 'feature_fraction': 0.9695093219481383, 'bagging_fraction': 0.9469196162141515, 'bagging_freq': 5, 'min_data_in_leaf': 50}. Best is trial 2 with value: 33.81476188122508.\n",
      "2025-11-18 18:23:16,825 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[87]\tval's l1: 16.4055\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tval's l1: 53.9701\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 34.9208\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:23:38,295] Trial 3 finished with value: 37.6201506708147 and parameters: {'num_leaves': 75, 'learning_rate': 0.009794843240353502, 'feature_fraction': 0.9045997932368575, 'bagging_fraction': 0.5580221371277473, 'bagging_freq': 4, 'min_data_in_leaf': 9}. Best is trial 2 with value: 33.81476188122508.\n",
      "2025-11-18 18:23:38,312 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 23.9696\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tval's l1: 54.2951\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 49.5594\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 49.3606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:24:17,072] Trial 4 finished with value: 51.07168965726461 and parameters: {'num_leaves': 218, 'learning_rate': 0.0021642205893236495, 'feature_fraction': 0.8443570838498611, 'bagging_fraction': 0.8219199664047961, 'bagging_freq': 2, 'min_data_in_leaf': 39}. Best is trial 2 with value: 33.81476188122508.\n",
      "2025-11-18 18:24:17,093 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tval's l1: 54.4437\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 46.4403\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 39.4246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:24:35,583] Trial 5 finished with value: 46.769530407026956 and parameters: {'num_leaves': 203, 'learning_rate': 0.0030703170011800243, 'feature_fraction': 0.6539086719980628, 'bagging_fraction': 0.5247517023332406, 'bagging_freq': 4, 'min_data_in_leaf': 48}. Best is trial 2 with value: 33.81476188122508.\n",
      "2025-11-18 18:24:35,600 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tval's l1: 54.0102\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 32.4361\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:24:57,378] Trial 6 finished with value: 34.8218772168905 and parameters: {'num_leaves': 89, 'learning_rate': 0.018622600335611857, 'feature_fraction': 0.8044817010931757, 'bagging_fraction': 0.7618247811092234, 'bagging_freq': 6, 'min_data_in_leaf': 37}. Best is trial 2 with value: 33.81476188122508.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 18.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 18:24:57,394 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tval's l1: 54.3043\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 45.963\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:25:25,266] Trial 7 finished with value: 47.572840880318815 and parameters: {'num_leaves': 99, 'learning_rate': 0.003347192093069399, 'feature_fraction': 0.8112296702001135, 'bagging_fraction': 0.9675479070709467, 'bagging_freq': 6, 'min_data_in_leaf': 30}. Best is trial 2 with value: 33.81476188122508.\n",
      "2025-11-18 18:25:25,282 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 42.4513\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tval's l1: 54.5639\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 51.1149\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:25:40,576] Trial 8 finished with value: 51.668286563090284 and parameters: {'num_leaves': 45, 'learning_rate': 0.0028550269723205185, 'feature_fraction': 0.8337984537117626, 'bagging_fraction': 0.6114034366674224, 'bagging_freq': 5, 'min_data_in_leaf': 14}. Best is trial 2 with value: 33.81476188122508.\n",
      "2025-11-18 18:25:40,593 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 49.3261\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tval's l1: 54.1514\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 35.662\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tval's l1: 22.5526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:26:32,551] Trial 9 finished with value: 37.455345186554766 and parameters: {'num_leaves': 231, 'learning_rate': 0.0110561826098508, 'feature_fraction': 0.6017542089559749, 'bagging_fraction': 0.9962523762791348, 'bagging_freq': 9, 'min_data_in_leaf': 9}. Best is trial 2 with value: 33.81476188122508.\n",
      "2025-11-18 18:26:32,584 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval's l1: 55.696\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tval's l1: 32.4843\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:26:40,655] Trial 10 finished with value: 34.770598365132805 and parameters: {'num_leaves': 149, 'learning_rate': 0.18285547572208544, 'feature_fraction': 0.9895546772181608, 'bagging_fraction': 0.8719291048401567, 'bagging_freq': 2, 'min_data_in_leaf': 20}. Best is trial 2 with value: 33.81476188122508.\n",
      "2025-11-18 18:26:40,678 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[96]\tval's l1: 16.1316\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tval's l1: 54.6927\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tval's l1: 31.0294\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:26:51,076] Trial 11 finished with value: 34.24291130190726 and parameters: {'num_leaves': 152, 'learning_rate': 0.17576709119808578, 'feature_fraction': 0.9828609100407718, 'bagging_fraction': 0.8657815012103152, 'bagging_freq': 1, 'min_data_in_leaf': 20}. Best is trial 2 with value: 33.81476188122508.\n",
      "2025-11-18 18:26:51,106 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tval's l1: 17.0066\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tval's l1: 54.497\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[315]\tval's l1: 33.7914\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:26:54,122] Trial 12 finished with value: 37.48682400940614 and parameters: {'num_leaves': 16, 'learning_rate': 0.0602749280233631, 'feature_fraction': 0.996276834127271, 'bagging_fraction': 0.8918279634655535, 'bagging_freq': 1, 'min_data_in_leaf': 21}. Best is trial 2 with value: 33.81476188122508.\n",
      "2025-11-18 18:26:54,148 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[183]\tval's l1: 24.172\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tval's l1: 53.2213\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[287]\tval's l1: 32.3074\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:27:12,015] Trial 13 finished with value: 33.407319940563525 and parameters: {'num_leaves': 132, 'learning_rate': 0.05477624395700139, 'feature_fraction': 0.9270293104638263, 'bagging_fraction': 0.7271888856262507, 'bagging_freq': 3, 'min_data_in_leaf': 38}. Best is trial 13 with value: 33.407319940563525.\n",
      "2025-11-18 18:27:12,037 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[309]\tval's l1: 14.6933\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tval's l1: 53.6323\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tval's l1: 32.9281\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:27:25,436] Trial 14 finished with value: 34.7315035878281 and parameters: {'num_leaves': 119, 'learning_rate': 0.04380917999057216, 'feature_fraction': 0.7028396419714934, 'bagging_fraction': 0.6722926126849897, 'bagging_freq': 3, 'min_data_in_leaf': 41}. Best is trial 13 with value: 33.407319940563525.\n",
      "2025-11-18 18:27:25,458 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[321]\tval's l1: 17.634\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tval's l1: 53.075\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[411]\tval's l1: 31.5891\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:27:30,148] Trial 15 finished with value: 35.68347873983353 and parameters: {'num_leaves': 17, 'learning_rate': 0.043898700359963745, 'feature_fraction': 0.9080188632100976, 'bagging_fraction': 0.6953537898988642, 'bagging_freq': 7, 'min_data_in_leaf': 43}. Best is trial 13 with value: 33.407319940563525.\n",
      "2025-11-18 18:27:30,168 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[475]\tval's l1: 22.3863\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tval's l1: 53.1801\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tval's l1: 32.2634\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:27:36,749] Trial 16 finished with value: 34.01068088739527 and parameters: {'num_leaves': 49, 'learning_rate': 0.08361134053361836, 'feature_fraction': 0.9131649577117884, 'bagging_fraction': 0.7595719653495129, 'bagging_freq': 4, 'min_data_in_leaf': 50}. Best is trial 13 with value: 33.407319940563525.\n",
      "2025-11-18 18:27:36,771 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tval's l1: 16.5885\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tval's l1: 53.9247\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[395]\tval's l1: 32.3885\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:27:57,897] Trial 17 finished with value: 34.67534383639602 and parameters: {'num_leaves': 181, 'learning_rate': 0.024913427251890358, 'feature_fraction': 0.7580102097400192, 'bagging_fraction': 0.6813856554668798, 'bagging_freq': 5, 'min_data_in_leaf': 33}. Best is trial 13 with value: 33.407319940563525.\n",
      "2025-11-18 18:27:57,919 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[308]\tval's l1: 17.7128\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tval's l1: 53.6643\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tval's l1: 31.6042\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:28:05,701] Trial 18 finished with value: 33.27282463620797 and parameters: {'num_leaves': 130, 'learning_rate': 0.11570297979919109, 'feature_fraction': 0.9204149258302629, 'bagging_fraction': 0.8063252163150805, 'bagging_freq': 3, 'min_data_in_leaf': 44}. Best is trial 18 with value: 33.27282463620797.\n",
      "2025-11-18 18:28:05,724 INFO Created 3 time-aware folds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[159]\tval's l1: 14.5499\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tval's l1: 53.1845\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[259]\tval's l1: 33.458\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[354]\tval's l1: 18.3616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:28:30,058] Trial 19 finished with value: 35.00136476128602 and parameters: {'num_leaves': 256, 'learning_rate': 0.03537745382444147, 'feature_fraction': 0.753439226224158, 'bagging_fraction': 0.8080734937068554, 'bagging_freq': 3, 'min_data_in_leaf': 35}. Best is trial 18 with value: 33.27282463620797.\n",
      "2025-11-18 18:28:30,059 INFO Optuna tuning completed. Best value: 33.27282463620797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Optuna params: {'num_leaves': 130, 'learning_rate': 0.11570297979919109, 'feature_fraction': 0.9204149258302629, 'bagging_fraction': 0.8063252163150805, 'bagging_freq': 3, 'min_data_in_leaf': 44}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Run only if Optuna installed and you want tuning time\n",
    "try:\n",
    "    study = ms.tune_lightgbm_optuna(np.vstack([X_train_s, X_val_s]), np.concatenate([y[train_idx], y[val_idx]]), train_df.iloc[np.concatenate([train_idx, val_idx])], n_trials=20)\n",
    "    print(\"Best Optuna params:\", study.best_params)\n",
    "except Exception as e:\n",
    "    print(\"Optuna tuning skipped:\", e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b638dfa-167c-4917-bc7c-9781bc782367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Persistence</td>\n",
       "      <td>0.992364</td>\n",
       "      <td>0.996175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MovingAvg</td>\n",
       "      <td>54.127533</td>\n",
       "      <td>67.793759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>26.985649</td>\n",
       "      <td>30.965903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>18.090269</td>\n",
       "      <td>21.495357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model        MAE       RMSE\n",
       "0  Persistence   0.992364   0.996175\n",
       "1    MovingAvg  54.127533  67.793759\n",
       "2           RF  26.985649  30.965903\n",
       "3     LightGBM  18.090269  21.495357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "rows.append({\"Model\":\"Persistence\",\"MAE\":metrics_persist[\"MAE\"], \"RMSE\":metrics_persist[\"RMSE\"]})\n",
    "rows.append({\"Model\":\"MovingAvg\",\"MAE\":metrics_ma[\"MAE\"], \"RMSE\":metrics_ma[\"RMSE\"]})\n",
    "rows.append({\"Model\":\"RF\",\"MAE\":metrics_rf[\"MAE\"], \"RMSE\":metrics_rf[\"RMSE\"]})\n",
    "if 'metrics_lgb' in globals():\n",
    "    rows.append({\"Model\":\"LightGBM\",\"MAE\":metrics_lgb[\"MAE\"], \"RMSE\":metrics_lgb[\"RMSE\"]})\n",
    "comp = pd.DataFrame(rows)\n",
    "display(comp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d425b-6665-4d0d-b449-3a16537c3b1f",
   "metadata": {},
   "source": [
    "## ðŸ“‰ Model Selection & Initial Evaluation Results\n",
    "\n",
    "We performed an initial model selection using a simple 70/30 time-based split (relative cycle < 0.7 for training) to compare model families and establish a robust baseline.\n",
    "\n",
    "### 1. Performance Benchmarking (MAE/RMSE)\n",
    "\n",
    "The goal was to significantly outperform the simple Moving Average (MA) baseline.\n",
    "\n",
    "| Model | MAE (Mean Abs. Error) | RMSE (Root Mean Sq. Error) | Observations |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **MovingAvg Baseline** | 54.128 | 67.794 | The true \"dumb\" model for comparison. |\n",
    "| **Random Forest (RF)** | 26.986 | 30.966 | Significant improvement over MA Baseline. |\n",
    "| **LightGBM** | **18.090** | **21.495** | The clear winner; optimized via Optuna to reduce MAE. |\n",
    "| *Persistence Baseline* | 0.992 | 0.996 | *Artifact: This is only a pipeline check and not a true performance baseline.* |\n",
    "\n",
    "### 2. Critical Failures (RÂ² and Business Metrics)\n",
    "\n",
    "Despite the promising MAE reduction, the models reveal significant flaws when assessed with business and generalization metrics.\n",
    "\n",
    "* **Negative Generalization (RÂ²):** The RÂ² score for both RF (`-1.22`) and LightGBM (`-0.07`) is **negative**. A negative RÂ² indicates that the models perform worse than simply predicting the mean RUL for the validation set.\n",
    "* **Zero Business Value (Early Warning):** The most critical finding is the **Early-warning@7 score of 0.0**. This means that *neither* model successfully provided a warning **7 cycles in advance** for any failing unit. The predictions only become accurate in the immediate vicinity of failure.\n",
    "* **Low Precision:** The Precision@100 (0.07 for LightGBM) is low, indicating that when the model is asked to flag the 100 most critical time-steps, many of its predictions are false alarms.\n",
    "\n",
    "### 3. Conclusion & Next Step\n",
    "\n",
    "The current single-split validation strategy and the simple models are **not sufficient**. The negative RÂ² score and the zero Early Warning rate indicate the model is either **severely overfitting** or the simple time-split is inadequate for capturing complex time dynamics across all units.\n",
    "\n",
    "**Decision:** We cannot trust the reported MAE/RMSE of 18.09. We must now proceed to **Nested Validation** to get an honest, reliable generalization estimate, and select a model that provides a positive Lead Time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394cb38-91c3-40d2-bcde-fa41307715b2",
   "metadata": {},
   "source": [
    "### Nested Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "47ad026c-ee2a-4df7-94cf-d414e546ad45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agentic_pm.modeling.nested_cv' from 'C:\\\\myProjects\\\\Agentic-Predictive-Maintenance\\\\agentic_pm\\\\modeling\\\\nested_cv.py'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from agentic_pm.modeling import nested_cv\n",
    "\n",
    "importlib.reload(nested_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e26d45a9-c2f4-4f36-9ac5-dc3483cfe9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 428)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>unit</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_13_norm_unit</th>\n",
       "      <th>sensor_14_norm_unit</th>\n",
       "      <th>sensor_15_norm_unit</th>\n",
       "      <th>sensor_16_norm_unit</th>\n",
       "      <th>sensor_17_norm_unit</th>\n",
       "      <th>sensor_18_norm_unit</th>\n",
       "      <th>sensor_19_norm_unit</th>\n",
       "      <th>sensor_20_norm_unit</th>\n",
       "      <th>sensor_21_norm_unit</th>\n",
       "      <th>health_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.315980</td>\n",
       "      <td>-1.372953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.721725</td>\n",
       "      <td>-0.134255</td>\n",
       "      <td>-0.925936</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278164</td>\n",
       "      <td>1.997798</td>\n",
       "      <td>-0.380157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.354811</td>\n",
       "      <td>1.317629</td>\n",
       "      <td>-0.534520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872722</td>\n",
       "      <td>-1.031720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.061780</td>\n",
       "      <td>0.211528</td>\n",
       "      <td>-0.643726</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636957</td>\n",
       "      <td>1.072544</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991643</td>\n",
       "      <td>1.360548</td>\n",
       "      <td>-0.438211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.961874</td>\n",
       "      <td>1.015677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-0.413166</td>\n",
       "      <td>-0.525953</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.149922</td>\n",
       "      <td>1.298342</td>\n",
       "      <td>-0.435259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.053313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689003</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>-0.618248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324090</td>\n",
       "      <td>-0.008022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.661813</td>\n",
       "      <td>-1.261314</td>\n",
       "      <td>-0.784831</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508715</td>\n",
       "      <td>1.376204</td>\n",
       "      <td>-2.042955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265307</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>-0.765705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.864611</td>\n",
       "      <td>-0.690488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621816</td>\n",
       "      <td>-1.251528</td>\n",
       "      <td>-0.301518</td>\n",
       "      <td>-5.329071e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021681</td>\n",
       "      <td>1.372310</td>\n",
       "      <td>-0.059266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.223972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386363</td>\n",
       "      <td>1.181405</td>\n",
       "      <td>-0.317219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cycle  unit  op_setting_1  op_setting_2  op_setting_3  sensor_1  sensor_2  \\\n",
       "0      1     1     -0.315980     -1.372953           0.0       0.0 -1.721725   \n",
       "1      2     1      0.872722     -1.031720           0.0       0.0 -1.061780   \n",
       "2      3     1     -1.961874      1.015677           0.0       0.0 -0.661813   \n",
       "3      4     1      0.324090     -0.008022           0.0       0.0 -0.661813   \n",
       "4      5     1     -0.864611     -0.690488           0.0       0.0 -0.621816   \n",
       "\n",
       "   sensor_3  sensor_4      sensor_5  ...  sensor_13_norm_unit  \\\n",
       "0 -0.134255 -0.925936 -5.329071e-15  ...            -1.278164   \n",
       "1  0.211528 -0.643726 -5.329071e-15  ...            -0.636957   \n",
       "2 -0.413166 -0.525953 -5.329071e-15  ...            -1.149922   \n",
       "3 -1.261314 -0.784831 -5.329071e-15  ...            -0.508715   \n",
       "4 -1.251528 -0.301518 -5.329071e-15  ...            -1.021681   \n",
       "\n",
       "   sensor_14_norm_unit  sensor_15_norm_unit  sensor_16_norm_unit  \\\n",
       "0             1.997798            -0.380157                  0.0   \n",
       "1             1.072544             0.018526                  0.0   \n",
       "2             1.298342            -0.435259                  0.0   \n",
       "3             1.376204            -2.042955                  0.0   \n",
       "4             1.372310            -0.059266                  0.0   \n",
       "\n",
       "   sensor_17_norm_unit  sensor_18_norm_unit  sensor_19_norm_unit  \\\n",
       "0            -0.833752                  0.0                  0.0   \n",
       "1            -0.833752                  0.0                  0.0   \n",
       "2            -2.053313                  0.0                  0.0   \n",
       "3            -0.833752                  0.0                  0.0   \n",
       "4            -0.223972                  0.0                  0.0   \n",
       "\n",
       "   sensor_20_norm_unit  sensor_21_norm_unit  health_index  \n",
       "0             1.354811             1.317629     -0.534520  \n",
       "1             0.991643             1.360548     -0.438211  \n",
       "2             0.689003             0.619718     -0.618248  \n",
       "3             0.265307             0.896829     -0.765705  \n",
       "4             0.386363             1.181405     -0.317219  \n",
       "\n",
       "[5 rows x 428 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from agentic_pm.modeling.nested_cv import nested_cv\n",
    "\n",
    "train_df = pd.read_csv(\"data/processed/CMAPSS/train_FD001_final.csv\")\n",
    "test_df  = pd.read_csv(\"data/processed/CMAPSS/test_FD001_final.csv\")\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80a52efd-8271-4292-b252-bcd3de546abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106,\n",
       " ['sensor_1',\n",
       "  'sensor_2',\n",
       "  'sensor_3',\n",
       "  'sensor_4',\n",
       "  'sensor_5',\n",
       "  'sensor_6',\n",
       "  'sensor_7',\n",
       "  'sensor_8',\n",
       "  'sensor_9',\n",
       "  'sensor_10'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "keep_patterns = [\n",
    "    r'^sensor_\\d+$',\n",
    "    r'^sensor_\\d+_rm_5$',\n",
    "    r'^sensor_\\d+_rm_15$',\n",
    "    r'^sensor_\\d+_rm_60$',\n",
    "    r'^sensor_\\d+_rstd_5$',\n",
    "    r'^health_index$',\n",
    "    r'^anom_score$'\n",
    "]\n",
    "\n",
    "import re\n",
    "def match_any(col):\n",
    "    return any(re.match(p, col) for p in keep_patterns)\n",
    "\n",
    "reduced_features = [c for c in feature_cols if match_any(c)]\n",
    "len(reduced_features), reduced_features[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "933c9d78-d60c-4870-ad19-54c6a70d5f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 21:54:04,611] A new study created in memory with name: no-name-cd12e146-00c0-4fee-b741-cb31a50115e9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”µ Starting Nested CV with 3 outer folds\n",
      "\n",
      "==============================\n",
      "ðŸŸ£ Outer Fold 1/3\n",
      "==============================\n",
      "   ðŸ” Inner Optuna tuning running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 21:54:19,282] Trial 0 finished with value: 25.284069545526744 and parameters: {'num_leaves': 194, 'learning_rate': 0.06459929534336861, 'feature_fraction': 0.6587121822901748, 'bagging_fraction': 0.6602133433127397, 'bagging_freq': 5, 'min_data_in_leaf': 43}. Best is trial 0 with value: 25.284069545526744.\n",
      "[I 2025-11-18 21:54:40,316] Trial 1 finished with value: 25.020514627747406 and parameters: {'num_leaves': 62, 'learning_rate': 0.06793437481942677, 'feature_fraction': 0.5578525038526883, 'bagging_fraction': 0.9248418227756814, 'bagging_freq': 9, 'min_data_in_leaf': 35}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 21:54:54,193] Trial 2 finished with value: 37.63652537390882 and parameters: {'num_leaves': 18, 'learning_rate': 0.0013506906929449162, 'feature_fraction': 0.8646398201998344, 'bagging_fraction': 0.685155478136366, 'bagging_freq': 5, 'min_data_in_leaf': 62}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 21:55:11,709] Trial 3 finished with value: 26.156295871979125 and parameters: {'num_leaves': 185, 'learning_rate': 0.04597955218322729, 'feature_fraction': 0.6504738747971437, 'bagging_fraction': 0.5156600148369537, 'bagging_freq': 7, 'min_data_in_leaf': 27}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 21:56:24,971] Trial 4 finished with value: 28.411946972107945 and parameters: {'num_leaves': 146, 'learning_rate': 0.0068294167617458665, 'feature_fraction': 0.9097733381160692, 'bagging_fraction': 0.8955031670370501, 'bagging_freq': 4, 'min_data_in_leaf': 31}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 21:57:10,175] Trial 5 finished with value: 30.509274587197762 and parameters: {'num_leaves': 141, 'learning_rate': 0.0036093592915499447, 'feature_fraction': 0.9622102574024121, 'bagging_fraction': 0.9337953438617469, 'bagging_freq': 5, 'min_data_in_leaf': 56}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 21:57:41,367] Trial 6 finished with value: 29.095368804703693 and parameters: {'num_leaves': 73, 'learning_rate': 0.0153753311740353, 'feature_fraction': 0.9818881231598822, 'bagging_fraction': 0.5075162218844413, 'bagging_freq': 9, 'min_data_in_leaf': 49}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 21:58:57,281] Trial 7 finished with value: 35.08142801000407 and parameters: {'num_leaves': 128, 'learning_rate': 0.0010863488126890068, 'feature_fraction': 0.5698690869853487, 'bagging_fraction': 0.8767971754127497, 'bagging_freq': 3, 'min_data_in_leaf': 24}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:00:14,945] Trial 8 finished with value: 35.35978275236934 and parameters: {'num_leaves': 191, 'learning_rate': 0.0011704242241079039, 'feature_fraction': 0.7395516169330618, 'bagging_fraction': 0.948815714225347, 'bagging_freq': 9, 'min_data_in_leaf': 28}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:00:48,449] Trial 9 finished with value: 29.346247295137264 and parameters: {'num_leaves': 183, 'learning_rate': 0.005476489162605227, 'feature_fraction': 0.7940049679756849, 'bagging_fraction': 0.8187096976523893, 'bagging_freq': 6, 'min_data_in_leaf': 51}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:01:05,842] Trial 10 finished with value: 26.71234903260152 and parameters: {'num_leaves': 67, 'learning_rate': 0.16994070623009852, 'feature_fraction': 0.5259184266126936, 'bagging_fraction': 0.7855311293729628, 'bagging_freq': 1, 'min_data_in_leaf': 5}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:01:16,399] Trial 11 finished with value: 25.4017962126586 and parameters: {'num_leaves': 75, 'learning_rate': 0.06958225341006778, 'feature_fraction': 0.6369636504778318, 'bagging_fraction': 0.6624397125197804, 'bagging_freq': 10, 'min_data_in_leaf': 72}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:01:38,060] Trial 12 finished with value: 25.698337539229602 and parameters: {'num_leaves': 28, 'learning_rate': 0.039102702519360884, 'feature_fraction': 0.6582669457124487, 'bagging_fraction': 0.6422014089466247, 'bagging_freq': 7, 'min_data_in_leaf': 39}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:01:56,125] Trial 13 finished with value: 28.192252365112722 and parameters: {'num_leaves': 103, 'learning_rate': 0.13031677731451238, 'feature_fraction': 0.7229660337492905, 'bagging_fraction': 0.5927058232580675, 'bagging_freq': 2, 'min_data_in_leaf': 13}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:02:21,512] Trial 14 finished with value: 28.39502591291596 and parameters: {'num_leaves': 47, 'learning_rate': 0.02122081215074753, 'feature_fraction': 0.5811671594822383, 'bagging_fraction': 0.7408537678976705, 'bagging_freq': 8, 'min_data_in_leaf': 40}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:02:38,701] Trial 15 finished with value: 25.503587772279488 and parameters: {'num_leaves': 104, 'learning_rate': 0.08362520031177832, 'feature_fraction': 0.5143466042247051, 'bagging_fraction': 0.9882910004175218, 'bagging_freq': 6, 'min_data_in_leaf': 67}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:02:58,461] Trial 16 finished with value: 28.935776411197036 and parameters: {'num_leaves': 165, 'learning_rate': 0.02590148962012813, 'feature_fraction': 0.6938792752749298, 'bagging_fraction': 0.7248220759868242, 'bagging_freq': 3, 'min_data_in_leaf': 79}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:03:14,745] Trial 17 finished with value: 25.564956932054432 and parameters: {'num_leaves': 91, 'learning_rate': 0.09726168045826195, 'feature_fraction': 0.7979092891088817, 'bagging_fraction': 0.8352545512510301, 'bagging_freq': 10, 'min_data_in_leaf': 17}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:03:37,857] Trial 18 finished with value: 25.1252443387659 and parameters: {'num_leaves': 46, 'learning_rate': 0.03928690702413784, 'feature_fraction': 0.5873725083245763, 'bagging_fraction': 0.6028745038498935, 'bagging_freq': 7, 'min_data_in_leaf': 38}. Best is trial 1 with value: 25.020514627747406.\n",
      "[I 2025-11-18 22:03:41,676] Trial 19 finished with value: 27.255802098499533 and parameters: {'num_leaves': 40, 'learning_rate': 0.19911084510141977, 'feature_fraction': 0.5907024141709875, 'bagging_fraction': 0.5877484194818349, 'bagging_freq': 8, 'min_data_in_leaf': 35}. Best is trial 1 with value: 25.020514627747406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ” Best inner params: {'num_leaves': 62, 'learning_rate': 0.06793437481942677, 'feature_fraction': 0.5578525038526883, 'bagging_fraction': 0.9248418227756814, 'bagging_freq': 9, 'min_data_in_leaf': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 22:03:51,015] A new study created in memory with name: no-name-563b25e3-9b4b-466b-85fc-cfd4779be8ed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸŸ£ Outer Fold 2/3\n",
      "==============================\n",
      "   ðŸ” Inner Optuna tuning running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 22:04:42,193] Trial 0 finished with value: 27.927449728233615 and parameters: {'num_leaves': 191, 'learning_rate': 0.008920154067967642, 'feature_fraction': 0.8971047565954049, 'bagging_fraction': 0.9651110089122326, 'bagging_freq': 9, 'min_data_in_leaf': 72}. Best is trial 0 with value: 27.927449728233615.\n",
      "[I 2025-11-18 22:06:02,364] Trial 1 finished with value: 28.29574627082053 and parameters: {'num_leaves': 169, 'learning_rate': 0.014603267614036975, 'feature_fraction': 0.9417027090086517, 'bagging_fraction': 0.531580295747047, 'bagging_freq': 6, 'min_data_in_leaf': 24}. Best is trial 0 with value: 27.927449728233615.\n",
      "[I 2025-11-18 22:07:16,833] Trial 2 finished with value: 31.103208040102345 and parameters: {'num_leaves': 150, 'learning_rate': 0.0030323725137054954, 'feature_fraction': 0.7549767055994452, 'bagging_fraction': 0.9127135511108219, 'bagging_freq': 4, 'min_data_in_leaf': 45}. Best is trial 0 with value: 27.927449728233615.\n",
      "[I 2025-11-18 22:08:04,604] Trial 3 finished with value: 28.077635072657504 and parameters: {'num_leaves': 141, 'learning_rate': 0.036676414286701146, 'feature_fraction': 0.9733302695646087, 'bagging_fraction': 0.9922851057330423, 'bagging_freq': 2, 'min_data_in_leaf': 42}. Best is trial 0 with value: 27.927449728233615.\n",
      "[I 2025-11-18 22:08:35,130] Trial 4 finished with value: 27.932772192874385 and parameters: {'num_leaves': 88, 'learning_rate': 0.055343278844717445, 'feature_fraction': 0.9924013633572915, 'bagging_fraction': 0.8850351855513989, 'bagging_freq': 7, 'min_data_in_leaf': 53}. Best is trial 0 with value: 27.927449728233615.\n",
      "[I 2025-11-18 22:08:51,604] Trial 5 finished with value: 27.77973167066881 and parameters: {'num_leaves': 188, 'learning_rate': 0.04692871105423619, 'feature_fraction': 0.611488859920642, 'bagging_fraction': 0.6252190438816496, 'bagging_freq': 3, 'min_data_in_leaf': 46}. Best is trial 5 with value: 27.77973167066881.\n",
      "[I 2025-11-18 22:09:15,630] Trial 6 finished with value: 41.24748865505191 and parameters: {'num_leaves': 26, 'learning_rate': 0.0014364662252116123, 'feature_fraction': 0.5389814272956112, 'bagging_fraction': 0.7371252610531074, 'bagging_freq': 7, 'min_data_in_leaf': 71}. Best is trial 5 with value: 27.77973167066881.\n",
      "[I 2025-11-18 22:10:27,325] Trial 7 finished with value: 40.22222636850575 and parameters: {'num_leaves': 45, 'learning_rate': 0.0012638110220711436, 'feature_fraction': 0.8780153132109131, 'bagging_fraction': 0.9230289076939606, 'bagging_freq': 5, 'min_data_in_leaf': 38}. Best is trial 5 with value: 27.77973167066881.\n",
      "[I 2025-11-18 22:11:13,327] Trial 8 finished with value: 27.772108372659172 and parameters: {'num_leaves': 49, 'learning_rate': 0.03414283252095578, 'feature_fraction': 0.6299997095535426, 'bagging_fraction': 0.8039507454884953, 'bagging_freq': 7, 'min_data_in_leaf': 6}. Best is trial 8 with value: 27.772108372659172.\n",
      "[I 2025-11-18 22:11:42,430] Trial 9 finished with value: 35.38545723362858 and parameters: {'num_leaves': 27, 'learning_rate': 0.002593553308424115, 'feature_fraction': 0.8751351236818057, 'bagging_fraction': 0.6898682171933528, 'bagging_freq': 9, 'min_data_in_leaf': 40}. Best is trial 8 with value: 27.772108372659172.\n",
      "[I 2025-11-18 22:11:58,233] Trial 10 finished with value: 28.046001479939562 and parameters: {'num_leaves': 79, 'learning_rate': 0.1825010751034743, 'feature_fraction': 0.6862532750440955, 'bagging_fraction': 0.8238384584667828, 'bagging_freq': 10, 'min_data_in_leaf': 5}. Best is trial 8 with value: 27.772108372659172.\n",
      "[I 2025-11-18 22:12:34,706] Trial 11 finished with value: 28.191667334981364 and parameters: {'num_leaves': 115, 'learning_rate': 0.060398436991404444, 'feature_fraction': 0.5723838484415198, 'bagging_fraction': 0.6259295187100313, 'bagging_freq': 2, 'min_data_in_leaf': 7}. Best is trial 8 with value: 27.772108372659172.\n",
      "[I 2025-11-18 22:13:18,830] Trial 12 finished with value: 27.733969650129225 and parameters: {'num_leaves': 59, 'learning_rate': 0.021045524848898614, 'feature_fraction': 0.6377745234713824, 'bagging_fraction': 0.595071216028551, 'bagging_freq': 4, 'min_data_in_leaf': 27}. Best is trial 12 with value: 27.733969650129225.\n",
      "[I 2025-11-18 22:14:17,969] Trial 13 finished with value: 27.64756183840289 and parameters: {'num_leaves': 62, 'learning_rate': 0.016053135663343533, 'feature_fraction': 0.6815914987599561, 'bagging_fraction': 0.7872307159777132, 'bagging_freq': 5, 'min_data_in_leaf': 24}. Best is trial 13 with value: 27.64756183840289.\n",
      "[I 2025-11-18 22:15:14,928] Trial 14 finished with value: 27.864055980797385 and parameters: {'num_leaves': 71, 'learning_rate': 0.012395746539934636, 'feature_fraction': 0.7682575494024457, 'bagging_fraction': 0.5250789165418438, 'bagging_freq': 4, 'min_data_in_leaf': 23}. Best is trial 13 with value: 27.64756183840289.\n",
      "[I 2025-11-18 22:16:23,770] Trial 15 finished with value: 27.943026861828915 and parameters: {'num_leaves': 108, 'learning_rate': 0.006324671257239457, 'feature_fraction': 0.6785061376048276, 'bagging_fraction': 0.6521445185742661, 'bagging_freq': 1, 'min_data_in_leaf': 25}. Best is trial 13 with value: 27.64756183840289.\n",
      "[I 2025-11-18 22:17:09,890] Trial 16 finished with value: 27.52354731810982 and parameters: {'num_leaves': 58, 'learning_rate': 0.01991991477770994, 'feature_fraction': 0.504133672688757, 'bagging_fraction': 0.7892394478088753, 'bagging_freq': 5, 'min_data_in_leaf': 17}. Best is trial 16 with value: 27.52354731810982.\n",
      "[I 2025-11-18 22:17:26,189] Trial 17 finished with value: 28.173792912958575 and parameters: {'num_leaves': 90, 'learning_rate': 0.11250050301522303, 'feature_fraction': 0.5124147565087246, 'bagging_fraction': 0.7950642290798886, 'bagging_freq': 6, 'min_data_in_leaf': 15}. Best is trial 16 with value: 27.52354731810982.\n",
      "[I 2025-11-18 22:17:52,103] Trial 18 finished with value: 34.01193066024942 and parameters: {'num_leaves': 18, 'learning_rate': 0.0048813404859373456, 'feature_fraction': 0.8223833052568805, 'bagging_fraction': 0.7345103394386773, 'bagging_freq': 5, 'min_data_in_leaf': 18}. Best is trial 16 with value: 27.52354731810982.\n",
      "[I 2025-11-18 22:19:01,734] Trial 19 finished with value: 27.554352175994286 and parameters: {'num_leaves': 124, 'learning_rate': 0.020822848050207128, 'feature_fraction': 0.7026573243831439, 'bagging_fraction': 0.8511316419031338, 'bagging_freq': 8, 'min_data_in_leaf': 33}. Best is trial 16 with value: 27.52354731810982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ” Best inner params: {'num_leaves': 58, 'learning_rate': 0.01991991477770994, 'feature_fraction': 0.504133672688757, 'bagging_fraction': 0.7892394478088753, 'bagging_freq': 5, 'min_data_in_leaf': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 22:19:34,866] A new study created in memory with name: no-name-4dba56a6-a4cc-4768-9d7a-c018491d2c86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸŸ£ Outer Fold 3/3\n",
      "==============================\n",
      "   ðŸ” Inner Optuna tuning running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 22:19:59,039] Trial 0 finished with value: 30.936668905563334 and parameters: {'num_leaves': 19, 'learning_rate': 0.008073551465127459, 'feature_fraction': 0.557366579476893, 'bagging_fraction': 0.8010145823440538, 'bagging_freq': 4, 'min_data_in_leaf': 34}. Best is trial 0 with value: 30.936668905563334.\n",
      "[I 2025-11-18 22:21:31,983] Trial 1 finished with value: 32.13832376253564 and parameters: {'num_leaves': 68, 'learning_rate': 0.003632350030227681, 'feature_fraction': 0.7473718273926353, 'bagging_fraction': 0.931479898304024, 'bagging_freq': 9, 'min_data_in_leaf': 8}. Best is trial 0 with value: 30.936668905563334.\n",
      "[I 2025-11-18 22:22:13,759] Trial 2 finished with value: 27.77360781836221 and parameters: {'num_leaves': 168, 'learning_rate': 0.024874528493745184, 'feature_fraction': 0.5817595695912527, 'bagging_fraction': 0.5155207018311645, 'bagging_freq': 1, 'min_data_in_leaf': 41}. Best is trial 2 with value: 27.77360781836221.\n",
      "[I 2025-11-18 22:22:37,996] Trial 3 finished with value: 27.95699712065779 and parameters: {'num_leaves': 60, 'learning_rate': 0.07620789735974082, 'feature_fraction': 0.661749960536502, 'bagging_fraction': 0.9406179972464604, 'bagging_freq': 3, 'min_data_in_leaf': 23}. Best is trial 2 with value: 27.77360781836221.\n",
      "[I 2025-11-18 22:22:52,086] Trial 4 finished with value: 27.6160748093543 and parameters: {'num_leaves': 168, 'learning_rate': 0.1517634717294632, 'feature_fraction': 0.6622571068083296, 'bagging_fraction': 0.7273724408871572, 'bagging_freq': 8, 'min_data_in_leaf': 53}. Best is trial 4 with value: 27.6160748093543.\n",
      "[I 2025-11-18 22:23:38,852] Trial 5 finished with value: 27.78975430237446 and parameters: {'num_leaves': 157, 'learning_rate': 0.03803846530974154, 'feature_fraction': 0.639256727966541, 'bagging_fraction': 0.6904167370910104, 'bagging_freq': 3, 'min_data_in_leaf': 28}. Best is trial 4 with value: 27.6160748093543.\n",
      "[I 2025-11-18 22:24:41,794] Trial 6 finished with value: 27.6284283354419 and parameters: {'num_leaves': 51, 'learning_rate': 0.018328824733765993, 'feature_fraction': 0.7528603603401537, 'bagging_fraction': 0.9480708059038415, 'bagging_freq': 4, 'min_data_in_leaf': 11}. Best is trial 4 with value: 27.6160748093543.\n",
      "[I 2025-11-18 22:25:59,273] Trial 7 finished with value: 27.75709599879184 and parameters: {'num_leaves': 155, 'learning_rate': 0.019248065253993543, 'feature_fraction': 0.8347810128033977, 'bagging_fraction': 0.8396852869649511, 'bagging_freq': 10, 'min_data_in_leaf': 28}. Best is trial 4 with value: 27.6160748093543.\n",
      "[I 2025-11-18 22:26:17,650] Trial 8 finished with value: 28.554667687287008 and parameters: {'num_leaves': 60, 'learning_rate': 0.09931269172657074, 'feature_fraction': 0.6537448615344867, 'bagging_fraction': 0.6098303612597256, 'bagging_freq': 1, 'min_data_in_leaf': 7}. Best is trial 4 with value: 27.6160748093543.\n",
      "[I 2025-11-18 22:26:44,678] Trial 9 finished with value: 38.69251439193215 and parameters: {'num_leaves': 26, 'learning_rate': 0.0026947428383229098, 'feature_fraction': 0.641347116876434, 'bagging_fraction': 0.5430121503330845, 'bagging_freq': 6, 'min_data_in_leaf': 40}. Best is trial 4 with value: 27.6160748093543.\n",
      "[I 2025-11-18 22:26:56,078] Trial 10 finished with value: 27.38300173475703 and parameters: {'num_leaves': 196, 'learning_rate': 0.16747332844106252, 'feature_fraction': 0.9909826520102807, 'bagging_fraction': 0.7095053399180138, 'bagging_freq': 7, 'min_data_in_leaf': 66}. Best is trial 10 with value: 27.38300173475703.\n",
      "[I 2025-11-18 22:27:11,485] Trial 11 finished with value: 27.485987639602428 and parameters: {'num_leaves': 200, 'learning_rate': 0.18666068892659654, 'feature_fraction': 0.9914541523649861, 'bagging_fraction': 0.7119771429325916, 'bagging_freq': 7, 'min_data_in_leaf': 67}. Best is trial 10 with value: 27.38300173475703.\n",
      "[I 2025-11-18 22:27:18,266] Trial 12 finished with value: 28.343306793666812 and parameters: {'num_leaves': 197, 'learning_rate': 0.19619892173872786, 'feature_fraction': 0.9942110472093466, 'bagging_fraction': 0.6400161582899254, 'bagging_freq': 7, 'min_data_in_leaf': 77}. Best is trial 10 with value: 27.38300173475703.\n",
      "[I 2025-11-18 22:28:21,652] Trial 13 finished with value: 45.145824984129696 and parameters: {'num_leaves': 118, 'learning_rate': 0.0011682586834615997, 'feature_fraction': 0.9961604533995913, 'bagging_fraction': 0.8077292207766947, 'bagging_freq': 7, 'min_data_in_leaf': 64}. Best is trial 10 with value: 27.38300173475703.\n",
      "[I 2025-11-18 22:28:42,418] Trial 14 finished with value: 27.278355182646123 and parameters: {'num_leaves': 193, 'learning_rate': 0.044098942423913094, 'feature_fraction': 0.9173771406765923, 'bagging_fraction': 0.6765865192979565, 'bagging_freq': 6, 'min_data_in_leaf': 78}. Best is trial 14 with value: 27.278355182646123.\n",
      "[I 2025-11-18 22:28:56,246] Trial 15 finished with value: 27.837353323057048 and parameters: {'num_leaves': 115, 'learning_rate': 0.05238355504019339, 'feature_fraction': 0.9073907264112847, 'bagging_fraction': 0.6151878089848284, 'bagging_freq': 6, 'min_data_in_leaf': 75}. Best is trial 14 with value: 27.278355182646123.\n",
      "[I 2025-11-18 22:29:51,530] Trial 16 finished with value: 27.88360017536799 and parameters: {'num_leaves': 137, 'learning_rate': 0.008906885626315933, 'feature_fraction': 0.9019253291412823, 'bagging_fraction': 0.6691030499307469, 'bagging_freq': 5, 'min_data_in_leaf': 67}. Best is trial 14 with value: 27.278355182646123.\n",
      "[I 2025-11-18 22:30:12,619] Trial 17 finished with value: 28.004480926010928 and parameters: {'num_leaves': 183, 'learning_rate': 0.07740497240741429, 'feature_fraction': 0.915229825434811, 'bagging_fraction': 0.7712445750972688, 'bagging_freq': 9, 'min_data_in_leaf': 54}. Best is trial 14 with value: 27.278355182646123.\n",
      "[I 2025-11-18 22:30:44,140] Trial 18 finished with value: 27.327582466505575 and parameters: {'num_leaves': 87, 'learning_rate': 0.038206836259430825, 'feature_fraction': 0.8308737996672901, 'bagging_fraction': 0.8702288333184622, 'bagging_freq': 5, 'min_data_in_leaf': 55}. Best is trial 14 with value: 27.278355182646123.\n",
      "[I 2025-11-18 22:31:27,232] Trial 19 finished with value: 27.765521211297298 and parameters: {'num_leaves': 87, 'learning_rate': 0.03622267111871543, 'feature_fraction': 0.8216026726481833, 'bagging_fraction': 0.8775315060213453, 'bagging_freq': 5, 'min_data_in_leaf': 53}. Best is trial 14 with value: 27.278355182646123.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ” Best inner params: {'num_leaves': 193, 'learning_rate': 0.044098942423913094, 'feature_fraction': 0.9173771406765923, 'bagging_fraction': 0.6765865192979565, 'bagging_freq': 6, 'min_data_in_leaf': 78}\n",
      "\n",
      "==============================\n",
      "ðŸ“Œ Nested CV Completed\n",
      "==============================\n",
      "   outer_fold        MAE       RMSE        R2  Precision@100  EarlyWarning@7  \\\n",
      "0           0  31.417908  38.446739 -0.866202           0.02             0.0   \n",
      "1           1  18.163740  21.213719 -0.149288           0.13             0.0   \n",
      "2           2  15.050323  18.083780 -0.695077           0.03             0.0   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'num_leaves': 62, 'learning_rate': 0.06793437...  \n",
      "1  {'num_leaves': 58, 'learning_rate': 0.01991991...  \n",
      "2  {'num_leaves': 193, 'learning_rate': 0.0440989...  \n",
      "\n",
      "ðŸ“Œ Average metrics across outer folds:\n",
      "{'outer_fold': 1.0, 'MAE': 21.543990315736206, 'RMSE': 25.914746283808437, 'R2': -0.5701890521954219, 'Precision@100': 0.06, 'EarlyWarning@7': 0.0}\n"
     ]
    }
   ],
   "source": [
    "results, avg = nested_cv(\n",
    "    df=train_df,\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=\"RUL\",\n",
    "    outer_splits=3,\n",
    "    inner_splits=3,\n",
    "    inner_trials=20,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2bff3a97-670e-49e9-917b-d5dfb81fcf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 23:36:40,304] A new study created in memory with name: no-name-7e087cce-24e9-4768-8562-203f3de2a904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”µ Starting Nested CV with 3 outer folds\n",
      "\n",
      "==============================\n",
      "ðŸŸ£ Outer Fold 1/3\n",
      "==============================\n",
      "   ðŸ” Inner Optuna tuning running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 23:36:53,223] Trial 0 finished with value: 25.973842083537118 and parameters: {'num_leaves': 199, 'learning_rate': 0.029771974085534458, 'feature_fraction': 0.9393202782940614, 'bagging_fraction': 0.6566006093856899, 'bagging_freq': 6, 'min_data_in_leaf': 40}. Best is trial 0 with value: 25.973842083537118.\n",
      "[I 2025-11-18 23:37:07,360] Trial 1 finished with value: 30.147260456618554 and parameters: {'num_leaves': 109, 'learning_rate': 0.0034433491559200547, 'feature_fraction': 0.9981254837838416, 'bagging_fraction': 0.7469559952923778, 'bagging_freq': 8, 'min_data_in_leaf': 70}. Best is trial 0 with value: 25.973842083537118.\n",
      "[I 2025-11-18 23:37:37,239] Trial 2 finished with value: 33.648104512640124 and parameters: {'num_leaves': 166, 'learning_rate': 0.0013244066840459956, 'feature_fraction': 0.5245633090153364, 'bagging_fraction': 0.5504153427956537, 'bagging_freq': 3, 'min_data_in_leaf': 19}. Best is trial 0 with value: 25.973842083537118.\n",
      "[I 2025-11-18 23:37:47,147] Trial 3 finished with value: 27.522260456320456 and parameters: {'num_leaves': 20, 'learning_rate': 0.018347737787327564, 'feature_fraction': 0.5547010492488915, 'bagging_fraction': 0.6162630870992274, 'bagging_freq': 6, 'min_data_in_leaf': 12}. Best is trial 0 with value: 25.973842083537118.\n",
      "[I 2025-11-18 23:38:06,222] Trial 4 finished with value: 28.553037605720814 and parameters: {'num_leaves': 142, 'learning_rate': 0.00337554539416641, 'feature_fraction': 0.7630994534568979, 'bagging_fraction': 0.7598404371524308, 'bagging_freq': 6, 'min_data_in_leaf': 46}. Best is trial 0 with value: 25.973842083537118.\n",
      "[I 2025-11-18 23:38:26,140] Trial 5 finished with value: 34.42947240386538 and parameters: {'num_leaves': 40, 'learning_rate': 0.0012463986093237053, 'feature_fraction': 0.5711310356601733, 'bagging_fraction': 0.9313556358809345, 'bagging_freq': 8, 'min_data_in_leaf': 7}. Best is trial 0 with value: 25.973842083537118.\n",
      "[I 2025-11-18 23:38:30,463] Trial 6 finished with value: 26.22227850866004 and parameters: {'num_leaves': 159, 'learning_rate': 0.13192068518260533, 'feature_fraction': 0.9425168131884589, 'bagging_fraction': 0.5302126068660786, 'bagging_freq': 9, 'min_data_in_leaf': 33}. Best is trial 0 with value: 25.973842083537118.\n",
      "[I 2025-11-18 23:38:52,063] Trial 7 finished with value: 25.71030898811361 and parameters: {'num_leaves': 130, 'learning_rate': 0.01365169647508442, 'feature_fraction': 0.8571664485827275, 'bagging_fraction': 0.7470596182778446, 'bagging_freq': 4, 'min_data_in_leaf': 43}. Best is trial 7 with value: 25.71030898811361.\n",
      "[I 2025-11-18 23:39:01,794] Trial 8 finished with value: 35.804792703203766 and parameters: {'num_leaves': 24, 'learning_rate': 0.001356958059706357, 'feature_fraction': 0.8950044935478425, 'bagging_fraction': 0.6873765249219379, 'bagging_freq': 1, 'min_data_in_leaf': 57}. Best is trial 7 with value: 25.71030898811361.\n",
      "[I 2025-11-18 23:39:31,617] Trial 9 finished with value: 31.10403655491551 and parameters: {'num_leaves': 66, 'learning_rate': 0.0017950319833741695, 'feature_fraction': 0.6011607335861524, 'bagging_fraction': 0.7922010818519434, 'bagging_freq': 8, 'min_data_in_leaf': 7}. Best is trial 7 with value: 25.71030898811361.\n",
      "[I 2025-11-18 23:39:37,738] Trial 10 finished with value: 25.78932562686451 and parameters: {'num_leaves': 98, 'learning_rate': 0.06416371935845566, 'feature_fraction': 0.7965664440553073, 'bagging_fraction': 0.9151646820141186, 'bagging_freq': 3, 'min_data_in_leaf': 77}. Best is trial 7 with value: 25.71030898811361.\n",
      "[I 2025-11-18 23:39:45,811] Trial 11 finished with value: 25.980219975334432 and parameters: {'num_leaves': 99, 'learning_rate': 0.07177624982504582, 'feature_fraction': 0.7960139266530306, 'bagging_fraction': 0.9973002379027868, 'bagging_freq': 3, 'min_data_in_leaf': 75}. Best is trial 7 with value: 25.71030898811361.\n",
      "[I 2025-11-18 23:40:01,842] Trial 12 finished with value: 26.60488585445631 and parameters: {'num_leaves': 107, 'learning_rate': 0.008673332891527243, 'feature_fraction': 0.6794700918507832, 'bagging_fraction': 0.8744369496879313, 'bagging_freq': 3, 'min_data_in_leaf': 60}. Best is trial 7 with value: 25.71030898811361.\n",
      "[I 2025-11-18 23:40:14,236] Trial 13 finished with value: 26.084732740325354 and parameters: {'num_leaves': 79, 'learning_rate': 0.02929834178947452, 'feature_fraction': 0.835979404490064, 'bagging_fraction': 0.8651233077244719, 'bagging_freq': 1, 'min_data_in_leaf': 80}. Best is trial 7 with value: 25.71030898811361.\n",
      "[I 2025-11-18 23:40:21,827] Trial 14 finished with value: 25.994763443975483 and parameters: {'num_leaves': 129, 'learning_rate': 0.06338805991331009, 'feature_fraction': 0.7090781703277969, 'bagging_fraction': 0.8274309445320827, 'bagging_freq': 4, 'min_data_in_leaf': 61}. Best is trial 7 with value: 25.71030898811361.\n",
      "[I 2025-11-18 23:40:50,224] Trial 15 finished with value: 25.25625930558144 and parameters: {'num_leaves': 72, 'learning_rate': 0.009832422944707018, 'feature_fraction': 0.8497095680455045, 'bagging_fraction': 0.9998851433663413, 'bagging_freq': 4, 'min_data_in_leaf': 24}. Best is trial 15 with value: 25.25625930558144.\n",
      "[I 2025-11-18 23:41:17,721] Trial 16 finished with value: 25.54165207875756 and parameters: {'num_leaves': 61, 'learning_rate': 0.008602886876761093, 'feature_fraction': 0.8594928165260696, 'bagging_fraction': 0.9785570741010122, 'bagging_freq': 5, 'min_data_in_leaf': 25}. Best is trial 15 with value: 25.25625930558144.\n",
      "[I 2025-11-18 23:41:41,537] Trial 17 finished with value: 25.886696194721285 and parameters: {'num_leaves': 56, 'learning_rate': 0.007429495863159584, 'feature_fraction': 0.6666934998266498, 'bagging_fraction': 0.9868431294042421, 'bagging_freq': 5, 'min_data_in_leaf': 27}. Best is trial 15 with value: 25.25625930558144.\n",
      "[I 2025-11-18 23:42:11,846] Trial 18 finished with value: 25.82054577532071 and parameters: {'num_leaves': 77, 'learning_rate': 0.005112472958654784, 'feature_fraction': 0.8858347368253154, 'bagging_fraction': 0.9340438811191132, 'bagging_freq': 5, 'min_data_in_leaf': 25}. Best is trial 15 with value: 25.25625930558144.\n",
      "[I 2025-11-18 23:42:32,407] Trial 19 finished with value: 25.951394897199695 and parameters: {'num_leaves': 39, 'learning_rate': 0.013357833112879408, 'feature_fraction': 0.9937713121891791, 'bagging_fraction': 0.9639078538678496, 'bagging_freq': 7, 'min_data_in_leaf': 18}. Best is trial 15 with value: 25.25625930558144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ” Best inner params: {'num_leaves': 72, 'learning_rate': 0.009832422944707018, 'feature_fraction': 0.8497095680455045, 'bagging_fraction': 0.9998851433663413, 'bagging_freq': 4, 'min_data_in_leaf': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 23:42:55,487] A new study created in memory with name: no-name-11d8addf-727c-4cdb-9c41-efdba75617d8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸŸ£ Outer Fold 2/3\n",
      "==============================\n",
      "   ðŸ” Inner Optuna tuning running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 23:43:01,193] Trial 0 finished with value: 31.26022039902502 and parameters: {'num_leaves': 102, 'learning_rate': 0.17402099360265333, 'feature_fraction': 0.5700268590705628, 'bagging_fraction': 0.8508090084809191, 'bagging_freq': 5, 'min_data_in_leaf': 29}. Best is trial 0 with value: 31.26022039902502.\n",
      "[I 2025-11-18 23:43:57,437] Trial 1 finished with value: 42.40312765857423 and parameters: {'num_leaves': 93, 'learning_rate': 0.0010412490360961874, 'feature_fraction': 0.7342317573806749, 'bagging_fraction': 0.7658837679712144, 'bagging_freq': 7, 'min_data_in_leaf': 8}. Best is trial 0 with value: 31.26022039902502.\n",
      "[I 2025-11-18 23:44:16,302] Trial 2 finished with value: 31.7411116051933 and parameters: {'num_leaves': 71, 'learning_rate': 0.025618096404752225, 'feature_fraction': 0.7758187347486425, 'bagging_fraction': 0.5361771586258137, 'bagging_freq': 8, 'min_data_in_leaf': 59}. Best is trial 0 with value: 31.26022039902502.\n",
      "[I 2025-11-18 23:44:35,751] Trial 3 finished with value: 37.35291308590714 and parameters: {'num_leaves': 96, 'learning_rate': 0.003332566759491739, 'feature_fraction': 0.5495815169599229, 'bagging_fraction': 0.5100991859092475, 'bagging_freq': 6, 'min_data_in_leaf': 68}. Best is trial 0 with value: 31.26022039902502.\n",
      "[I 2025-11-18 23:45:23,344] Trial 4 finished with value: 31.122266381912556 and parameters: {'num_leaves': 69, 'learning_rate': 0.02330436295290011, 'feature_fraction': 0.5610706471723996, 'bagging_fraction': 0.6926021951654269, 'bagging_freq': 8, 'min_data_in_leaf': 16}. Best is trial 4 with value: 31.122266381912556.\n",
      "[I 2025-11-18 23:46:00,888] Trial 5 finished with value: 38.60532163979897 and parameters: {'num_leaves': 171, 'learning_rate': 0.001943243530766953, 'feature_fraction': 0.5994691733565448, 'bagging_fraction': 0.7670393824992698, 'bagging_freq': 8, 'min_data_in_leaf': 55}. Best is trial 4 with value: 31.122266381912556.\n",
      "[I 2025-11-18 23:46:24,643] Trial 6 finished with value: 31.095289556734418 and parameters: {'num_leaves': 136, 'learning_rate': 0.051878279180437664, 'feature_fraction': 0.8956505048106957, 'bagging_fraction': 0.8494538214725442, 'bagging_freq': 2, 'min_data_in_leaf': 37}. Best is trial 6 with value: 31.095289556734418.\n",
      "[I 2025-11-18 23:46:36,108] Trial 7 finished with value: 31.05757412671532 and parameters: {'num_leaves': 20, 'learning_rate': 0.05292471920793855, 'feature_fraction': 0.5613495102353983, 'bagging_fraction': 0.6453250350712993, 'bagging_freq': 1, 'min_data_in_leaf': 51}. Best is trial 7 with value: 31.05757412671532.\n",
      "[I 2025-11-18 23:47:12,199] Trial 8 finished with value: 31.296586519915092 and parameters: {'num_leaves': 91, 'learning_rate': 0.014051968936073404, 'feature_fraction': 0.6592292051719415, 'bagging_fraction': 0.8011740227319484, 'bagging_freq': 7, 'min_data_in_leaf': 69}. Best is trial 7 with value: 31.05757412671532.\n",
      "[I 2025-11-18 23:48:12,104] Trial 9 finished with value: 31.27774421887285 and parameters: {'num_leaves': 75, 'learning_rate': 0.014548596971312396, 'feature_fraction': 0.6778930046909577, 'bagging_fraction': 0.747224862339755, 'bagging_freq': 9, 'min_data_in_leaf': 8}. Best is trial 7 with value: 31.05757412671532.\n",
      "[I 2025-11-18 23:48:15,783] Trial 10 finished with value: 30.51471116639318 and parameters: {'num_leaves': 18, 'learning_rate': 0.16982779129560277, 'feature_fraction': 0.9479721646445783, 'bagging_fraction': 0.6453915255621331, 'bagging_freq': 1, 'min_data_in_leaf': 48}. Best is trial 10 with value: 30.51471116639318.\n",
      "[I 2025-11-18 23:48:20,387] Trial 11 finished with value: 30.904702478424863 and parameters: {'num_leaves': 16, 'learning_rate': 0.14820715462312675, 'feature_fraction': 0.9822033634727411, 'bagging_fraction': 0.6348308037834088, 'bagging_freq': 1, 'min_data_in_leaf': 47}. Best is trial 10 with value: 30.51471116639318.\n",
      "[I 2025-11-18 23:48:24,372] Trial 12 finished with value: 31.181455454098057 and parameters: {'num_leaves': 17, 'learning_rate': 0.1829469594079429, 'feature_fraction': 0.9991731542477286, 'bagging_fraction': 0.6144510883478513, 'bagging_freq': 3, 'min_data_in_leaf': 42}. Best is trial 10 with value: 30.51471116639318.\n",
      "[I 2025-11-18 23:48:39,303] Trial 13 finished with value: 30.341962107674693 and parameters: {'num_leaves': 44, 'learning_rate': 0.08980059975471123, 'feature_fraction': 0.9660320227923596, 'bagging_fraction': 0.96795371847666, 'bagging_freq': 3, 'min_data_in_leaf': 80}. Best is trial 13 with value: 30.341962107674693.\n",
      "[I 2025-11-18 23:48:54,667] Trial 14 finished with value: 30.859674043514207 and parameters: {'num_leaves': 45, 'learning_rate': 0.07505103454942298, 'feature_fraction': 0.8840789688675474, 'bagging_fraction': 0.9898616785668113, 'bagging_freq': 4, 'min_data_in_leaf': 73}. Best is trial 13 with value: 30.341962107674693.\n",
      "[I 2025-11-18 23:49:07,045] Trial 15 finished with value: 30.862286824474428 and parameters: {'num_leaves': 46, 'learning_rate': 0.09922447905933375, 'feature_fraction': 0.896868223157467, 'bagging_fraction': 0.9810731268163196, 'bagging_freq': 3, 'min_data_in_leaf': 29}. Best is trial 13 with value: 30.341962107674693.\n",
      "[I 2025-11-18 23:49:30,918] Trial 16 finished with value: 32.1699879206978 and parameters: {'num_leaves': 136, 'learning_rate': 0.007363060753953918, 'feature_fraction': 0.7968478376468079, 'bagging_fraction': 0.9268082299242366, 'bagging_freq': 3, 'min_data_in_leaf': 78}. Best is trial 13 with value: 30.341962107674693.\n",
      "[I 2025-11-18 23:49:44,048] Trial 17 finished with value: 31.10438753533697 and parameters: {'num_leaves': 38, 'learning_rate': 0.03934272816831102, 'feature_fraction': 0.8490060035750924, 'bagging_fraction': 0.5752982531475825, 'bagging_freq': 2, 'min_data_in_leaf': 59}. Best is trial 13 with value: 30.341962107674693.\n",
      "[I 2025-11-18 23:49:50,605] Trial 18 finished with value: 31.56676394725211 and parameters: {'num_leaves': 124, 'learning_rate': 0.0979793144734376, 'feature_fraction': 0.9429116958247938, 'bagging_fraction': 0.6947568860616751, 'bagging_freq': 5, 'min_data_in_leaf': 79}. Best is trial 13 with value: 30.341962107674693.\n",
      "[I 2025-11-18 23:50:06,091] Trial 19 finished with value: 31.59306756601502 and parameters: {'num_leaves': 200, 'learning_rate': 0.08490618487150495, 'feature_fraction': 0.8390471183029015, 'bagging_fraction': 0.9096191532792595, 'bagging_freq': 1, 'min_data_in_leaf': 25}. Best is trial 13 with value: 30.341962107674693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ” Best inner params: {'num_leaves': 44, 'learning_rate': 0.08980059975471123, 'feature_fraction': 0.9660320227923596, 'bagging_fraction': 0.96795371847666, 'bagging_freq': 3, 'min_data_in_leaf': 80}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 23:50:13,476] A new study created in memory with name: no-name-72014570-f349-4903-b164-e6b9b895aa19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸŸ£ Outer Fold 3/3\n",
      "==============================\n",
      "   ðŸ” Inner Optuna tuning running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 23:50:19,495] Trial 0 finished with value: 32.48260340596381 and parameters: {'num_leaves': 75, 'learning_rate': 0.11371029595761421, 'feature_fraction': 0.9703370383971632, 'bagging_fraction': 0.6457218150201651, 'bagging_freq': 8, 'min_data_in_leaf': 70}. Best is trial 0 with value: 32.48260340596381.\n",
      "[I 2025-11-18 23:50:39,060] Trial 1 finished with value: 50.141213616985745 and parameters: {'num_leaves': 42, 'learning_rate': 0.0014381297807744445, 'feature_fraction': 0.5532815829526464, 'bagging_fraction': 0.8611713388516246, 'bagging_freq': 1, 'min_data_in_leaf': 61}. Best is trial 0 with value: 32.48260340596381.\n",
      "[I 2025-11-18 23:51:42,502] Trial 2 finished with value: 33.7429430830205 and parameters: {'num_leaves': 145, 'learning_rate': 0.020553098578038248, 'feature_fraction': 0.7463517104619655, 'bagging_fraction': 0.8476819219527341, 'bagging_freq': 1, 'min_data_in_leaf': 33}. Best is trial 0 with value: 32.48260340596381.\n",
      "[I 2025-11-18 23:51:53,269] Trial 3 finished with value: 32.93054388687016 and parameters: {'num_leaves': 55, 'learning_rate': 0.10230334674104175, 'feature_fraction': 0.9450454862081791, 'bagging_fraction': 0.9242977891029722, 'bagging_freq': 1, 'min_data_in_leaf': 29}. Best is trial 0 with value: 32.48260340596381.\n",
      "[I 2025-11-18 23:51:59,888] Trial 4 finished with value: 33.199188787433876 and parameters: {'num_leaves': 166, 'learning_rate': 0.08350604443036007, 'feature_fraction': 0.5869164815968098, 'bagging_fraction': 0.6488291223028803, 'bagging_freq': 6, 'min_data_in_leaf': 67}. Best is trial 0 with value: 32.48260340596381.\n",
      "[I 2025-11-18 23:53:19,291] Trial 5 finished with value: 34.050546028913764 and parameters: {'num_leaves': 113, 'learning_rate': 0.007942697198051978, 'feature_fraction': 0.6785849112629948, 'bagging_fraction': 0.8296869004724746, 'bagging_freq': 2, 'min_data_in_leaf': 28}. Best is trial 0 with value: 32.48260340596381.\n",
      "[I 2025-11-18 23:53:47,189] Trial 6 finished with value: 48.47149277020569 and parameters: {'num_leaves': 56, 'learning_rate': 0.0015257629398153967, 'feature_fraction': 0.5607640134280619, 'bagging_fraction': 0.7546360942403975, 'bagging_freq': 4, 'min_data_in_leaf': 19}. Best is trial 0 with value: 32.48260340596381.\n",
      "[I 2025-11-18 23:53:53,431] Trial 7 finished with value: 32.46056928659363 and parameters: {'num_leaves': 199, 'learning_rate': 0.08023111418750989, 'feature_fraction': 0.5389124273296972, 'bagging_fraction': 0.5639852288472298, 'bagging_freq': 9, 'min_data_in_leaf': 79}. Best is trial 7 with value: 32.46056928659363.\n",
      "[I 2025-11-18 23:54:00,883] Trial 8 finished with value: 33.25155501017046 and parameters: {'num_leaves': 153, 'learning_rate': 0.1320424580161312, 'feature_fraction': 0.9180330490344679, 'bagging_fraction': 0.8107181784259525, 'bagging_freq': 2, 'min_data_in_leaf': 69}. Best is trial 7 with value: 32.46056928659363.\n",
      "[I 2025-11-18 23:54:04,539] Trial 9 finished with value: 31.945911973740902 and parameters: {'num_leaves': 22, 'learning_rate': 0.1260934339263, 'feature_fraction': 0.6212910704370168, 'bagging_fraction': 0.5964638023453894, 'bagging_freq': 4, 'min_data_in_leaf': 52}. Best is trial 9 with value: 31.945911973740902.\n",
      "[I 2025-11-18 23:54:15,734] Trial 10 finished with value: 32.43713929694383 and parameters: {'num_leaves': 18, 'learning_rate': 0.020906426825864566, 'feature_fraction': 0.8051006615192313, 'bagging_fraction': 0.5597373073493107, 'bagging_freq': 5, 'min_data_in_leaf': 51}. Best is trial 9 with value: 31.945911973740902.\n",
      "[I 2025-11-18 23:54:29,282] Trial 11 finished with value: 31.93397387218126 and parameters: {'num_leaves': 20, 'learning_rate': 0.02217276291791728, 'feature_fraction': 0.8098740100162439, 'bagging_fraction': 0.5111603224418697, 'bagging_freq': 5, 'min_data_in_leaf': 48}. Best is trial 11 with value: 31.93397387218126.\n",
      "[I 2025-11-18 23:54:39,977] Trial 12 finished with value: 39.44045296304978 and parameters: {'num_leaves': 17, 'learning_rate': 0.006380048330757279, 'feature_fraction': 0.821671080808871, 'bagging_fraction': 0.522009022018773, 'bagging_freq': 4, 'min_data_in_leaf': 47}. Best is trial 11 with value: 31.93397387218126.\n",
      "[I 2025-11-18 23:54:54,395] Trial 13 finished with value: 32.692673575762996 and parameters: {'num_leaves': 88, 'learning_rate': 0.035358088153491805, 'feature_fraction': 0.6559852223353247, 'bagging_fraction': 0.6436292108432154, 'bagging_freq': 7, 'min_data_in_leaf': 54}. Best is trial 11 with value: 31.93397387218126.\n",
      "[I 2025-11-18 23:55:07,579] Trial 14 finished with value: 31.947870335568336 and parameters: {'num_leaves': 31, 'learning_rate': 0.04776387819791099, 'feature_fraction': 0.8659668377349751, 'bagging_fraction': 0.5020795497479672, 'bagging_freq': 4, 'min_data_in_leaf': 7}. Best is trial 11 with value: 31.93397387218126.\n",
      "[I 2025-11-18 23:55:42,565] Trial 15 finished with value: 37.16665189542589 and parameters: {'num_leaves': 116, 'learning_rate': 0.004036577825697565, 'feature_fraction': 0.7140092526581938, 'bagging_fraction': 0.5952057795550415, 'bagging_freq': 5, 'min_data_in_leaf': 41}. Best is trial 11 with value: 31.93397387218126.\n",
      "[I 2025-11-18 23:55:47,409] Trial 16 finished with value: 33.51299117516702 and parameters: {'num_leaves': 81, 'learning_rate': 0.18214153869305347, 'feature_fraction': 0.6279246884955977, 'bagging_fraction': 0.7228699426559798, 'bagging_freq': 10, 'min_data_in_leaf': 41}. Best is trial 11 with value: 31.93397387218126.\n",
      "[I 2025-11-18 23:56:03,966] Trial 17 finished with value: 32.47581928941723 and parameters: {'num_leaves': 51, 'learning_rate': 0.0440399158852713, 'feature_fraction': 0.5017364435056112, 'bagging_fraction': 0.9924789998727699, 'bagging_freq': 3, 'min_data_in_leaf': 58}. Best is trial 11 with value: 31.93397387218126.\n",
      "[I 2025-11-18 23:56:22,138] Trial 18 finished with value: 32.86188854798511 and parameters: {'num_leaves': 33, 'learning_rate': 0.013359196586882078, 'feature_fraction': 0.7917207762588463, 'bagging_fraction': 0.7087264877138497, 'bagging_freq': 6, 'min_data_in_leaf': 37}. Best is trial 11 with value: 31.93397387218126.\n",
      "[I 2025-11-18 23:56:53,410] Trial 19 finished with value: 41.387263988369114 and parameters: {'num_leaves': 71, 'learning_rate': 0.002686898273785685, 'feature_fraction': 0.8779315409130126, 'bagging_fraction': 0.5862151297313171, 'bagging_freq': 7, 'min_data_in_leaf': 48}. Best is trial 11 with value: 31.93397387218126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ” Best inner params: {'num_leaves': 20, 'learning_rate': 0.02217276291791728, 'feature_fraction': 0.8098740100162439, 'bagging_fraction': 0.5111603224418697, 'bagging_freq': 5, 'min_data_in_leaf': 48}\n",
      "\n",
      "==============================\n",
      "ðŸ“Œ Nested CV Completed\n",
      "==============================\n",
      "   outer_fold        MAE       RMSE        R2  Precision@100  EarlyWarning@7  \\\n",
      "0           0  38.407876  47.127483 -1.804065           0.09             0.0   \n",
      "1           1  23.284995  28.361995 -1.054323           0.11             0.0   \n",
      "2           2  18.267073  21.303689 -1.352452           0.00             0.0   \n",
      "\n",
      "                                         best_params  \n",
      "0  {'num_leaves': 72, 'learning_rate': 0.00983242...  \n",
      "1  {'num_leaves': 44, 'learning_rate': 0.08980059...  \n",
      "2  {'num_leaves': 20, 'learning_rate': 0.02217276...  \n",
      "\n",
      "ðŸ“Œ Average metrics across outer folds:\n",
      "{'outer_fold': 1.0, 'MAE': 26.65331425902204, 'RMSE': 32.26438897507788, 'R2': -1.4036132847636302, 'Precision@100': 0.06666666666666667, 'EarlyWarning@7': 0.0}\n"
     ]
    }
   ],
   "source": [
    "results, avg = nested_cv(\n",
    "    df=train_df,\n",
    "    feature_cols=reduced_features,\n",
    "    target_col=\"RUL\",\n",
    "    outer_splits=3,\n",
    "    inner_splits=3,\n",
    "    inner_trials=20,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65fb77-7044-4599-956d-fbf70fb13e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
